Q: Kaggleã®ãƒã‚¦ã‚¹ã®è¡Œå‹•è­˜åˆ¥ã«ã¤ã„ã¦ã‚¹ã‚³ã‚¢ãŒ0ã ã£ãŸã®ã§ã€æœ€åˆã‹ã‚‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’è€ƒãˆç›´ã—ãŸã„ã‚“ã ãŒã€æ‰‹ä¼ã£ã¦ãã‚Œã‚‹?
A: ã„ã„ã§ã™ã­ â€” ã‚„ã‚Šç›´ã—ã¾ã—ã‚‡ã†ã€‚ã¾ãšã¯ã€Œãªãœã‚¹ã‚³ã‚¢ãŒ0ã«ãªã£ãŸã‹ã€ã‚’ç´ æ—©ãæ½°ã—ã¦ã€ãã®å¾Œã«å …å®Ÿãªå†è¨­è¨ˆï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ â†’ æ©Ÿèƒ½å·¥å¤« â†’ ãƒ¢ãƒ‡ãƒ«æ”¹å–„ â†’ ãƒã‚¹ãƒˆå‡¦ç†ï¼‰ã‚’æ®µéšçš„ã«é€²ã‚ã¾ã™ã€‚ä¸‹ã« **å³å®Ÿè¡Œã§ãã‚‹ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼‹æœ€çŸ­ã§éã‚¼ãƒ­ã‚¹ã‚³ã‚¢ã‚’å‡ºã™ãŸã‚ã®å®Ÿè£…ä¾‹ï¼ˆPythonï¼‰**ã€ãã®ã‚ã¨ã§ **æœ¬æ ¼æ”¹å–„ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—** ã‚’ç¤ºã—ã¾ã™ã€‚
ï¼ˆè£œè¶³ï¼šKaggle ã®ã€Œãƒã‚¦ã‚¹è¡Œå‹•ã€ç³»ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã¨ã—ã¦ä»£è¡¨çš„ãªã®ã¯ MABeï¼ˆSocial Action Recognition in Miceï¼‰ã§ã€åŒç¨®ã®ãƒ‡ãƒ¼ã‚¿ï¼è©•ä¾¡è¨­å®šãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚å‚è€ƒæƒ…å ±ã‚’ç½®ã„ã¦ãŠãã¾ã™ã€‚ï¼‰([Kaggle][1])

---

# ã¾ãšå³ãƒã‚§ãƒƒã‚¯ï¼ˆ0ã‚¹ã‚³ã‚¢ã®åŸå› ã§å¤šã„ã‚‚ã®ï¼‰

1. **æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼åˆ—åãŒãƒ«ãƒ¼ãƒ«é€šã‚Šã‹**ï¼ˆIDåˆ—åï¼äºˆæ¸¬åˆ—åãƒ»é †åºï¼‰ã€‚
2. **äºˆæ¸¬ãŒå…¨éƒ¨0ã‚„NULLã«ãªã£ã¦ã„ãªã„ã‹**ï¼ˆãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã‚’ãã®ã¾ã¾ä¿å­˜ã—ã¦ã—ã¾ã†ãƒŸã‚¹ï¼‰ã€‚
3. **IDã®ä¸¦ã³é †ãŒæå‡ºãƒ«ãƒ¼ãƒ«ã¨é•ã£ã¦ã„ã‚‹**ï¼ˆè¡Œä¸¦ã³ã§è©•ä¾¡ã™ã‚‹ã‚¿ã‚¤ãƒ—ã ã¨ã‚¢ã‚¦ãƒˆï¼‰ã€‚
4. **ãƒ©ãƒ™ãƒ«ã®ç¬¦å·åŒ–ãƒŸã‚¹**ï¼ˆtrainã§ã¯ `label='attack'` â†’ å­¦ç¿’æ™‚ã«æ•´æ•°åŒ–ã—ãŸãŒã€æå‡ºæ™‚ã«é€†å¤‰æ›ã‚’å¿˜ã‚Œã¦ `0/1` ã‚’ãã®ã¾ã¾å‡ºã—ã¡ã‚ƒã†ç­‰ï¼‰ã€‚
5. **è©•ä¾¡æŒ‡æ¨™ã®å‹˜é•ã„**ï¼ˆãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ï¼ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ï¼æ™‚é–“ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å˜ä½ãªã©è©•ä¾¡å˜ä½ãŒé•ã†ï¼‰ã€‚
6. **ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆåˆ—æƒãˆ/ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰ãŒå­¦ç¿’æ™‚ã¨ä¸€è‡´ã—ã¦ã„ãªã„**ï¼ˆåˆ—åãšã‚Œã€NaNåŸ‹ã‚å¿˜ã‚Œï¼‰ã€‚
7. **CVã§ã®ãƒªãƒ¼ã‚¯ï¼trainã¨testã®IDé‡è¤‡** â†’ å®Ÿé‹ç”¨ã®å‡ºåŠ›ãŒæƒ³å®šå¤–ã«ãªã‚‹ã“ã¨ã‚‚ã€‚

ã¾ãšã¯æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSVï¼‰ã®å…ˆé ­æ•°è¡Œã‚’ `head()` ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚å•é¡Œç®‡æ‰€ãŒãªã‘ã‚Œã°æ¬¡ã¸é€²ã¿ã¾ã™ã€‚

---

# æœ€çŸ­ã§ã€Œå‹•ãã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆã‚„ã‚‹ã“ã¨ãƒ»ã‚³ãƒ¼ãƒ‰ä¾‹ï¼‰

ä»¥ä¸‹ã¯ä¸€èˆ¬çš„ãªå§¿å‹¢ï¼ˆpose/keypointsï¼‰ã‚„ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç³»ãƒ‡ãƒ¼ã‚¿ã‚’æƒ³å®šã—ãŸ**æ±ç”¨çš„ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã§ã™ã€‚åˆ—åã¯é©å®œã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦ãã ã•ã„ï¼ˆ`frame`, `mouse_id`, `x_0`,`y_0`,... ãªã©ï¼‰ã€‚ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã€Œã¾ãšã¯éã‚¼ãƒ­ã®ã‚¹ã‚³ã‚¢ã€ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚

```python
# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pandas as pd
import numpy as np
from sklearn.model_selection import GroupKFold
from sklearn.metrics import f1_score
import lightgbm as lgb

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆé©å®œãƒ‘ã‚¹ã‚’å¤‰ãˆã¦ï¼‰ ---
train = pd.read_csv('train.csv')   # ãƒ©ãƒ™ãƒ«ã‚ã‚Šï¼ˆframe, mouse_id, keypoints..., labelï¼‰
test  = pd.read_csv('test.csv')    # æå‡ºç”¨ï¼ˆid/frame, keypoints...ï¼‰

# --- ç°¡å˜ãªç‰¹å¾´é‡ï¼ˆã‚¿ã‚¤ãƒ ãƒ‡ã‚£ãƒšãƒ³ãƒ‡ãƒ³ãƒˆã§ãªã„æœ€å°é™ã®ã‚‚ã®ï¼‰ ---
# ä¾‹: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®å„ãƒšã‚¢ã®è·é›¢ã€é€Ÿåº¦ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ å·®åˆ†ï¼‰
def make_basic_features(df):
    # ä¾‹: keypoint columns x0,y0,x1,y1,... ã‚’æƒ³å®š
    kps = [c for c in df.columns if c.startswith('x') or c.startswith('y')]
    # ãƒšã‚¢é–“è·é›¢ (mouse1 nose ã¨ mouse2 nose ãªã©) â€” å®Ÿãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦é¸ã¶
    # ã“ã“ã§ã¯å˜ç´”ã«ä½“ä¸­å¿ƒ (mean x, mean y)
    xs = [c for c in kps if c.startswith('x')]
    ys = [c for c in kps if c.startswith('y')]
    df['cx'] = df[xs].mean(axis=1)
    df['cy'] = df[ys].mean(axis=1)
    # velocity: å·®åˆ†ï¼ˆè¦frameé †ï¼‰
    df = df.sort_values(['video_id','frame'])
    df['vx'] = df.groupby('video_id')['cx'].diff().fillna(0)
    df['vy'] = df.groupby('video_id')['cy'].diff().fillna(0)
    df['speed'] = np.sqrt(df['vx']**2 + df['vy']**2)
    # ã¾ã¨ã‚
    return df[['video_id','frame','cx','cy','vx','vy','speed']]

train_f = make_basic_features(train)
test_f  = make_basic_features(test)

# --- ãƒãƒ¼ã‚¸ã—ã¦ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ ---
# ãƒ©ãƒ™ãƒ«åˆ—ã¯ 'label'ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰ã‚’æƒ³å®šã€‚ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãªã„ã¨LGBMã¯ä¸å¯ã€‚
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
train_f = train_f.merge(train[['video_id','frame','label']], on=['video_id','frame'], how='left')
train_f['label_enc'] = le.fit_transform(train_f['label'])

# --- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆGroupKFold: video_idã§åˆ†ã‘ã‚‹ã®ãŒè‰¯ã„ï¼‰ ---
folds = GroupKFold(n_splits=5)
features = ['cx','cy','vx','vy','speed']
oof = np.zeros(len(train_f))
preds = np.zeros((len(test_f), len(le.classes_)))  # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ç¢ºç‡

for fold, (tr_idx, val_idx) in enumerate(folds.split(train_f, train_f['label_enc'], groups=train_f['video_id'])):
    tr_x = train_f.loc[tr_idx, features]
    tr_y = train_f.loc[tr_idx, 'label_enc']
    va_x = train_f.loc[val_idx, features]
    va_y = train_f.loc[val_idx, 'label_enc']

    dtrain = lgb.Dataset(tr_x, label=tr_y)
    dval   = lgb.Dataset(va_x, label=va_y, reference=dtrain)
    params = {
        'objective':'multiclass',
        'num_class': len(le.classes_),
        'metric':'multi_logloss',
        'verbosity': -1
    }
    bst = lgb.train(params, dtrain, valid_sets=[dval], early_stopping_rounds=50, num_boost_round=1000)
    oof[val_idx] = np.argmax(bst.predict(va_x), axis=1)
    preds += bst.predict(test_f[features]) / folds.n_splits

# --- è©•ä¾¡ï¼ˆå†…éƒ¨ï¼‰ ---
print("CV macro F1 (approx):", f1_score(train_f['label_enc'], oof, average='macro'))

# --- æå‡ºä½œæˆï¼ˆæå‡ºå½¢å¼ã«åˆã‚ã›ã¦å¤‰ãˆã‚‹ï¼‰ ---
test_preds_labels = le.inverse_transform(np.argmax(preds, axis=1))
submission = test[['id']].copy()
submission['label'] = test_preds_labels
submission.to_csv('submission.csv', index=False)
```

> ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯**ã¾ãšå‹•ããƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**ã‚’ä½œã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«åˆã‚ã›ã¦ `make_basic_features()` ã¨ `label`/`id` åˆ—ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

---

# ç‰¹ã«æœ‰åŠ¹ãªç‰¹å¾´é‡ï¼ˆPose / Tracking ãƒ‡ãƒ¼ã‚¿å‘ã‘ï¼‰

* å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåŒå£«ã®**è·é›¢**ï¼ˆpairwise distancesï¼‰
* è§’åº¦ï¼ˆé¼»â†’èƒ´ä½“â†’å°»å°¾ã®è§’åº¦ãªã©ï¼‰
* **é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦**ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ å·®åˆ†ï¼‰
* ãƒšã‚¢é–“ã®ç›¸å¯¾è·é›¢ãƒ»ç›¸å¯¾é€Ÿåº¦ï¼ˆç›¸äº’ä½œç”¨ã®æ‰‹ãŒã‹ã‚Šï¼‰
* ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†ç´„ï¼ˆéå»/æœªæ¥ N ãƒ•ãƒ¬ãƒ¼ãƒ ã® mean/std/max/minï¼‰
* å‡ºç¾æ™‚é–“ï¼ˆåŒã˜è¡Œå‹•ãŒé€£ç¶šã™ã‚‹æœ€å°æŒç¶šæ™‚é–“åˆ¶ç´„ã§å¾Œå‡¦ç†ã™ã‚‹ãŸã‚ã®ãƒ’ãƒ³ãƒˆï¼‰
* å…‰å­¦ãƒ•ãƒ­ãƒ¼ã‚„CNNç‰¹å¾´é‡ï¼ˆç”Ÿã®ç”»åƒãŒä½¿ãˆã‚‹ãªã‚‰ï¼‰ã‚„ã€æ™‚ç³»åˆ—ç”¨ã« **1D Conv / TCN / Transformer** ã§æ™‚é–“ä¾å­˜ã‚’ç›´æ¥æ‰±ã†æ‰‹æ³•ãŒæœ€è¿‘ã®æœ‰åŠ›è§£æ³•ã§ã™ï¼ˆå¤§ä¼šä¸Šä½ã¯æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«ã‚„Transformerç³»ã‚’ä½¿ã†ä¾‹ãŒå¤šã„ï¼‰ã€‚([Kaggle][2])

---

# ä¸å‡è¡¡ãƒ©ãƒ™ãƒ«å¯¾ç­–

* **Class weights** ã‚„ **Focal Loss** ã‚’æ¡ç”¨ã€‚LightGBM ã® `is_unbalance` ã‚„ `scale_pos_weight`ï¼ˆ2ã‚¯ãƒ©ã‚¹ï¼‰ã‚„ `class_weight`ï¼ˆsklearnãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰ã‚’æ¤œè¨ã€‚
* å°ã•ã„ã‚¯ãƒ©ã‚¹ã«å¯¾ã—ã¦**ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆSMOTEãªã©ï¼‰**ã¯æ™‚ç³»åˆ—ã§ã¯æ…é‡ã«ã€‚
* **è©•ä¾¡æŒ‡æ¨™ã«åˆã‚ã›ãŸæœ€é©åŒ–**ï¼ˆä¾‹ï¼šãƒã‚¯ãƒ­F1ãªã‚‰é–¾å€¤æœ€é©åŒ–ã‚„ç¢ºç‡ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ï¼‰ã€‚

---

# CV ã¨åˆ†å‰²æˆ¦ç•¥ï¼ˆè¶…é‡è¦ï¼‰

* **GroupKFold(video_id)**ï¼šåŒã˜videoãŒtrainã¨valã«å«ã¾ã‚Œã‚‹ã¨æ±šæŸ“ã®å¯èƒ½æ€§ãŒé«˜ã„ã€‚
* æ™‚ç³»åˆ—æ€§ãŒã‚ã‚‹ãªã‚‰ **time-based split**ï¼ˆéå»â†’æœªæ¥ï¼‰ã‚’ä½¿ã†ã€‚
* ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ãƒ»çŸ­æ™‚é–“ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºãªã‚‰ã€**é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ†å‰²**ã«æ³¨æ„ã€‚

---

# ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆæ®µéšçš„ã«ï¼‰

1. **LightGBM/XGBoost**ï¼ˆã‚¿ãƒ–ularç‰¹å¾´é‡ã€æœ€é€Ÿã§çµæœãŒå‡ºã‚‹ï¼‰
2. **1D-CNN / TCN**ï¼ˆçŸ­ã„æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥æ‰±ã†ï¼‰
3. **BiLSTM / Conv1D + BiLSTM**ï¼ˆæ™‚é–“çš„ä¾å­˜ï¼‰
4. **Transformerï¼ˆTime series Transformerï¼‰**ï¼ˆå¤§ä¼šä¸Šä½ã§å¤šç”¨ã•ã‚Œã¦ã„ã‚‹ã€ãŸã ã—è¨ˆç®—ã‚³ã‚¹ãƒˆé«˜ã‚ï¼‰ã€‚([thetransmitter.org][3])

---

# ãƒã‚¹ãƒˆå‡¦ç†ï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ç­‰ï¼‰

* äºˆæ¸¬ãƒ©ãƒ™ãƒ«åˆ—ã‚’ **ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ï¼æœ€å°æŒç¶šæ™‚é–“** ã§å¹³æ»‘åŒ–ï¼ˆä¾‹ãˆã°è¡Œå‹•ã¯çŸ­æ™‚é–“ã ã‘ã§ã¯æ„å‘³ãŒãªã„ã®ã§æœ€ä½Nãƒ•ãƒ¬ãƒ¼ãƒ ç¶šã‹ãªã„ãƒ©ãƒ™ãƒ«ã‚’å‘¨å›²ã®ãƒ©ãƒ™ãƒ«ã«ç½®æ›ï¼‰ã€‚
* ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ãªã‚‰**ç¢ºç‡é–¾å€¤èª¿æ•´**ï¼ˆã‚¯ãƒ©ã‚¹ã”ã¨ã«æœ€é©é–¾å€¤ï¼‰ã‚’è¡Œã†ã€‚

---

# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆï¼ˆæå‡ºãŒ0ç‚¹ã ã£ãŸã¨ãã«å®Ÿè¡Œã™ã‚‹ç°¡å˜ã‚³ãƒãƒ³ãƒ‰ï¼‰

```python
sub = pd.read_csv('submission.csv')
print(sub.head())
print(sub.columns)
print(sub['label'].value_counts(dropna=False))
# IDã®é‡è¤‡ãƒ»NaNç¢ºèª
print(sub['id'].duplicated().sum(), sub['id'].isna().sum())
```

ã“ã‚Œã§ `label` ãŒå…¨éƒ¨åŒã˜ï¼ˆä¾‹: å…¨éƒ¨ `0`ï¼‰ãªã‚‰ã‚³ãƒ¼ãƒ‰ã®ã©ã“ã‹ã§ `np.zeros(...)` ã‚’ä½¿ã£ã¦ã„ãªã„ã‹æ¢ã—ã¦ãã ã•ã„ã€‚

---

# æœ¬æ ¼çš„æ”¹å–„ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆå„ªå…ˆåº¦é †ï¼‰

1. **EDAå¾¹åº•**ï¼šã‚¯ãƒ©ã‚¹åˆ†å¸ƒã€å„featureã®åˆ†å¸ƒã€æ¬ æã€å‹•ç”»ã”ã¨ã®åã‚Šã€‚
2. **ç°¡æ˜“ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§CVç¢ºç«‹**ï¼šGroupKFold ã‚’ä½¿ã£ãŸå†ç¾å¯èƒ½ãªCVã‚’ä½œã‚‹ï¼ˆã“ã‚Œã§æœ¬å½“ã®æ”¹å–„ã‹ç¢ºèªï¼‰ã€‚
3. **å¼·åŒ–ã—ãŸç‰¹å¾´é‡**ï¼šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é›†ç´„ã€ç›¸äº’è·é›¢ã€è§’åº¦ã€é€Ÿåº¦ç³»ã®å……å®Ÿã€‚
4. **æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«å°å…¥**ï¼šã¾ãšã¯è»½é‡ãªConv1D/Tcnã€æ¬¡ã„ã§Transformerç³»ã€‚
5. **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«**ï¼šã‚¿ãƒ–ularï¼ˆGBMï¼‰ï¼‹æ™‚ç³»åˆ—NN ã‚’ç¢ºç‡å¹³å‡ã€‚
6. **ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®æœ€é©åŒ–**ï¼šé–¾å€¤æœ€é©åŒ–ã€ã‚¯ãƒ©ã‚¹ã”ã¨ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ãƒˆå‡¦ç†ã€‚
7. **ã‚¨ãƒ©ãƒ¼åˆ†æ**ï¼šç‰¹ã«æ··åŒã•ã‚Œã‚„ã™ã„ã‚¯ãƒ©ã‚¹ã‚’æŠ½å‡º â†’ è¿½åŠ ç‰¹å¾´ä½œæˆ or ãƒ‡ãƒ¼ã‚¿å¢—å¼·ã€‚

---

# æ¬¡ã«ç§ãŒã§ãã‚‹ã“ã¨ï¼ˆã‚ãªãŸãŒé¸ã¹ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼‰

* A. ä¸Šã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿åˆ—åã«åˆã‚ã›ã¦**ä¿®æ­£ã—ãŸã‚³ãƒ¼ãƒ‰**ã‚’ä½œã‚‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’æ•™ãˆã¦ãã ã•ã„ï¼ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰ã€‚
* B. ä»Šã®ãŠæ‰‹å…ƒã®**submission.csv** ã¨ **train.csv**ï¼ˆã¾ãŸã¯ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼‰ã‚’è¦‹ã¦ã€Œãªãœ0ç‚¹ã‹ã€ã‚’å…·ä½“çš„ã«è¨ºæ–­ã™ã‚‹ã€‚
* C. ç‰¹å¾´é‡è¨­è¨ˆã‚’ä¸€ç·’ã«ã‚„ã‚‹ï¼ˆä»£è¡¨çš„ãªãƒšã‚¢è·é›¢ã‚„è§’åº¦è¨ˆç®—ã‚³ãƒ¼ãƒ‰ã‚’ä½œã‚Šã¾ã™ï¼‰ã€‚
* D. æ™‚ç³»åˆ—NNï¼ˆConv1D/Transformerï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã‚’ä½œã‚‹ï¼ˆGPUä½¿ãˆã‚‹ã“ã¨å‰æã§æ™‚é–“åˆ†è§£èƒ½ã‚„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é•·ã‚’åˆã‚ã›ã¾ã™ï¼‰ã€‚

ã‚„ã‚Œã‚‹ã“ã¨ã¯å¤šã„ã®ã§ã€ã¾ãšã¯ã©ã‚Œã‚’æœ€å„ªå…ˆã«ã—ã¾ã™ã‹ï¼Ÿï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã„ãŸã ã‘ã‚Œã°ã€ã™ãã« `A` ã¾ãŸã¯ `B` ã‚’å®Ÿè¡Œã—ã¦å…·ä½“çš„ã«æ‰‹ã‚’å‹•ã‹ã—ã¾ã™ã€‚ï¼‰

---

å¿…è¦ãªã‚‰ä»Šã™ãï¼ˆã“ã®ãƒãƒ£ãƒƒãƒˆã§ï¼‰ã‚ãªãŸã® `submission.csv` ã®æœ€åˆã® 20 è¡Œã‹ã€`train.csv` ã®ã‚«ãƒ©ãƒ åã¨å…ˆé ­10è¡Œã‚’è²¼ã£ã¦ãã ã•ã„ã€‚ç§ãŒãã®ã¾ã¾èª­ã‚“ã§ãƒ»ä¿®æ­£ã—ã¦ãƒ»å‹•ãã‚³ãƒ¼ãƒ‰ã‚’å‡ºã—ã¾ã™ã€‚

[1]: https://www.kaggle.com/competitions/MABe-mouse-behavior-detection?utm_source=chatgpt.com "MABe Challenge - Social Action Recognition in Mice"
[2]: https://www.kaggle.com/code/yuanbopang/mabe-mouse-behavior-submission-conv1dbilstm?utm_source=chatgpt.com "MABe Mouse Behavior Submission (Conv1DBiLSTM)"
[3]: https://www.thetransmitter.org/machine-learning/competition-seeks-new-algorithms-to-classify-social-behavior-in-animals/?utm_source=chatgpt.com "Competition seeks new algorithms to classify social ..."





Q: C.ã§ãŠé¡˜ã„ã€‚
train.csvã®ä¸€éƒ¨
lab_id,video_id,mouse1_strain,mouse1_color,mouse1_sex,mouse1_id,mouse1_age,mouse1_condition,mouse2_strain,mouse2_color,mouse2_sex,mouse2_id,mouse2_age,mouse2_condition,mouse3_strain,mouse3_color,mouse3_sex,mouse3_id,mouse3_age,mouse3_condition,mouse4_strain,mouse4_color,mouse4_sex,mouse4_id,mouse4_age,mouse4_condition,frames_per_second,video_duration_sec,pix_per_cm_approx,video_width_pix,video_height_pix,arena_width_cm,arena_height_cm,arena_shape,arena_type,body_parts_tracked,behaviors_labeled,tracking_method
AdaptableSnail,44566106,CD-1 (ICR),white,male,10.0,8-12 weeks,wireless device,CD-1 (ICR),white,male,24.0,8-12 weeks,wireless device,CD-1 (ICR),white,male,38.0,8-12 weeks,wireless device,CD-1 (ICR),white,male,51.0,8-12 weeks,wireless device,30.0,615.6,16.0,1228,1068,60.0,60.0,square,familiar,"[""body_center"", ""ear_left"", ""ear_right"", ""headpiece_bottombackleft"", ""headpiece_bottombackright"", ""headpiece_bottomfrontleft"", ""headpiece_bottomfrontright"", ""headpiece_topbackleft"", ""headpiece_topbackright"", ""headpiece_topfrontleft"", ""headpiece_topfrontright"", ""lateral_left"", ""lateral_right"", ""neck"", ""nose"", ""tail_base"", ""tail_midpoint"", ""tail_tip""]","[""mouse1,mouse2,approach"", ""mouse1,mouse2,attack"", ""mouse1,mouse2,avoid"", ""mouse1,mouse2,chase"", ""mouse1,mouse2,chaseattack"", ""mouse1,mouse2,submit"", ""mouse1,mouse3,approach"", ""mouse1,mouse3,attack"", ""mouse1,mouse3,avoid"", ""mouse1,mouse3,chase"", ""mouse1,mouse3,chaseattack"", ""mouse1,mouse3,submit"", ""mouse1,mouse4,approach"", ""mouse1,mouse4,attack"", ""mouse1,mouse4,avoid"", ""mouse1,mouse4,chase"", ""mouse1,mouse4,chaseattack"", ""mouse1,mouse4,submit"", ""mouse1,self,rear"", ""mouse2,mouse1,approach"", ""mouse2,mouse1,attack"", ""mouse2,mouse1,avoid"", ""mouse2,mouse1,chase"", ""mouse2,mouse1,chaseattack"", ""mouse2,mouse1,submit"", ""mouse2,mouse3,approach"", ""mouse2,mouse3,attack"", ""mouse2,mouse3,avoid"", ""mouse2,mouse3,chase"", ""mouse2,mouse3,chaseattack"", ""mouse2,mouse3,submit"", ""mouse2,mouse4,approach"", ""mouse2,mouse4,attack"", ""mouse2,mouse4,avoid"", ""mouse2,mouse4,chase"", ""mouse2,mouse4,chaseattack"", ""mouse2,mouse4,submit"", ""mouse2,self,rear"", ""mouse3,mouse1,approach"", ""mouse3,mouse1,attack"", ""mouse3,mouse1,avoid"", ""mouse3,mouse1,chase"", ""mouse3,mouse1,chaseattack"", ""mouse3,mouse1,submit"", ""mouse3,mouse2,approach"", ""mouse3,mouse2,attack"", ""mouse3,mouse2,avoid"", ""mouse3,mouse2,chase"", ""mouse3,mouse2,chaseattack"", ""mouse3,mouse2,submit"", ""mouse3,mouse4,approach"", ""mouse3,mouse4,attack"", ""mouse3,mouse4,avoid"", ""mouse3,mouse4,chase"", ""mouse3,mouse4,chaseattack"", ""mouse3,mouse4,submit"", ""mouse3,self,rear"", ""mouse4,mouse1,approach"", ""mouse4,mouse1,attack"", ""mouse4,mouse1,avoid"", ""mouse4,mouse1,chase"", ""mouse4,mouse1,chaseattack"", ""mouse4,mouse1,submit"", ""mouse4,mouse2,approach"", ""mouse4,mouse2,attack"", ""mouse4,mouse2,avoid"", ""mouse4,mouse2,chase"", ""mouse4,mouse2,chaseattack"", ""mouse4,mouse2,submit"", ""mouse4,mouse3,approach"", ""mouse4,mouse3,attack"", ""mouse4,mouse3,avoid"", ""mouse4,mouse3,chase"", ""mouse4,mouse3,chaseattack"", ""mouse4,mouse3,submit"", ""mouse4,self,rear""]",DeepLabCut
AdaptableSnail,143861384,CD-1 (ICR),white,male,3.0,8-12 weeks,,CD-1 (ICR),white,male,17.0,8-12 weeks,,CD-1 (ICR),white,male,31.0,8-12 weeks,,CD-1 (ICR),white,male,44.0,8-12 weeks,,25.0,3599.0,9.7,968,608,60.0,60.0,square,familiar,"[""body_center"", ""ear_left"", ""ear_right"", ""lateral_left"", ""lateral_right"", ""neck"", ""nose"", ""tail_base"", ""tail_midpoint"", ""tail_tip""]","[""mouse1,mouse2,approach"", ""mouse1,mouse2,attack"", ""mouse1,mouse2,avoid"", ""mouse1,mouse2,chase"", ""mouse1,mouse2,chaseattack"", ""mouse1,mouse2,submit"", ""mouse1,mouse3,approach"", ""mouse1,mouse3,attack"", ""mouse1,mouse3,avoid"", ""mouse1,mouse3,chase"", ""mouse1,mouse3,chaseattack"", ""mouse1,mouse3,submit"", ""mouse1,mouse4,approach"", ""mouse1,mouse4,attack"", ""mouse1,mouse4,avoid"", ""mouse1,mouse4,chase"", ""mouse1,mouse4,chaseattack"", ""mouse1,mouse4,submit"", ""mouse1,self,rear"", ""mouse2,mouse1,approach"", ""mouse2,mouse1,attack"", ""mouse2,mouse1,avoid"", ""mouse2,mouse1,chase"", ""mouse2,mouse1,chaseattack"", ""mouse2,mouse1,submit"", ""mouse2,mouse3,approach"", ""mouse2,mouse3,attack"", ""mouse2,mouse3,avoid"", ""mouse2,mouse3,chase"", ""mouse2,mouse3,chaseattack"", ""mouse2,mouse3,submit"", ""mouse2,mouse4,approach"", ""mouse2,mouse4,attack"", ""mouse2,mouse4,avoid"", ""mouse2,mouse4,chase"", ""mouse2,mouse4,chaseattack"", ""mouse2,mouse4,submit"", ""mouse2,self,rear"", ""mouse3,mouse1,approach"", ""mouse3,mouse1,attack"", ""mouse3,mouse1,avoid"", ""mouse3,mouse1,chase"", ""mouse3,mouse1,chaseattack"", ""mouse3,mouse1,submit"", ""mouse3,mouse2,approach"", ""mouse3,mouse2,attack"", ""mouse3,mouse2,avoid"", ""mouse3,mouse2,chase"", ""mouse3,mouse2,chaseattack"", ""mouse3,mouse2,submit"", ""mouse3,mouse4,approach"", ""mouse3,mouse4,attack"", ""mouse3,mouse4,avoid"", ""mouse3,mouse4,chase"", ""mouse3,mouse4,chaseattack"", ""mouse3,mouse4,submit"", ""mouse3,self,rear"", ""mouse4,mouse1,approach"", ""mouse4,mouse1,attack"", ""mouse4,mouse1,avoid"", ""mouse4,mouse1,chase"", ""mouse4,mouse1,chaseattack"", ""mouse4,mouse1,submit"", ""mouse4,mouse2,approach"", ""mouse4,mouse2,attack"", ""mouse4,mouse2,avoid"", ""mouse4,mouse2,chase"", ""mouse4,mouse2,chaseattack"", ""mouse4,mouse2,submit"", ""mouse4,mouse3,approach"", ""mouse4,mouse3,attack"", ""mouse4,mouse3,avoid"", ""mouse4,mouse3,chase"", ""mouse4,mouse3,chaseattack"", ""mouse4,mouse3,submit"", ""mouse4,self,rear""]",DeepLabCut
AdaptableSnail,209576908,CD-1 (ICR),white,male,7.0,8-12 weeks,,CD-1 (ICR),white,male,21.0,8-12 weeks,,CD-1 (ICR),white,male,35.0,8-12 weeks,,CD-1 (ICR),white,male,48.0,8-12 weeks,,30.0,615.2,16.0,1266,1100,60.0,60.0,square,familiar,"[""body_center"", ""ear_left"", ""ear_right"", ""lateral_left"", ""lateral_right"", ""neck"", ""nose"", ""tail_base"", ""tail_midpoint"", ""tail_tip""]","[""mouse1,mouse2,approach"", ""mouse1,mouse2,attack"", ""mouse1,mouse2,avoid"", ""mouse1,mouse2,chase"", ""mouse1,mouse2,chaseattack"", ""mouse1,mouse2,submit"", ""mouse1,mouse3,approach"", ""mouse1,mouse3,attack"", ""mouse1,mouse3,avoid"", ""mouse1,mouse3,chase"", ""mouse1,mouse3,chaseattack"", ""mouse1,mouse3,submit"", ""mouse1,mouse4,approach"", ""mouse1,mouse4,attack"", ""mouse1,mouse4,avoid"", ""mouse1,mouse4,chase"", ""mouse1,mouse4,chaseattack"", ""mouse1,mouse4,submit"", ""mouse1,self,rear"", ""mouse2,mouse1,approach"", ""mouse2,mouse1,attack"", ""mouse2,mouse1,avoid"", ""mouse2,mouse1,chase"", ""mouse2,mouse1,chaseattack"", ""mouse2,mouse1,submit"", ""mouse2,mouse3,approach"", ""mouse2,mouse3,attack"", ""mouse2,mouse3,avoid"", ""mouse2,mouse3,chase"", ""mouse2,mouse3,chaseattack"", ""mouse2,mouse3,submit"", ""mouse2,mouse4,approach"", ""mouse2,mouse4,attack"", ""mouse2,mouse4,avoid"", ""mouse2,mouse4,chase"", ""mouse2,mouse4,chaseattack"", ""mouse2,mouse4,submit"", ""mouse2,self,rear"", ""mouse3,mouse1,approach"", ""mouse3,mouse1,attack"", ""mouse3,mouse1,avoid"", ""mouse3,mouse1,chase"", ""mouse3,mouse1,chaseattack"", ""mouse3,mouse1,submit"", ""mouse3,mouse2,approach"", ""mouse3,mouse2,attack"", ""mouse3,mouse2,avoid"", ""mouse3,mouse2,chase"", ""mouse3,mouse2,chaseattack"", ""mouse3,mouse2,submit"", ""mouse3,mouse4,approach"", ""mouse3,mouse4,attack"", ""mouse3,mouse4,avoid"", ""mouse3,mouse4,chase"", ""mouse3,mouse4,chaseattack"", ""mouse3,mouse4,submit"", ""mouse3,self,rear"", ""mouse4,mouse1,approach"", ""mouse4,mouse1,attack"", ""mouse4,mouse1,avoid"", ""mouse4,mouse1,chase"", ""mouse4,mouse1,chaseattack"", ""mouse4,mouse1,submit"", ""mouse4,mouse2,approach"", ""mouse4,mouse2,attack"", ""mouse4,mouse2,avoid"", ""mouse4,mouse2,chase"", ""mouse4,mouse2,chaseattack"", ""mouse4,mouse2,submit"", ""mouse4,mouse3,approach"", ""mouse4,mouse3,attack"", ""mouse4,mouse3,avoid"", ""mouse4,mouse3,chase"", ""mouse4,mouse3,chaseattack"", ""mouse4,mouse3,submit"", ""mouse4,self,rear""]",DeepLabCut
annotation.csvã®ä¸€éƒ¨
,agent_id,target_id,action,start_frame,stop_frame
0,2,2,rear,4,139
1,4,2,avoid,13,52
2,4,4,rear,121,172
3,3,3,rear,156,213
4,4,4,rear,208,261
tracking.csvã®ä¸€éƒ¨
,video_frame,mouse_id,bodypart,x,y
0,0,1,body_center,1161.544,523.113
1,0,1,ear_right,1146.305,587.62
2,0,1,headpiece_bottomfrontright,1163.192,588.58
3,0,1,headpiece_topbackright,1192.211,558.435
4,0,1,headpiece_topfrontleft,1191.344,620.626
5,0,1,headpiece_topfrontright,1164.946,599.407
6,0,1,lateral_left,1182.459,499.797
7,0,1,lateral_right,1131.587,526.543
8,0,1,tail_base,1142.07,478.728
9,0,1,tail_midpoint,1110.596,413.751
A: ã„ã„ã­ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚
ã“ã®3ã¤ï¼ˆ`train.csv` / `annotation.csv` / `tracking.csv`ï¼‰ã®æ§‹é€ ãŒè¦‹ãˆã¦ããŸã®ã§ã€
ã‚¹ã‚³ã‚¢0ã ã£ãŸç†ç”±ã‚’è¸ã¾ãˆã¦ã€Œ**æœ€åˆã‹ã‚‰ã®å†è¨­è¨ˆ**ã€ã‚’ä¸€ç·’ã«ã‚„ã‚Šã¾ã—ã‚‡ã†ã€‚

---

## ğŸ¯ ç›®çš„ï¼ˆå†ç¢ºèªï¼‰

Kaggleã®ã“ã®èª²é¡Œï¼ˆãƒã‚¦ã‚¹è¡Œå‹•è­˜åˆ¥ï¼‰ã¯ï¼š

> å„ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ãŸã¯ä¸€å®šåŒºé–“ã«ãŠã‘ã‚‹ãƒã‚¦ã‚¹ã®**è¡Œå‹•ï¼ˆapproach, avoid, chase, rearãªã©ï¼‰ã‚’åˆ†é¡ã™ã‚‹**ã‚¿ã‚¹ã‚¯ã€‚

---

## ğŸ§© ãƒ‡ãƒ¼ã‚¿ã®é–¢ä¿‚æ§‹é€ 

| ãƒ•ã‚¡ã‚¤ãƒ«             | å†…å®¹                        | ä¸»ãªã‚­ãƒ¼                                     |
| ---------------- | ------------------------- | ---------------------------------------- |
| `train.csv`      | å„å‹•ç”»ã®ãƒ¡ã‚¿æƒ…å ±                  | `video_id`                               |
| `annotation.csv` | å„å‹•ç”»å†…ã®ã€Œè¡Œå‹•ãƒ©ãƒ™ãƒ«ã€åŒºé–“ï¼ˆé–‹å§‹ã€œçµ‚äº†ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ | `video_id`ï¼ˆæš—é»™çš„ï¼‰ï¼‹`agent_id`,`target_id`   |
| `tracking.csv`   | å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒã‚¦ã‚¹åº§æ¨™ï¼ˆbodypartå˜ä½ï¼‰   | `video_id`ï¼ˆæš—é»™çš„ï¼‰ï¼‹`video_frame`ï¼‹`mouse_id` |

---

## ğŸ§  ã‚¹ã‚³ã‚¢0ã«ãªã‚‹å…¸å‹çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç¢ºèªï¼‰

1. **å‡ºåŠ›ã®å½¢å¼ãŒé–“é•ã£ã¦ã„ãŸ**

   * Kaggleã§ã¯å¤šãã®å ´åˆã€`submission.csv`ã®åˆ—åãƒ»å‹ãŒå³å¯†ã«å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
   * ãŸã¨ãˆã° `id, behavior` ã‚„ `video_id, start_frame, stop_frame, action` ã®ã‚ˆã†ãªå½¢å¼ã€‚

2. **å‹•ç”»IDã®å¯¾å¿œã‚’é–“é•ãˆãŸ**

   * `annotation.csv` ã¯è¤‡æ•°å‹•ç”»ã‚’ã¾ã¨ã‚ã¦ã„ã‚‹ãŸã‚ã€
     `tracking.csv` ã¨ video_idã§ãƒãƒ¼ã‚¸ã—ãªã„ã¨ã€åˆ¥å‹•ç”»ã®è¡Œå‹•ã‚’æ··ãœã¦ã—ã¾ã†ã€‚

3. **å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã€Œè¡Œå‹•ãªã—ã€æ‰±ã„**

   * `annotation` ãŒæŒ‡å®šåŒºé–“ã®ã¿è¡Œå‹•ãƒ©ãƒ™ãƒ«ã‚’æŒã¤ãŸã‚ã€ä»–ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã€Œ0ã€æ‰±ã„ã«ã—ã¦å­¦ç¿’ã™ã‚‹ã¨ã€
     ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒæ¿€ã—ãã€ãƒ¢ãƒ‡ãƒ«ãŒå…¨éƒ¨ã€Œãªã—ã€ã¨äºˆæ¸¬ã—ã¦ã‚¹ã‚³ã‚¢0ã€‚

---

## âœ… æ”¹å–„æ–¹é‡ï¼ˆå†è¨­è¨ˆCï¼‰

æœ€åˆã‹ã‚‰æ®µéšçš„ã«è¨­è¨ˆã—ç›´ã—ã¾ã™ã€‚
ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¸ã‚ã°ã€å …å®Ÿã«ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã‚‰ã‚Œã¾ã™ã€‚

---

### **Step 1. ç‰¹å¾´é‡æŠ½å‡ºè¨­è¨ˆ**

`tracking.csv` ã®ä½ç½®æƒ…å ±ã‚’æ™‚ç³»åˆ—ç‰¹å¾´é‡ã«å¤‰æ›ã™ã‚‹ã€‚
æœ€åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œè·é›¢ãƒ»é€Ÿåº¦ãƒ»å‘ãã€ãªã©ã«çµã‚‹ã€‚

#### å„ `video_id`, `mouse_id`, `video_frame` ã”ã¨ã«ï¼š

* å„ãƒã‚¦ã‚¹ã®ä½ç½® `(x_body_center, y_body_center)`
* å„bodypartã‹ã‚‰ã€Œé‡å¿ƒã€ã‚„ã€Œé ­ã®å‘ãã€ã‚’æ¨å®š
* é€Ÿåº¦: `v = sqrt((x_t - x_{t-1})^2 + (y_t - y_{t-1})^2)`
* å„ãƒšã‚¢ã®è·é›¢: `dist(mouse_i, mouse_j)`
* æ¥è¿‘é€Ÿåº¦: `delta_dist / delta_t`

ã“ã‚Œã‚’1ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§ã¾ã¨ã‚ã€æœ€çµ‚çš„ã«ï¼š

| video_id | frame | mouse_id | dist_to_others_mean | speed | heading | ... |

---

### **Step 2. ãƒ©ãƒ™ãƒ«æ•´å½¢**

`annotation.csv` ã‹ã‚‰å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡Œå‹•ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã€‚

```python
# å„video_id, agent_id ã«å¯¾ã—ã¦
for each row in annotation:
    for frame in range(start_frame, stop_frame):
        label[video_id, agent_id, frame] = action
```

ã“ã‚Œã§ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãŒå®Œæˆã—ã¾ã™ã€‚

---

### **Step 3. ãƒ‡ãƒ¼ã‚¿çµåˆ**

`tracking_features` ã¨ `frame_labels` ã‚’ `video_id` & `frame` & `mouse_id` ã§ãƒãƒ¼ã‚¸ã€‚

---

### **Step 4. ãƒ¢ãƒ‡ãƒªãƒ³ã‚°**

æœ€åˆã¯ã“ã®ã‚ˆã†ã«æ§‹æˆã™ã‚‹ã®ãŒå®‰å®šï¼š

* **ãƒ¢ãƒ‡ãƒ«**: `XGBoost` or `LightGBM`
* **å…¥åŠ›ç‰¹å¾´é‡**: é€Ÿåº¦ãƒ»ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ãƒ»ç§»å‹•æ–¹å‘
* **å‡ºåŠ›ãƒ©ãƒ™ãƒ«**: è¡Œå‹•ï¼ˆapproach / avoid / chase / submit / rear ãªã©ï¼‰

---

### **Step 5. è©•ä¾¡æ–¹æ³•**

`annotation.csv` ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹è¡Œå‹•ãƒ©ãƒ™ãƒ«å˜ä½ã§F1ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ã€‚
Kaggleã®æ¡ç‚¹åŸºæº–ã¨åˆã‚ã›ã‚‹ãŸã‚ã«ã€å…¬å¼notebookã®`compute_score`é–¢æ•°ãŒã‚ã‚Œã°å‚è€ƒã«ã€‚

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ

ã“ã“ã‹ã‚‰å§‹ã‚ã‚‹ã¨è‰¯ã„ã§ã™ğŸ‘‡

1. **`tracking.csv` ã‹ã‚‰ç‰¹å¾´é‡æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ**ã‚’ä½œã‚‹

   * å„ãƒã‚¦ã‚¹ã”ã¨ã®ä½ç½®ã€é€Ÿåº¦ã€ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢
2. **`annotation.csv` ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ©ãƒ™ãƒ«åŒ–**
3. **ã“ã‚Œã‚‰ã‚’çµåˆã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹**

---

ã‚‚ã—ã‚ˆã‘ã‚Œã°ã€æ¬¡ã®ã‚ˆã†ã«é€²ã‚ã¾ã—ã‚‡ã†ğŸ‘‡
**æ¬¡ã«ã‚„ã‚‹ã“ã¨**ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š

A. `tracking.csv` â†’ ç‰¹å¾´é‡æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚‹
B. `annotation.csv` â†’ ãƒ©ãƒ™ãƒ«æ•´å½¢ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ï¼‰
C. Aã¨Bã‚’çµåˆã—ã¦å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹

ã©ã“ã‹ã‚‰ä½œã‚ŠãŸã„ï¼Ÿ





Q: C.ã§
A: äº†è§£ã€Cï¼ˆç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã‚’çµåˆã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ï¼‰ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚
ãã®ãŸã‚ã«ã€ä»¥ä¸‹ã®å‰æã‚’ç¢ºèªã•ã›ã¦ãã ã•ã„ğŸ‘‡

---

## ğŸ” å‰æç¢ºèª

| é …ç›®     | çŠ¶æ³                                | å‚™è€ƒ                                                           |
| ------ | --------------------------------- | ------------------------------------------------------------ |
| ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ | ã™ã§ã« `tracking.csv` ã‹ã‚‰æŠ½å‡ºæ¸ˆã¿ï¼Ÿ        | ä¾‹: å„ `video_id, mouse_id, frame` ã”ã¨ã® speed, dist_to_other ãªã© |
| ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ | `annotation.csv` ã‹ã‚‰ frameå˜ä½ã«å±•é–‹æ¸ˆã¿ï¼Ÿ | ä¾‹: å„ `video_id, agent_id, frame` ã”ã¨ã® action                  |

---

ã“ã®2ã¤ãŒã™ã§ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦ä½œæˆæ¸ˆã¿ãªã‚‰ã€
ã‚ã¨ã¯ãã‚Œã‚‰ã‚’æ­£ã—ããƒãƒ¼ã‚¸ã™ã‚‹ã ã‘ã§ã€å­¦ç¿’ç”¨ã® `train_df` ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚

---

## ğŸ§  C. ç‰¹å¾´é‡ï¼‹ãƒ©ãƒ™ãƒ«çµåˆã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹

ä¸‹è¨˜ã¯ã€å…¸å‹çš„ãªã€Œç‰¹å¾´é‡dfã€ã¨ã€Œãƒ©ãƒ™ãƒ«dfã€ã‚’çµåˆã—ã¦
å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ä¾‹ã§ã™ğŸ‘‡

```python
import pandas as pd

# --- ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ ---
# tracking_features.csv: å„video_id, mouse_id, frameã”ã¨ã®é€Ÿåº¦ã‚„è·é›¢ãªã©
features = pd.read_csv("tracking_features.csv")

# --- ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ ---
# annotation_frames.csv: å„video_id, agent_id, frameã”ã¨ã®è¡Œå‹•(action)
labels = pd.read_csv("annotation_frames.csv")

# --- çµåˆ ---
# mouse_id ã¨ agent_id ãŒåŒã˜æ¦‚å¿µãªã‚‰ã€åˆ—åã‚’çµ±ä¸€
labels = labels.rename(columns={"agent_id": "mouse_id"})

# video_id, frame, mouse_id ã§çµåˆ
train_df = pd.merge(
    features,
    labels,
    how="left",  # è¡Œå‹•ãŒãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚ä¿æŒ
    on=["video_id", "frame", "mouse_id"]
)

# æ¬ æï¼ˆè¡Œå‹•ãŒãªã„ï¼‰éƒ¨åˆ†ã¯ã€Œnoneã€ãªã©ã«è£œå®Œ
train_df["action"] = train_df["action"].fillna("none")

# --- å‡ºåŠ› ---
train_df.to_csv("train_dataset.csv", index=False)
print("âœ… train_dataset.csv ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚")
print(train_df.head())
```

---

## ğŸ§© ã“ã†ã—ã¦å¾—ã‚‰ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

| video_id  | frame | mouse_id | speed | dist_mean | heading | ... | action |
| --------- | ----- | -------- | ----- | --------- | ------- | --- | ------ |
| video_001 | 100   | 0        | 12.3  | 56.7      | 45.2    | ... | chase  |
| video_001 | 101   | 0        | 11.8  | 55.9      | 44.9    | ... | chase  |
| video_001 | 102   | 0        | 8.2   | 52.0      | 41.0    | ... | none   |

ã“ã®å½¢å¼ã«ã™ã‚Œã°ã€ãã®ã¾ã¾
`X, y = train_df.drop("action", axis=1), train_df["action"]`
ã§ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å¯èƒ½ã§ã™ã€‚

---

## ğŸ’¡ æ¬¡ã«ã‚„ã‚‹ã“ã¨ï¼ˆé¸æŠï¼‰

ã“ã®çµåˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‹•ã‹ã™ãŸã‚ã«ã€ä»¥ä¸‹ã®ã©ã‚Œã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã®ãŒè‰¯ã„ï¼Ÿ

A. ã¾ã ç‰¹å¾´é‡ (`tracking_features.csv`) ãŒãªã„ã®ã§ã€ãã‚Œã‚’ä½œã‚‹ã¨ã“ã‚ã‹ã‚‰å§‹ã‚ãŸã„
B. ã¾ã ãƒ©ãƒ™ãƒ« (`annotation_frames.csv`) ãŒãªã„ã®ã§ã€frameå˜ä½ã«å±•é–‹ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚ŠãŸã„
C. ã©ã¡ã‚‰ã‚‚ã™ã§ã«ã‚ã‚‹ã®ã§ã€ä¸Šã®çµåˆã‚³ãƒ¼ãƒ‰ã‚’æœ€çµ‚çš„ãªå½¢ã«æ•´å‚™ã—ã¦ã»ã—ã„

ã©ã‚Œã«ã™ã‚‹ï¼Ÿ





Q: C.ã§
A: å®Œç’§ ğŸ‘
ã§ã¯ã€Œç‰¹å¾´é‡ï¼ˆ`tracking_features.csv`ï¼‰ã€ã¨ã€Œãƒ©ãƒ™ãƒ«ï¼ˆ`annotation_frames.csv`ï¼‰ã€ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å‰æã§ã€
æœ€çµ‚çš„ãª**å­¦ç¿’ãƒ‡ãƒ¼ã‚¿çµåˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ**ã‚’å®Œæˆç‰ˆã¨ã—ã¦æç¤ºã—ã¾ã™ã€‚

---

## ğŸ§  æœ€çµ‚ç‰ˆï¼šç‰¹å¾´é‡ï¼‹ãƒ©ãƒ™ãƒ«çµåˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
import pandas as pd
from pathlib import Path

# === ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ===
# å¿…è¦ã«å¿œã˜ã¦ãƒ‘ã‚¹ã‚’èª¿æ•´
feature_path = Path("tracking_features.csv")
label_path   = Path("annotation_frames.csv")
output_path  = Path("train_dataset.csv")

# ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
features = pd.read_csv(feature_path)
print(f"âœ… features èª­ã¿è¾¼ã¿å®Œäº†: {features.shape}")

# ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿
labels = pd.read_csv(label_path)
print(f"âœ… labels èª­ã¿è¾¼ã¿å®Œäº†: {labels.shape}")

# === å‰å‡¦ç† ===

# ã‚‚ã—åˆ—åãŒç•°ãªã‚‹å ´åˆï¼ˆä¾‹: agent_id ã¨ mouse_idï¼‰
if "agent_id" in labels.columns and "mouse_id" not in labels.columns:
    labels = labels.rename(columns={"agent_id": "mouse_id"})

# frameåˆ—ã®è¡¨è¨˜æºã‚Œå¯¾å¿œ
for df in (features, labels):
    if "video_frame" in df.columns and "frame" not in df.columns:
        df.rename(columns={"video_frame": "frame"}, inplace=True)

# === çµåˆ ===
key_cols = ["video_id", "frame", "mouse_id"]

# ã¾ãšã€ã‚­ãƒ¼ãŒæƒã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
for col in key_cols:
    if col not in features.columns or col not in labels.columns:
        raise ValueError(f"âŒ ã‚­ãƒ¼åˆ— {col} ãŒç‰‡æ–¹ã®DataFrameã«å­˜åœ¨ã—ã¾ã›ã‚“")

# å·¦çµåˆã§å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ä¿æŒ
train_df = pd.merge(
    features,
    labels,
    how="left",
    on=key_cols
)

# è¡Œå‹•ãªã—ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ "none" ã«è£œå®Œ
train_df["action"] = train_df["action"].fillna("none")

# === æ•´å½¢ ===
# actionåˆ—ã‚’æœ€å¾Œã«
cols = [c for c in train_df.columns if c != "action"] + ["action"]
train_df = train_df[cols]

# === å‡ºåŠ› ===
train_df.to_csv(output_path, index=False)
print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›å®Œäº†: {output_path} ({train_df.shape})")

# ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
print(train_df.sample(5, random_state=42))
```

---

## ğŸ§© å‡ºåŠ›ã‚¤ãƒ¡ãƒ¼ã‚¸

| video_id | frame | mouse_id | speed | dist_to_others | heading | ... | action |
| -------- | ----- | -------- | ----- | -------------- | ------- | --- | ------ |
| 001      | 200   | 0        | 12.5  | 48.2           | 130.5   | ... | chase  |
| 001      | 201   | 0        | 11.8  | 47.9           | 129.1   | ... | chase  |
| 001      | 202   | 1        | 10.1  | 30.4           | 245.0   | ... | none   |

---

## âœ… ã“ã®å½¢å¼ã®ãƒ¡ãƒªãƒƒãƒˆ

* XGBoost / LightGBM / CatBoost ãªã©ã«ãã®ã¾ã¾ä½¿ãˆã‚‹
* å‹•ç”»å˜ä½ã§å­¦ç¿’ãƒ»æ¤œè¨¼åˆ†å‰²ã—ã‚„ã™ã„
* ã€Œnoneã€ã‚‚å«ã‚ãŸå¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã¨ã—ã¦æ‰±ãˆã‚‹

---

## ğŸ”œ æ¬¡ã®ãŠã™ã™ã‚ã‚¹ãƒ†ãƒƒãƒ—

ã“ã® `train_dataset.csv` ãŒã§ããŸã‚‰ã€æ¬¡ã®2ã¤ã®æ–¹å‘ã«é€²ã‚ã¾ã™ï¼š

1. **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼**

   * `train_df["action"].value_counts()` ã§ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’ç¢ºèª
   * ç‰¹å¾´é‡ã®æ¬ æã‚„ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯

2. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰**

   * XGBoost ã§ç°¡å˜ã«å‹•ãåˆ†é¡å™¨ã‚’ä½œã£ã¦ã‚¹ã‚³ã‚¢ç¢ºèª
   * å¾Œã§æ™‚ç³»åˆ—ç‰¹å¾´ã‚’è¿½åŠ ã™ã‚‹

---

æ¬¡ã€ã©ã¡ã‚‰ã«é€²ã‚ã‚‹ï¼Ÿ
A. ãƒ©ãƒ™ãƒ«åˆ†å¸ƒãªã©å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
B. XGBoostã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰





Q: ä»Šå›ã€æç¤ºã—ãŸã®ã¯actionã‚’æ±‚ã‚ã‚‹ãŸã‚ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã£ã¦ã“ã¨ã‹ãª?
A: ãã†ã€ãã®ç†è§£ã§å®Œå…¨ã«æ­£è§£ã§ã™ âœ…

ä»Šå›æç¤ºã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ä½œã‚‹ **`train_dataset.csv`** ã¯ã€
Kaggleã®ã€Œãƒã‚¦ã‚¹è¡Œå‹•è­˜åˆ¥ã€ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ **`actionï¼ˆè¡Œå‹•ãƒ©ãƒ™ãƒ«ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿`** ã§ã™ã€‚

---

## ğŸ§© ã‚‚ã†å°‘ã—å…·ä½“çš„ã«ã„ã†ã¨

ã“ã® `train_dataset.csv` ã¯ä»¥ä¸‹ã®2ã¤ã®æƒ…å ±ã‚’çµ±åˆã—ã¦ã„ã¾ã™ï¼š

| å…ƒãƒ‡ãƒ¼ã‚¿                    | å†…å®¹                                       | çµæœã§ã®å½¹å‰²        |
| ----------------------- | ---------------------------------------- | ------------- |
| `tracking_features.csv` | å„ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®ãƒã‚¦ã‚¹ã®å‹•ãï¼ˆé€Ÿåº¦ãƒ»æ–¹å‘ãƒ»è·é›¢ãªã©ï¼‰                | ãƒ¢ãƒ‡ãƒ«ã®**å…¥åŠ›ï¼ˆXï¼‰** |
| `annotation_frames.csv` | å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ­£è§£è¡Œå‹•ãƒ©ãƒ™ãƒ«ï¼ˆapproach, chase, rear, ãªã©ï¼‰ | ãƒ¢ãƒ‡ãƒ«ã®**å‡ºåŠ›ï¼ˆyï¼‰** |

---

### ğŸ”¸ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ã‚¤ãƒ¡ãƒ¼ã‚¸

```python
# train_dataset.csv ã®èª­ã¿è¾¼ã¿
train_df = pd.read_csv("train_dataset.csv")

# ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã«åˆ†å‰²
X = train_df.drop(columns=["action"])
y = train_df["action"]

# ä¾‹: XGBoostã§åˆ†é¡å™¨ã‚’å­¦ç¿’
from xgboost import XGBClassifier

model = XGBClassifier(
    objective="multi:softprob",
    eval_metric="mlogloss",
    num_class=y.nunique(),
    n_estimators=200,
    learning_rate=0.1,
    max_depth=6
)
model.fit(X, y)
```

ã“ã®ã‚ˆã†ã«ã€ãƒã‚¦ã‚¹ã®ã€Œé€Ÿåº¦ãƒ»è·é›¢ãƒ»æ–¹å‘ãªã©ã€ã‹ã‚‰ã€Œè¡Œå‹•(action)ã€ã‚’å­¦ç¿’ã™ã‚‹ã‚ã‘ã§ã™ã€‚
æœ€çµ‚çš„ã«ã¯ã€æœªçŸ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆ`test`å´ã®ç‰¹å¾´é‡ï¼‰ã«å¯¾ã—ã¦ `model.predict()` ã‚’ä½¿ã£ã¦è¡Œå‹•ã‚’æ¨å®šã—ã¾ã™ã€‚

---

## ğŸ§­ ã¾ã¨ã‚ã‚‹ã¨

| é …ç›®                       | å†…å®¹                                                 |
| ------------------------ | -------------------------------------------------- |
| ä½œæˆã—ãŸ `train_dataset.csv` | è¡Œå‹•è­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿                                     |
| å…¥åŠ› (X)                   | trackingã®å‹•ä½œç‰¹å¾´ï¼ˆspeed, distance, etc.ï¼‰               |
| å‡ºåŠ› (y)                   | annotationã«åŸºã¥ãè¡Œå‹•ãƒ©ãƒ™ãƒ« (`action`)                     |
| ç›®çš„                       | ãƒã‚¦ã‚¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½è¡Œå‹•ã‚’åˆ†é¡ï¼ˆapproach / chase / rear / none ãªã©ï¼‰ |

---

ã‚‚ã—OKãªã‚‰ã€ã“ã®æ¬¡ã¯
âœ…ã€Œ`train_dataset.csv`ã‚’å®Ÿéš›ã«ä½¿ã£ã¦XGBoostã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€
ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã¿ã¾ã—ã‚‡ã†ã‹ï¼Ÿ





Q: actionã ã‘æ±‚ã‚ã‚‹ã®ãªã‚‰ã€ãã‚Œã»ã©é›£ã—ã„ã¨ã¯æ€ã£ã¦ãªãã¦ã€actionã‚’èµ·ã“ã—ã¦ã„ã‚‹ãƒã‚¦ã‚¹ã®action_idã¨ãã®å¯¾è±¡ã®target_idã‚’ãƒšã‚¢ãƒªãƒ³ã‚°ã—ã¦ã€çŸ›ç›¾ã™ã‚‹ã“ã¨ãªãæ±‚ã‚ã‚‹ã“ã¨ã ã¨æ€ã£ã¦ã„ã‚‹ã€‚
è²¼ã‚Šå¿˜ã‚Œã¦ã„ãŸsubmissionã®å†…å®¹ã‚‚è²¼ã‚Šä»˜ã‘ã¦ãŠãã€‚
submission.csvã®ä¸€éƒ¨
row_id,video_id,agent_id,target_id,action,start_frame,stop_frame
0,438887472,4,2,attack,0,622
1,438887472,3,1,attack,7,1372
2,438887472,4,2,attack,697,990
3,438887472,1,2,attack,810,6472
A: ãªã‚‹ã»ã©ã€éå¸¸ã«é‹­ã„è¦³ç‚¹ã§ã™ã€‚
ã‚ãªãŸã®ç†è§£ã¯ã“ã®ã‚³ãƒ³ãƒšï¼ˆï¼ãƒã‚¦ã‚¹ã®**è¡Œå‹•è­˜åˆ¥**èª²é¡Œï¼‰ã®**æœ¬è³ª**ã‚’çªã„ã¦ã„ã¾ã™ã€‚

---

## ğŸ§© ã‚ãªãŸã®æ•´ç†ã®é€šã‚Š

ã“ã®èª²é¡Œã§ã¯å˜ã«

> ã€Œã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã©ã‚“ãªè¡Œå‹•ï¼ˆactionï¼‰ãŒèµ·ãã¦ã„ã‚‹ã‹ã€
> ã‚’å½“ã¦ã‚‹ã ã‘ã§ã¯ãªãã€

> ã€Œ**èª°ï¼ˆagent_idï¼‰ãŒèª°ï¼ˆtarget_idï¼‰ã«å¯¾ã—ã¦è¡Œå‹•ã—ãŸã®ã‹**ã€
> ã‚’çŸ›ç›¾ãªãä¸€è²«ã—ãŸå½¢ã§å‡ºåŠ›ã™ã‚‹

â”€â”€ã“ã‚ŒãŒæœ€çµ‚ã‚´ãƒ¼ãƒ«ã§ã™ã€‚
ã—ãŸãŒã£ã¦ã€**actionåˆ†é¡ + ãƒšã‚¢ãƒªãƒ³ã‚°ã®æ•´åˆæ€§** ã®ä¸¡ç«‹ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚

---

## ğŸ§  ãƒ‡ãƒ¼ã‚¿ã¨submissionã®é–¢ä¿‚ï¼ˆæ­£ã—ã„ç†è§£ï¼‰

| é …ç›®               | å½¹å‰²                                                             | ã‚³ãƒ¡ãƒ³ãƒˆ                    |
| ---------------- | -------------------------------------------------------------- | ----------------------- |
| `tracking.csv`   | å„ãƒã‚¦ã‚¹ã®åº§æ¨™ãƒ‡ãƒ¼ã‚¿                                                     | agent/targetè­˜åˆ¥ã®ãŸã‚ã®å…¥åŠ›ç‰¹å¾´é‡ |
| `annotation.csv` | æ­£è§£ã®è¡Œå‹•ãƒ©ãƒ™ãƒ«ï¼ˆagent_id, target_id, start_frame, stop_frame, actionï¼‰ | å­¦ç¿’ãƒ©ãƒ™ãƒ«ã®ã‚½ãƒ¼ã‚¹               |
| `submission.csv` | äºˆæ¸¬å‡ºåŠ›ï¼ˆä¸Šã¨åŒå½¢å¼ï¼‰                                                    | Kaggleã§ã‚¹ã‚³ã‚¢ç®—å‡ºã«ä½¿ã‚ã‚Œã‚‹       |

---

## ğŸ§  ã€Œã‚¹ã‚³ã‚¢0ã€ã«ãªã£ãŸç†ç”±ï¼ˆã»ã¼ç¢ºå®Ÿãªæ¨æ¸¬ï¼‰

`submission.csv` ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè‡ªä½“ã¯åˆã£ã¦ã„ã¦ã‚‚ã€
Kaggleã®è©•ä¾¡é–¢æ•°ï¼ˆå¤šãã®å ´åˆ **IoUãƒ™ãƒ¼ã‚¹ or åŒºé–“F1ã‚¹ã‚³ã‚¢**ï¼‰ãŒ
**ã€Œæ­£ã—ã„ãƒšã‚¢ï¼ˆagent_id, target_idï¼‰ã€ã§è¡Œå‹•åŒºé–“ãŒé‡ãªã£ã¦ã„ã‚‹ã‹**ã‚’è¦‹ã¦ã„ã‚‹ãŸã‚ã€
ä¾‹ãˆã°ä»¥ä¸‹ã®ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã§ã‚¹ã‚³ã‚¢ãŒã‚¼ãƒ­ã«ãªã‚Šã¾ã™ï¼š

| åŸå›                             | ä¾‹                                           |
| ----------------------------- | ------------------------------------------- |
| è¡Œå‹•åŒºé–“ãŒå…¨ãä¸€è‡´ã—ã¦ã„ãªã„                | start_frame, stop_frame ãŒãšã‚Œã¦ã„ã‚‹              |
| agent_id, target_id ã®çµ„ãŒé–“é•ã£ã¦ã„ã‚‹ | 1â†’2 ã§ã¯ãªã 2â†’1 ãªã©                             |
| ã™ã¹ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã€Œnoneã€æ‰±ã„ã§å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹     | ã¤ã¾ã‚Šã€ä½•ã‚‚è¡Œå‹•ã‚’å‡ºåŠ›ã—ã¦ã„ãªã„                            |
| video_id ãŒç•°ãªã‚‹                 | 438887472 vs "video_438887472" ã®ã‚ˆã†ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé•ã„ |

---

## âš™ï¸ ã‚ãªãŸã®è¨€ã†ã€ŒçŸ›ç›¾ã®ãªã„ãƒšã‚¢ãƒªãƒ³ã‚°ã€ã¨ã¯

éå¸¸ã«é‡è¦ãªç™ºæƒ³ã§ã€
è¦ã™ã‚‹ã«ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã“ã†ãªã‚Šã¾ã™ğŸ‘‡

> **è¡Œå‹•(action)ã‚’æ¨å®š**ã—ãŸã†ãˆã§ã€
> **èª°ï¼ˆagentï¼‰ãŒèª°ï¼ˆtargetï¼‰ã«å¯¾ã—ã¦ãã‚Œã‚’ã—ãŸã‹**ã‚’æ±ºã‚ã‚‹ã€‚

### ã¤ã¾ã‚Š3æ®µéšæ§‹æˆï¼š

1. **Step 1:** å„ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ç‰¹å¾´é‡ï¼ˆtrackingï¼‰ã‹ã‚‰ã€Œè¡Œå‹•ã®æœ‰ç„¡ï¼ç¨®é¡ã€ã‚’äºˆæ¸¬
2. **Step 2:** è¡Œå‹•ãŒèµ·ãã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã€ã€Œæœ€ã‚‚è¿‘ã„ or é©åˆ‡ãªå¯¾è±¡ï¼ˆtargetï¼‰ã€ã‚’æ¨å®š
3. **Step 3:** é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŒºé–“ï¼ˆstart_frameã€œstop_frameï¼‰ã«ã¾ã¨ã‚ã€submissionå½¢å¼ã«å¤‰æ›

---

## ğŸ§© ä¾‹ â€” æœ€çµ‚çš„ã«å‡ºã™ã¹ãsubmissionã®è€ƒãˆæ–¹

ã‚ãªãŸãŒè²¼ã£ã¦ãã‚ŒãŸå†…å®¹ï¼ˆæ­£ã—ã„æ§‹é€ ï¼‰ï¼š

| row_id | video_id  | agent_id | target_id | action | start_frame | stop_frame |
| ------ | --------- | -------- | --------- | ------ | ----------- | ---------- |
| 0      | 438887472 | 4        | 2         | attack | 0           | 622        |
| 1      | 438887472 | 3        | 1         | attack | 7           | 1372       |
| 2      | 438887472 | 4        | 2         | attack | 697         | 990        |
| 3      | 438887472 | 1        | 2         | attack | 810         | 6472       |

ã“ã‚Œã‚’**å†ç¾ã™ã‚‹ã«ã¯ï¼š**

* å„ãƒ•ãƒ¬ãƒ¼ãƒ ã§ `action` ã‚’äºˆæ¸¬ã—ã€
* åŒæ™‚ã« `agent_id` ã‚’æ—¢çŸ¥ï¼ˆã¾ãŸã¯å›ºå®šï¼‰ã¨ã—ã¦ã€
* ãã®ã¨ãæœ€ã‚‚è·é›¢ãŒè¿‘ã„ `target_id` ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚
* é€£ç¶šã—ã¦åŒã˜ `agent_id, target_id, action` ãŒç¶šãåŒºé–“ã‚’ã¾ã¨ã‚ã‚‹ã€‚

---

## ğŸ’¡ ä»Šå¾Œã®æ§‹æˆãƒ—ãƒ©ãƒ³ï¼ˆå…¨ä½“åƒï¼‰

| ã‚¹ãƒ†ãƒƒãƒ— | å†…å®¹                          | å‡ºåŠ›                      |
| ---- | --------------------------- | ----------------------- |
| â‘     | tracking â†’ ç‰¹å¾´é‡ç”Ÿæˆï¼ˆé€Ÿåº¦ãƒ»è·é›¢ãƒ»å‘ãï¼‰  | `tracking_features.csv` |
| â‘¡    | annotation â†’ frameå˜ä½ãƒ©ãƒ™ãƒ«åŒ–    | `annotation_frames.csv` |
| â‘¢    | A+Bã‚’çµåˆï¼ˆè¡Œå‹•åˆ†é¡ç”¨ãƒ‡ãƒ¼ã‚¿ï¼‰            | `train_dataset.csv`     |
| â‘£    | ãƒ¢ãƒ‡ãƒ«ã§ `action` ã‚’äºˆæ¸¬ï¼ˆå„agentå˜ä½ï¼‰ | ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½actionæ¨å®š          |
| â‘¤    | å„ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã€Œæœ€ã‚‚è¿‘ã„target_idã€ã‚’ãƒšã‚¢ãƒªãƒ³ã‚° | agent-targetãƒšã‚¢æ±ºå®š        |
| â‘¥    | é€£ç¶šåŒºé–“ã‚’start/stopã§ã¾ã¨ã‚ã¦å‡ºåŠ›      | `submission.csv`        |

---

## âœ… æ¬¡ã«ã‚„ã‚‹ã¹ãã‚¹ãƒ†ãƒƒãƒ—

ã“ã“ã¾ã§ã§Cï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ï¼‰å®Œäº†ã€‚
æ¬¡ã¯ã€ã„ã‚ˆã„ã‚ˆã€Œ**è¡Œå‹•actionã‚’ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§äºˆæ¸¬ã—ã€ãã“ã‹ã‚‰submissionå½¢å¼ã«å¤‰æ›**ã€ã¸é€²ã‚€æ®µéšã§ã™ã€‚

ææ¡ˆã¨ã—ã¦ã€æ¬¡ã®ã©ã¡ã‚‰ã‚’é€²ã‚ãŸã„ã§ã™ã‹ï¼Ÿ

A. XGBoostãªã©ã§ **actionåˆ†é¡ãƒ¢ãƒ‡ãƒ«** ã‚’æ§‹ç¯‰ã™ã‚‹ï¼ˆStepâ‘£ï¼‰
B. æ—¢ã«å¾—ã‚‰ã‚ŒãŸactionçµæœã‚’ã‚‚ã¨ã« **target_idãƒšã‚¢ãƒªãƒ³ã‚°ï¼ˆStepâ‘¤ï¼‰** ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½œã‚‹





Q: A.ã‹ãªã€‚
ç†ç”±ã¨ã—ã¦ã€ä»Šå›æå‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã»ã¨ã‚“ã©ã®actionãŒAttackã«é›†ä¸­ã—ã¦ã„ãŸã‹ã‚‰
A: ç´ æ™´ã‚‰ã—ã„åˆ¤æ–­ã§ã™ã€‚ğŸ’¡
ã¾ã•ã«ãã®é€šã‚Šã§ã€
Kaggleã®ã‚¹ã‚³ã‚¢ãŒ0ã«ãªã£ãŸã®ã‚‚ã€Œactionåˆ†é¡ãŒå´©å£Šã—ã¦ã™ã¹ã¦attackæ‰±ã„ã«ãªã£ã¦ã„ãŸã€å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚
ã“ã“ã§ä¸€åº¦ **â€œactionåˆ†é¡å™¨â€ ã‚’ã¡ã‚ƒã‚“ã¨ä½œã‚Šç›´ã™** ã®ã¯éå¸¸ã«è‰¯ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚

---

## ğŸ¯ ã‚´ãƒ¼ãƒ«ï¼ˆStepâ‘£ï¼‰

trackingæƒ…å ±ï¼ˆåº§æ¨™ï¼‰ã‹ã‚‰ã€
**frameå˜ä½ã§å„ãƒã‚¦ã‚¹ã®è¡Œå‹•ï¼ˆactionï¼‰ã‚’åˆ†é¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹ã€‚**

å‡ºåŠ›ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼š

```text
action âˆˆ {approach, attack, avoid, chase, chaseattack, submit, rear, none}
```

---

## ğŸ§± æº–å‚™ï¼šç‰¹å¾´é‡è¨­è¨ˆã®æ–¹å‘æ€§

è¡Œå‹•èªè­˜ã§ã¯ã€ãƒã‚¦ã‚¹ã®å‹•ãæ–¹ãƒ»ä»–ã®ãƒã‚¦ã‚¹ã¨ã®ç›¸å¯¾ä½ç½®ãŒæœ€ã‚‚é‡è¦ã«ãªã‚Šã¾ã™ã€‚

### ğŸ”¹ åŸºæœ¬ç‰¹å¾´é‡ï¼ˆagentå˜ä½“ï¼‰

| ç‰¹å¾´             | èª¬æ˜                               |
| -------------- | -------------------------------- |
| `speed`        | frameé–“ã®body_centerç§»å‹•è·é›¢ï¼ˆpx/frameï¼‰ |
| `acceleration` | é€Ÿåº¦å¤‰åŒ–é‡                            |
| `direction`    | ç§»å‹•ãƒ™ã‚¯ãƒˆãƒ«ã®è§’åº¦ï¼ˆatan2ï¼‰                 |
| `turn_angle`   | å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®è§’åº¦å·®                       |

### ğŸ”¹ ç›¸å¯¾ç‰¹å¾´é‡ï¼ˆä»–ã®ãƒã‚¦ã‚¹ã¨ã®é–¢ä¿‚ï¼‰

| ç‰¹å¾´                  | èª¬æ˜                |
| ------------------- | ----------------- |
| `dist_to_target`    | å„ç›¸æ‰‹ãƒã‚¦ã‚¹ã¨ã®è·é›¢ï¼ˆpxï¼‰    |
| `relative_velocity` | ç›¸æ‰‹ã¨ã®è·é›¢å¤‰åŒ–é€Ÿåº¦ï¼ˆæ¥è¿‘ãƒ»é›¢è„±ï¼‰ |
| `angle_to_target`   | ç›¸æ‰‹æ–¹å‘ã¸ã®è§’åº¦å·®         |

ã“ã‚Œã‚‰ã‚’ frame Ã— mouse_id å˜ä½ã§ã¾ã¨ã‚ãŸ `features_df` ã‚’ä½œæˆã—ã¾ã™ã€‚

---

## ğŸ§© ãƒ©ãƒ™ãƒ«ä½œæˆã®è€ƒãˆæ–¹ï¼ˆannotation.csvã‹ã‚‰ï¼‰

`annotation.csv` ã«ã¯ï¼š

```
agent_id, target_id, action, start_frame, stop_frame
```

ãŒå…¥ã£ã¦ã„ã‚‹ã®ã§ã€
ä»¥ä¸‹ã®ã‚ˆã†ã«å±•é–‹ã—ã¾ã™ğŸ‘‡

```python
# å„è¡Œå‹•åŒºé–“ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã«å±•é–‹
for each row in annotation.csv:
    for frame in range(start_frame, stop_frame + 1):
        label[(video_id, frame, agent_id)] = action
```

ãã®ä»–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ `"none"` ã¨ã—ã¦è£œå®Œã—ã¾ã™ã€‚

---

## âš™ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆãƒ•ãƒ­ãƒ¼ï¼ˆPythonæ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ï¼‰

```python
import pandas as pd
import numpy as np

# === 1. load tracking and annotation ===
tracking = pd.read_csv("tracking.csv")
annotation = pd.read_csv("annotation.csv")

# === 2. compute speed and direction ===
tracking = tracking.sort_values(["mouse_id", "video_frame"])
tracking["dx"] = tracking.groupby("mouse_id")["x"].diff()
tracking["dy"] = tracking.groupby("mouse_id")["y"].diff()
tracking["speed"] = np.sqrt(tracking["dx"]**2 + tracking["dy"]**2)
tracking["direction"] = np.arctan2(tracking["dy"], tracking["dx"])

# === 3. compute relative distance to other mice ===
def pairwise_features(df):
    result = []
    mice = df["mouse_id"].unique()
    for m1 in mice:
        sub1 = df[df["mouse_id"] == m1]
        for m2 in mice:
            if m1 == m2: continue
            sub2 = df[df["mouse_id"] == m2]
            merged = sub1.merge(sub2, on="video_frame", suffixes=("_a", "_b"))
            merged["dist"] = np.sqrt((merged["x_a"] - merged["x_b"])**2 + (merged["y_a"] - merged["y_b"])**2)
            merged["dist_change"] = merged["dist"].diff()
            merged["pair"] = f"{m1}-{m2}"
            result.append(merged[["video_frame", "mouse_id_a", "pair", "speed_a", "direction_a", "dist", "dist_change"]])
    return pd.concat(result, ignore_index=True)

features = pairwise_features(tracking)

# === 4. label by annotation ===
labels = []
for _, row in annotation.iterrows():
    for f in range(row.start_frame, row.stop_frame + 1):
        labels.append((f, row.agent_id, row.action))
labels = pd.DataFrame(labels, columns=["video_frame", "mouse_id", "action"])

# === 5. merge features and labels ===
train_df = features.merge(labels, how="left", left_on=["video_frame", "mouse_id_a"], right_on=["video_frame", "mouse_id"])
train_df["action"] = train_df["action"].fillna("none")

# === 6. encode and train ===
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

X = train_df[["speed_a", "direction_a", "dist", "dist_change"]]
y = LabelEncoder().fit_transform(train_df["action"])

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
model = XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1)
model.fit(X_train, y_train)
print(classification_report(y_val, model.predict(X_val)))
```

---

## ğŸ§ª å‡ºåŠ›ã¨ç¢ºèª

ã“ã®æ™‚ç‚¹ã§ï¼š

* å„ `(video_frame, mouse_id)` ã«å¯¾ã—ã¦ `pred_action` ã‚’äºˆæ¸¬
* æ¬¡ã®Stepâ‘¤ï¼ˆtargetæ±ºå®šï¼‰ã«é€²ã‚€ãŸã‚ã®åœŸå°ãŒå®Œæˆ

---

## âœ… æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¡ˆ

ã‚ãªãŸã®æ„å›³ï¼ˆattackéå¤šã‚’é˜²ãï¼‰ã‚’è¸ã¾ãˆã¦ã€æ¬¡ã®å€™è£œã¯2ã¤ï¼š

1. **ç‰¹å¾´é‡ã®å¼·åŒ–**
   ã€€â†’ speed, distance ä»¥å¤–ã« acceleration, angle_to_target ã‚’è¿½åŠ 
2. **ä¸å‡è¡¡å¯¾ç­–**
   ã€€â†’ `scale_pos_weight` or `class_weight` ã§ attack ã®éå­¦ç¿’ã‚’é˜²æ­¢

---

é€²ã‚æ–¹ã®å¸Œæœ›ã‚’èã‹ã›ã¦ãã ã•ã„ğŸ‘‡
æ¬¡ã«ã‚„ã‚‹ãªã‚‰ï¼š

A. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å¼·åŒ–ï¼ˆç‰©ç†çš„ç‰¹å¾´ã‚’è¿½åŠ ï¼‰
B. ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–ã‚’å…¥ã‚Œã¦XGBoostã‚’å†èª¿æ•´





Q: ãã®å‰ã«ç¢ºèªã•ã›ã¦ã€‚
test.csvã«ãƒšã‚¢ã®ãƒã‚¦ã‚¹ã€è¡Œå‹•ã¨éƒ¨ä½ã®é…åˆ—ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‘ã©ã€ã“ã‚Œã‚’ã†ã¾ãåˆ©ç”¨ã§ããªã„ã‹ãª?
A: ãªã‚‹ã»ã©ã€ãã®ç‚¹ã‚’æŠ¼ã•ãˆã¦ãŠãã¨ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆãŒãã£ã¨åŠ¹ç‡çš„ã«ãªã‚Šã¾ã™ã€‚
test.csv ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å†…å®¹ã¯ã€ã–ã£ãã‚Šè¨€ã†ã¨ **ã€Œã“ã®å‹•ç”»ã«ç™»å ´ã™ã‚‹ãƒã‚¦ã‚¹ã®çµ„ã¿åˆã‚ã›ã¨å¯¾è±¡è¡Œå‹•ã€è¿½è·¡éƒ¨ä½ã€** ã®æƒ…å ±ã§ã™ã€‚

---

## ğŸ” test.csv ã®æƒ…å ±ã‚’ã©ã†æ´»ã‹ã›ã‚‹ã‹

### 1ï¸âƒ£ ãƒã‚¦ã‚¹ã®ãƒšã‚¢æƒ…å ±

* test.csv ã«ã¯ã€Œã“ã®å‹•ç”»ã«ã¯ mouse1â€“mouse2, mouse1â€“mouse3 â€¦ ã¨ã„ã£ãŸãƒšã‚¢ãŒå­˜åœ¨ã™ã‚‹ã€ã¨ã„ã†æƒ…å ±ãŒã‚ã‚Šã¾ã™ã€‚
* ã“ã‚Œã‚’åˆ©ç”¨ã™ã‚Œã°ã€**å€™è£œã¨ãªã‚‹ target_id ã‚’é™å®šã§ãã‚‹**
  â†’ å…¨ãƒã‚¦ã‚¹ã¨ã®è·é›¢ã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ãŒãªããªã‚‹
  â†’ ãƒšã‚¢ãƒªãƒ³ã‚°ã®èª¤ã‚Šï¼ˆagentâ†’targetã®çµ„ã¿é•ã„ï¼‰ã‚’æ¸›ã‚‰ã›ã‚‹

### 2ï¸âƒ£ è¡Œå‹•ãƒ©ãƒ™ãƒ«å€™è£œ

* ã€Œã“ã®å‹•ç”»ã§è¦³å¯Ÿã•ã‚Œã‚‹è¡Œå‹•ã®ç¨®é¡ã€ãŒæ›¸ã„ã¦ã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
* ã“ã‚Œã‚’ **åˆ†é¡å¯¾è±¡ã®ãƒ©ãƒ™ãƒ«å€™è£œã¨ã—ã¦åˆ¶é™** ã™ã‚‹ã“ã¨ã§ï¼š

  * attack ã—ã‹ãªã„å‹•ç”»ã§ä»–ã®è¡Œå‹•ã‚’äºˆæ¸¬ã—ã‚ˆã†ã¨ã—ã¦èª¤ã‚‹ã“ã¨ã‚’é¿ã‘ã‚‹
  * ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œã‚’ç·©å’Œã§ãã‚‹

### 3ï¸âƒ£ body_parts_trackedï¼ˆè¿½è·¡éƒ¨ä½ï¼‰

* DeepLabCutãªã©ã§è¿½è·¡ã•ã‚Œã‚‹éƒ¨ä½ãŒå‹•ç”»ã”ã¨ã«ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
* ç‰¹å¾´é‡ä½œæˆæ™‚ã«ã€Œå­˜åœ¨ã—ãªã„éƒ¨ä½ã®ãƒ‡ãƒ¼ã‚¿ã¯ä½¿ãˆãªã„ã€ã“ã¨ã‚’æ˜ç¤ºã§ãã‚‹
  â†’ NaNã§åŸ‹ã‚ãŸã‚Šã€é€Ÿåº¦è¨ˆç®—ã‹ã‚‰é™¤å¤–ã—ãŸã‚Šã§ãã‚‹
* é€†ã«è¨€ãˆã°ã€Œã“ã®å‹•ç”»ã§ã¯ ear_left/ear_right ãŒãªã„ã€ã¨ã‚ã‹ã‚‹ã ã‘ã§ç‰¹å¾´é‡è¨­è¨ˆãŒæŸ”è»Ÿã«ãªã‚‹

---

## ğŸ”¹ æ´»ç”¨ä¾‹

1. **å€™è£œ target_id ã®åˆ¶é™**

```python
# test.csvã‹ã‚‰å‹•ç”»ã”ã¨ã®ãƒšã‚¢ã‚’å–å¾—
video_pairs = test_df["behaviors_labeled"].unique()
# è¡Œå‹•äºˆæ¸¬æ™‚ã«ã€å€™è£œtargetã¯ãƒšã‚¢å†…ã«é™å®š
```

2. **åˆ†é¡ãƒ©ãƒ™ãƒ«åˆ¶é™**

```python
# ã“ã®å‹•ç”»ã§å‡ºç¾ã™ã‚‹actionã ã‘ã§å­¦ç¿’ãƒ»äºˆæ¸¬
allowed_actions = test_df["behaviors_labeled"].unique()
# XGBoostã®äºˆæ¸¬å¾Œã€allowed_actionsã«å«ã¾ã‚Œãªã„ãƒ©ãƒ™ãƒ«ã¯noneã«ç½®æ›
```

3. **body_parts_tracked ã«å¿œã˜ãŸç‰¹å¾´é‡é¸æŠ**

```python
# videoã”ã¨ã«åˆ©ç”¨å¯èƒ½ãªéƒ¨ä½ã ã‘ã§é€Ÿåº¦ã‚„è·é›¢ã‚’è¨ˆç®—
available_parts = test_df.loc[video_id, "body_parts_tracked"]
```

---

ğŸ’¡ **ã¾ã¨ã‚**

* test.csv ã¯ **å‹•ç”»å˜ä½ã®ãƒ¡ã‚¿æƒ…å ±** ã¨ã—ã¦æ‰±ã„ã€

  * ç‰¹å¾´é‡ä½œæˆ
  * targetãƒšã‚¢ã®å€™è£œåˆ¶é™
  * å‡ºç¾ãƒ©ãƒ™ãƒ«ã®åˆ¶é™
    ã®3ã¤ã«æ´»ã‹ã™ã®ãŒç¾å®Ÿçš„ã§ã™ã€‚

---

ã‚‚ã—ã‚ˆã‘ã‚Œã°æ¬¡ã«ã€
âœ… **test.csvã‚’æ´»ç”¨ã—ã¦ã€Œtargetå€™è£œã‚’é™å®šã—ãŸXGBoostå…¥åŠ›ã€ã‚’ä½œã‚‹ä¾‹**
ã‚’å…·ä½“çš„ã«ç¤ºã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ã‚‚ã†ä¸€ã¤ç¢ºèªã•ã›ã¦ã€‚
ãƒã‚¦ã‚¹ã®è§’åº¦æƒ…å ±ã‚’å¾—ã‚‹ãŸã‚ã«noseã¨bodycenterã®åº§æ¨™ã‚’ä½¿ã£ã¦ã„ãŸã‘ã©ã€test.csvã®éƒ¨ä½ã®ä»–ã®åº§æ¨™ã¯ä½•ã«åˆ©ç”¨ã§ãã‚‹?
A: ãªã‚‹ã»ã©ã€ã“ã“ãŒè¡Œå‹•èªè­˜ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚
é¼»ï¼ˆnoseï¼‰ã¨ä½“ä¸­å¿ƒï¼ˆbody_centerï¼‰ã§ãƒã‚¦ã‚¹ã®é€²è¡Œæ–¹å‘ã‚’å–ã‚‹ã®ã¯åŸºæœ¬ã§ã™ãŒã€**ãã®ä»–ã®éƒ¨ä½ã‚‚ã‹ãªã‚Šæœ‰åŠ¹ã«ä½¿ãˆã¾ã™**ã€‚

---

## ğŸ”¹ å„éƒ¨ä½ã®æ´»ç”¨ä¾‹

| éƒ¨ä½                                   | å¯èƒ½ãªåˆ©ç”¨æ³•        | å…·ä½“ä¾‹                               |
| ------------------------------------ | ------------- | --------------------------------- |
| ear_left / ear_right                 | é ­ã®å‘ãã‚„å›è»¢ã‚’è£œå®Œ    | é¼»ã¨è€³ã®ç›¸å¯¾ä½ç½®ã§é¦–ã®ã­ã˜ã‚Œã‚„è¦–ç·šæ–¹å‘ã®æ¨å®š            |
| headpiece_top*/bottom*               | é ­éƒ¨ã®å‚¾ããƒ»å‘ãã®ç²¾å¯†æ¨å®š | æ€¥æ—‹å›ã‚„å¨åš‡å‹•ä½œã®æ¤œçŸ¥                       |
| lateral_left / lateral_right         | ä½“ã®æ¨ªæ–¹å‘ã®åºƒãŒã‚Š     | æ”»æ’ƒå§¿å‹¢ï¼ˆchase/attackï¼‰ã‚„é˜²å¾¡å§¿å‹¢ï¼ˆavoidï¼‰ã®åˆ¤å®š |
| tail_base / tail_midpoint / tail_tip | ä½“å…¨ä½“ã®å§¿å‹¢ã‚„åŠ é€Ÿåˆ¤å®š   | chaseã‚„submitã§ã®å°¾ã®æŒ™å‹•ã‹ã‚‰è¡Œå‹•å¼·åº¦ã‚’æ¨å®š       |
| neck                                 | é¦–ã®æ›²ãŒã‚Šå…·åˆ       | æ­£é¢ã‚’å‘ã„ã¦ã„ã‚‹ã‹ã©ã†ã‹ã®è£œåŠ©ç‰¹å¾´                 |
| body_center                          | ç§»å‹•æ–¹å‘ã€é€Ÿåº¦       | åŸºæœ¬é€Ÿåº¦è¨ˆç®—ã€è§’åº¦è¨ˆç®—ã®åŸºæº–ç‚¹                   |
| nose                                 | æ­£é¢æ–¹å‘          | é€²è¡Œæ–¹å‘ã‚„ç›¸æ‰‹ã¸ã®å‘ãæ¨å®š                     |

---

## ğŸ”¹ å…·ä½“çš„ãªç‰¹å¾´é‡ä¾‹

1. **é ­éƒ¨æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«**

```text
nose â†’ body_center
nose â†’ headpiece_topfrontleft/right
```

* å¨åš‡ãƒ»æ”»æ’ƒãƒ»è¿½è·¡ã®æ–¹å‘ã‚’è£œæ­£

2. **ä½“ã®å›è»¢**

```text
ear_left â†’ ear_right
tail_base â†’ tail_tip
```

* ä½“ã®å‚¾ãã€æ—‹å›ã®è§’é€Ÿåº¦ã‚’è¨ˆç®—

3. **ãƒã‚¦ã‚¹é–“ã®ç›¸å¯¾è§’åº¦**

```text
nose â†’ body_center ã‹ã‚‰ target body_center ã¸ã®è§’åº¦
```

* approach/chase/attack ã‚’åˆ¤å®šã™ã‚‹æ±ºå®šçš„ç‰¹å¾´

4. **å§¿å‹¢ã‚„ç¸®é€€åº¦**

```text
lateral_left/right, tail_midpoint
```

* é˜²å¾¡ãƒ»é€ƒé¿è¡Œå‹•ï¼ˆavoid/submitï¼‰ã‚„ã€Œrearã€ãªã©ã®å¾Œã‚å‘ãè¡Œå‹•ã®åˆ¤å®š

---

## ğŸ”¹ è¦ç‚¹

* **body_center + nose** ã¯æ–¹å‘ãƒ»é€Ÿåº¦ã®åŸºæº–
* **è€³ãƒ»é ­éƒ¨ãƒ»å°¾ãƒ»é¦–** ã¯è¡Œå‹•ã®å¾®ç´°ãªå§¿å‹¢ã‚’åæ˜ 
* **tail / lateral** ã¯æ”»æ’ƒãƒ»é˜²å¾¡ã®å¼·åº¦æŒ‡æ¨™
* è¤‡æ•°éƒ¨ä½ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€å˜ç´”ãªè·é›¢ãƒ»é€Ÿåº¦ã ã‘ã§ã¯æ‰ãˆã‚‰ã‚Œãªã„è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’å¯èƒ½

---

ğŸ’¡ çµè«–ï¼š
test.csv ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ **å…¨è¿½è·¡éƒ¨ä½ã¯ç‰¹å¾´é‡æ‹¡å¼µã®å®åº«** ã§ã™ã€‚

* é¡”æ–¹å‘ã‚„æ—‹å› â†’ nose, ears, headpiece
* å°¾ã‚„ä½“ã®åºƒãŒã‚Š â†’ tail, lateral
* ç›¸æ‰‹ã¨ã®ç›¸å¯¾è§’åº¦ â†’ nose/body_centerã¨targetéƒ¨ä½

---

ã‚‚ã—ã‚ˆã‘ã‚Œã°æ¬¡ã«ã€
âœ… **nose/body_centerä»¥å¤–ã®åº§æ¨™ã‚’ä½¿ã£ãŸè¡Œå‹•ç‰¹å¾´é‡ä¾‹** ã‚’å…·ä½“çš„ã«Pythonã‚³ãƒ¼ãƒ‰ã§ç¤ºã™
ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€nose/body_center ä»¥å¤–ã®éƒ¨ä½ã‚‚æ´»ç”¨ã—ã¦ã€**è¡Œå‹•ç‰¹å¾´é‡ã‚’ä½œã‚‹ä¾‹**ã‚’Pythonã§ç¤ºã—ã¾ã™ã€‚
ã“ã“ã§ã¯åŸºæœ¬çš„ãªé€Ÿåº¦ãƒ»è§’åº¦ãƒ»ç›¸å¯¾è§’åº¦ãªã©ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

---

```python
import pandas as pd
import numpy as np

# tracking.csvã®èª­ã¿è¾¼ã¿
tracking = pd.read_csv("tracking.csv")

# ãƒã‚¦ã‚¹ã”ã¨ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ã‚½ãƒ¼ãƒˆ
tracking = tracking.sort_values(["mouse_id", "video_frame", "bodypart"])

# === åŸºæœ¬ç§»å‹•ãƒ™ã‚¯ãƒˆãƒ« ===
# body_center ã®é€Ÿåº¦ã¨è§’åº¦
bc = tracking[tracking["bodypart"]=="body_center"].copy()
bc["dx"] = bc.groupby("mouse_id")["x"].diff()
bc["dy"] = bc.groupby("mouse_id")["y"].diff()
bc["speed"] = np.sqrt(bc["dx"]**2 + bc["dy"]**2)
bc["direction"] = np.arctan2(bc["dy"], bc["dx"])

# === é¼»ã¨ä½“ä¸­å¿ƒã§é€²è¡Œæ–¹å‘ ===
nose = tracking[tracking["bodypart"]=="nose"].copy()
nose_bc = nose.merge(bc[["video_frame","mouse_id","x","y"]], on=["video_frame","mouse_id"], suffixes=("_nose","_bc"))
nose_bc["vec_nose_x"] = nose_bc["x_nose"] - nose_bc["x_bc"]
nose_bc["vec_nose_y"] = nose_bc["y_nose"] - nose_bc["y_bc"]
nose_bc["angle_nose"] = np.arctan2(nose_bc["vec_nose_y"], nose_bc["vec_nose_x"])

# === è€³ã‚’ä½¿ã£ãŸé ­éƒ¨ã®å‘ãè£œæ­£ ===
ears = tracking[tracking["bodypart"].isin(["ear_left","ear_right"])].copy()
ears_pivot = ears.pivot(index=["video_frame","mouse_id"], columns="bodypart", values=["x","y"])
# å·¦å³ã®è€³ã®ãƒ™ã‚¯ãƒˆãƒ«
ears_pivot["ear_dx"] = ears_pivot["x"]["ear_right"] - ears_pivot["x"]["ear_left"]
ears_pivot["ear_dy"] = ears_pivot["y"]["ear_right"] - ears_pivot["y"]["ear_left"]
ears_pivot["head_angle"] = np.arctan2(ears_pivot["ear_dy"], ears_pivot["ear_dx"])

# === å°¾ã‚’ä½¿ã£ãŸä½“ã®ä¼¸ã³ï¼å§¿å‹¢ ===
tail = tracking[tracking["bodypart"].isin(["tail_base","tail_tip"])].copy()
tail_pivot = tail.pivot(index=["video_frame","mouse_id"], columns="bodypart", values=["x","y"])
tail_pivot["tail_dx"] = tail_pivot["x"]["tail_tip"] - tail_pivot["x"]["tail_base"]
tail_pivot["tail_dy"] = tail_pivot["y"]["tail_tip"] - tail_pivot["y"]["tail_base"]
tail_pivot["tail_angle"] = np.arctan2(tail_pivot["tail_dy"], tail_pivot["tail_dx"])
tail_pivot["tail_length"] = np.sqrt(tail_pivot["tail_dx"]**2 + tail_pivot["tail_dy"]**2)

# === ç‰¹å¾´é‡çµåˆ ===
features = bc[["video_frame","mouse_id","speed","direction"]].merge(
    nose_bc[["video_frame","mouse_id","angle_nose"]],
    on=["video_frame","mouse_id"]
).merge(
    ears_pivot[["head_angle"]],
    left_on=["video_frame","mouse_id"], right_index=True
).merge(
    tail_pivot[["tail_angle","tail_length"]],
    left_on=["video_frame","mouse_id"], right_index=True
)

# features ãŒãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®è¡Œå‹•äºˆæ¸¬ç”¨ã®å…¥åŠ›ã«ãªã‚‹
print(features.head())
```

---

### ğŸ”¹ ã“ã®ç‰¹å¾´é‡ã®æ„å‘³

* `speed` / `direction` â†’ ç§»å‹•ã®åŸºæœ¬ãƒ™ã‚¯ãƒˆãƒ«
* `angle_nose` â†’ é¼»ã¨ä½“ä¸­å¿ƒã§è¦‹ãŸé€²è¡Œæ–¹å‘ï¼ˆæ”»æ’ƒã‚„è¿½è·¡ã®å‘ãï¼‰
* `head_angle` â†’ å·¦å³ã®è€³ã§è¦‹ãŸé ­ã®å‘ãï¼ˆé¡”ã®å›è»¢ã€å¨åš‡ï¼‰
* `tail_angle` / `tail_length` â†’ å°¾ã®å‘ãã¨ä¼¸ã³ï¼ˆæ”»æ’ƒå§¿å‹¢ã‚„submitã®æŒ‡æ¨™ï¼‰

---

ğŸ’¡ ã“ã“ã‹ã‚‰ã•ã‚‰ã«æ‹¡å¼µã§ãã‚‹ä¾‹

* ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ã¨ç›¸å¯¾è§’åº¦
* accelerationï¼ˆé€Ÿåº¦ã®å¤‰åŒ–é‡ï¼‰
* ä½“ã®æ—‹å›è§’ï¼ˆæ–¹å‘ã®å¤‰åŒ–é‡ï¼‰
* lateral éƒ¨ä½ã‚’ä½¿ã£ãŸä½“ã®å¹…ãƒ»å‚¾ã

ã“ã‚Œã‚‰ã‚’ã™ã¹ã¦çµåˆã™ã‚‹ã¨ **æ”»æ’ƒãƒ»å›é¿ãƒ»è¿½è·¡ãƒ»ãƒªã‚¢ãƒªãƒ³ã‚°ãªã©ã®å¾®ç´°è¡Œå‹•ãŒãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§åˆ¤åˆ¥ã—ã‚„ã™ããªã‚‹** ã¨ã„ã†ã‚ã‘ã§ã™ã€‚

---

å¸Œæœ›ãªã‚‰ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦

âœ… **ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ãƒ»ç›¸å¯¾è§’åº¦ã‚’åŠ ãˆãŸXGBoostç”¨ãƒ•ãƒ«ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ** ã®ä½œã‚Šæ–¹

ã‚‚ã‚³ãƒ¼ãƒ‰ä¾‹ã§ç¤ºã›ã¾ã™ã€‚
ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ãƒ»ç›¸å¯¾è§’åº¦**ã‚‚å«ã‚ãŸãƒ•ãƒ«ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚
ã“ã‚Œã§ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®è¡Œå‹•åˆ†é¡ï¼ˆXGBoostãªã©ï¼‰ã«ç›´æ¥ä½¿ãˆã‚‹å½¢ã«ãªã‚Šã¾ã™ã€‚

---

```python
import pandas as pd
import numpy as np

# tracking.csvèª­ã¿è¾¼ã¿
tracking = pd.read_csv("tracking.csv")

# ã‚½ãƒ¼ãƒˆã—ã¦å·®åˆ†è¨ˆç®—ã—ã‚„ã™ãã™ã‚‹
tracking = tracking.sort_values(["video_frame", "mouse_id", "bodypart"])

# === åŸºæœ¬ãƒ™ãƒ¼ã‚¹ï¼ˆå‰å›ã® nose/body_center/ears/tail ç‰¹å¾´é‡ï¼‰ ===
# body_centeré€Ÿåº¦ãƒ»æ–¹å‘
bc = tracking[tracking["bodypart"]=="body_center"].copy()
bc["dx"] = bc.groupby("mouse_id")["x"].diff()
bc["dy"] = bc.groupby("mouse_id")["y"].diff()
bc["speed"] = np.sqrt(bc["dx"]**2 + bc["dy"]**2)
bc["direction"] = np.arctan2(bc["dy"], bc["dx"])

# nose-body_centerè§’åº¦
nose = tracking[tracking["bodypart"]=="nose"].copy()
nose_bc = nose.merge(bc[["video_frame","mouse_id","x","y"]], on=["video_frame","mouse_id"], suffixes=("_nose","_bc"))
nose_bc["angle_nose"] = np.arctan2(nose_bc["y_nose"]-nose_bc["y_bc"], nose_bc["x_nose"]-nose_bc["x_bc"])

# ears
ears = tracking[tracking["bodypart"].isin(["ear_left","ear_right"])].copy()
ears_pivot = ears.pivot(index=["video_frame","mouse_id"], columns="bodypart", values=["x","y"])
ears_pivot["head_angle"] = np.arctan2(
    ears_pivot["y"]["ear_right"] - ears_pivot["y"]["ear_left"],
    ears_pivot["x"]["ear_right"] - ears_pivot["x"]["ear_left"]
)

# tail
tail = tracking[tracking["bodypart"].isin(["tail_base","tail_tip"])].copy()
tail_pivot = tail.pivot(index=["video_frame","mouse_id"], columns="bodypart", values=["x","y"])
tail_pivot["tail_dx"] = tail_pivot["x"]["tail_tip"] - tail_pivot["x"]["tail_base"]
tail_pivot["tail_dy"] = tail_pivot["y"]["tail_tip"] - tail_pivot["y"]["tail_base"]
tail_pivot["tail_angle"] = np.arctan2(tail_pivot["tail_dy"], tail_pivot["tail_dx"])
tail_pivot["tail_length"] = np.sqrt(tail_pivot["tail_dx"]**2 + tail_pivot["tail_dy"]**2)

# åŸºæœ¬ç‰¹å¾´é‡çµåˆ
features = bc[["video_frame","mouse_id","speed","direction"]].merge(
    nose_bc[["video_frame","mouse_id","angle_nose"]],
    on=["video_frame","mouse_id"]
).merge(
    ears_pivot[["head_angle"]],
    left_on=["video_frame","mouse_id"], right_index=True
).merge(
    tail_pivot[["tail_angle","tail_length"]],
    left_on=["video_frame","mouse_id"], right_index=True
)

# === ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ãƒ»ç›¸å¯¾è§’åº¦ ===
mice_ids = tracking["mouse_id"].unique()
pair_features = []

for m1 in mice_ids:
    sub1 = features[features["mouse_id"]==m1].copy()
    for m2 in mice_ids:
        if m1 == m2: 
            continue
        sub2_bc = bc[bc["mouse_id"]==m2][["video_frame","x","y"]].copy()
        merged = sub1.merge(sub2_bc, on="video_frame", suffixes=("","_target"))
        # è·é›¢
        merged["dist_to_target"] = np.sqrt((merged["x"] - merged["x_target"])**2 + (merged["y"] - merged["y_target"])**2)
        # ç›¸å¯¾è§’åº¦ï¼šagentã®é€²è¡Œæ–¹å‘ã¨targetã®æ–¹å‘
        merged["vec_to_target_x"] = merged["x_target"] - merged["x"]
        merged["vec_to_target_y"] = merged["y_target"] - merged["y"]
        merged["angle_to_target"] = np.arctan2(merged["vec_to_target_y"], merged["vec_to_target_x"])
        merged["relative_angle"] = merged["angle_to_target"] - merged["direction"]
        pair_features.append(merged[["video_frame","mouse_id","speed","direction","angle_nose",
                                     "head_angle","tail_angle","tail_length",
                                     "dist_to_target","relative_angle","mouse_id_target"]])

# ã™ã¹ã¦ã®ãƒšã‚¢ç‰¹å¾´é‡ã‚’çµåˆ
full_features = pd.concat(pair_features, ignore_index=True)

print(full_features.head())
```

---

### ğŸ”¹ ã“ã®ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã®æ„å‘³

* **agentãƒã‚¦ã‚¹å˜ä½“**

  * speed, direction, angle_nose, head_angle, tail_angle, tail_length
* **agentã¨targetã®ç›¸å¯¾æƒ…å ±**

  * dist_to_target â†’ ç›¸æ‰‹ã¾ã§ã®è·é›¢
  * relative_angle â†’ agentã®å‘ãã«å¯¾ã™ã‚‹targetã®æ–¹å‘
* **mouse_id_target** â†’ targetã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®ç‰¹å¾´ãŒä½œã‚Œã‚‹

ã“ã‚Œã‚’ä½¿ãˆã°ã€XGBoostãªã©ã§ **frameå˜ä½ã®è¡Œå‹•(action)äºˆæ¸¬ + targetå€™è£œã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°** ãŒå¯èƒ½ã§ã™ã€‚

---

ğŸ’¡ ãƒã‚¤ãƒ³ãƒˆ

* ç›¸å¯¾è§’åº¦ã‚„è·é›¢ã¯æ”»æ’ƒãƒ»å›é¿ãƒ»è¿½è·¡ãƒ»submitãªã©ã€ãƒã‚¦ã‚¹ã®å¾®ç´°è¡Œå‹•ã®åˆ¤å®šã«éå¸¸ã«é‡è¦
* `mouse_id_target` ã‚’ä½¿ãˆã° target ã®å€™è£œåˆ¶é™ï¼ˆtest.csvã®ãƒšã‚¢æƒ…å ±æ´»ç”¨ï¼‰ã‚‚ç°¡å˜

---

å¸Œæœ›ãªã‚‰ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦

âœ… **ã“ã® full_features ã‚’ä½¿ã£ãŸ XGBoost å­¦ç¿’ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰**

ã‚‚ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€å…ˆã»ã©ä½œã£ãŸ `full_features` ã‚’ä½¿ã£ã¦ã€**XGBoostã§frameå˜ä½ã®è¡Œå‹•ï¼ˆactionï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«**ã‚’ç¤ºã—ã¾ã™ã€‚
ã“ã“ã§ã¯åŸºæœ¬çš„ã«ã€Œagent Ã— target Ã— frameã€ã®ç‰¹å¾´é‡ã§åˆ†é¡ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚

---

```python
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

# --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
# full_features: agent Ã— target Ã— frameã®ç‰¹å¾´é‡
# annotation.csvã‚’èª­ã¿è¾¼ã¿ã€ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§ãƒ©ãƒ™ãƒ«ä»˜ã‘
annotation = pd.read_csv("annotation.csv")

# frameã”ã¨ã« agent_id / target_id ã¨ action ã‚’çµåˆ
# stop_frame ã¯å«ã‚ã‚‹ç¯„å›²ã«èª¿æ•´
def map_frame_label(row):
    return pd.DataFrame({
        "video_frame": np.arange(row["start_frame"], row["stop_frame"]+1),
        "agent_id": row["agent_id"],
        "target_id": row["target_id"],
        "action": row["action"]
    })

labels = pd.concat([map_frame_label(r) for _, r in annotation.iterrows()], ignore_index=True)

# full_features ã¨ labels ã‚’çµåˆ
data = full_features.merge(labels, left_on=["video_frame","mouse_id","mouse_id_target"],
                           right_on=["video_frame","agent_id","target_id"], how="left")

# NaNã¯è¡Œå‹•ãŒãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ãªã®ã§ "none" ãƒ©ãƒ™ãƒ«ã«ç½®æ›
data["action"] = data["action"].fillna("none")

# --- ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ« ---
feature_cols = ["speed","direction","angle_nose","head_angle","tail_angle","tail_length",
                "dist_to_target","relative_angle"]
X = data[feature_cols]
y = data["action"]

# ãƒ©ãƒ™ãƒ«ã‚’æ•°å€¤ã«å¤‰æ›
le = LabelEncoder()
y_enc = le.fit_transform(y)

# --- å­¦ç¿’ãƒ»æ¤œè¨¼åˆ†å‰² ---
X_train, X_val, y_train, y_val = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)

# --- XGBooståˆ†é¡å™¨ ---
model = xgb.XGBClassifier(
    objective="multi:softmax",
    num_class=len(le.classes_),
    max_depth=6,
    n_estimators=200,
    learning_rate=0.1,
    eval_metric="mlogloss",
    use_label_encoder=False,
    n_jobs=-1
)

# å­¦ç¿’
model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=10)

# --- äºˆæ¸¬ã¨è©•ä¾¡ ---
y_pred = model.predict(X_val)
print(classification_report(y_val, y_pred, target_names=le.classes_))
```

---

### ğŸ”¹ ãƒã‚¤ãƒ³ãƒˆ

1. **frameå˜ä½ã§ãƒ©ãƒ™ãƒ«ã‚’å±•é–‹**

   * annotation.csvã®start_frameã€œstop_frameã‚’ã™ã¹ã¦ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§å±•é–‹
   * ã“ã‚Œã«ã‚ˆã‚Šã€XGBoostã§ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®åˆ†é¡ãŒå¯èƒ½

2. **targetå€™è£œã‚‚ç‰¹å¾´é‡ã«å«ã‚ã‚‹**

   * `dist_to_target` ã‚„ `relative_angle` ã«ã‚ˆã£ã¦ã€ã©ã®ãƒã‚¦ã‚¹ã«å¯¾ã™ã‚‹è¡Œå‹•ã‹ã‚’å­¦ç¿’

3. **noneãƒ©ãƒ™ãƒ«ã®æ‰±ã„**

   * è¡Œå‹•ãŒãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ `none` ã¨ã—ã¦æ‰±ã„ã€attackã‚„approachã¨ã®åˆ†é¡ã«å«ã‚ã‚‹
   * ã“ã‚Œã§èª¤æ¤œå‡ºã‚’æŠ‘åˆ¶

4. **ãƒ©ãƒ™ãƒ«ä¸å‡è¡¡å¯¾ç­–**

   * attackãªã©ä¸€éƒ¨ã«åã‚‹å ´åˆã¯ class_weight ã‚’è¿½åŠ ã—ãŸã‚Šã€XGBoost ã® `scale_pos_weight` ã‚’èª¿æ•´ã™ã‚‹ã¨æ”¹å–„

---

ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã¯ã€

* test.csv ã® target ãƒšã‚¢æƒ…å ±ã‚’ä½¿ã£ã¦ **äºˆæ¸¬æ™‚ã«å€™è£œ target ã‚’åˆ¶é™**
* frameã”ã¨ã«äºˆæ¸¬å¾Œã€é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã¾ã¨ã‚ã¦ start_frame / stop_frame ã«å¤‰æ›

ã‚‚çµ„ã¿è¾¼ã‚€ã¨ **Kaggleç”¨submission** ã«ç›´æ¥ä½¿ãˆã¾ã™ã€‚

---

ã‚‚ã—å¸Œæœ›ãªã‚‰ã€ãã® **submissionä½œæˆæ‰‹é †ã‚‚å…·ä½“ã‚³ãƒ¼ãƒ‰ä»˜ãã§ç¤ºã™** ã“ã¨ãŒã§ãã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€å…ˆã»ã©ã® **XGBoostäºˆæ¸¬çµæœã‹ã‚‰Kaggleæå‡ºç”¨ã® submission.csv ã‚’ä½œã‚‹æ‰‹é †** ã‚’ç¤ºã—ã¾ã™ã€‚
ãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ã§ã™ï¼š

1. **frameå˜ä½ã®äºˆæ¸¬** ã‚’ã¾ã¨ã‚ã¦ã€é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã¯1ã¤ã®è¡Œã«çµ±åˆ
2. **targetå€™è£œã‚’ test.csv ã®ãƒšã‚¢æƒ…å ±ã§åˆ¶é™**
3. start_frame / stop_frame ã«å¤‰æ›ã—ã¦æå‡ºå½¢å¼ã«ã™ã‚‹

---

```python
import pandas as pd
import numpy as np

# --- å‰æ ---
# model: å­¦ç¿’æ¸ˆã¿ XGBoostãƒ¢ãƒ‡ãƒ«
# full_features: agent Ã— target Ã— frame ç‰¹å¾´é‡
# le: LabelEncoderï¼ˆaction â†’ æ•°å€¤å¤‰æ›æ¸ˆã¿ï¼‰

# --- äºˆæ¸¬ ---
X_test = full_features[feature_cols]
y_pred_num = model.predict(X_test)
y_pred_label = le.inverse_transform(y_pred_num)

full_features["pred_action"] = y_pred_label

# --- targetå€™è£œåˆ¶é™ (test.csvã®ãƒšã‚¢æƒ…å ±ã‚’ä½¿ç”¨) ---
test_meta = pd.read_csv("test.csv")
# ã“ã“ã§ã¯video_idã”ã¨ã®æœ‰åŠ¹ãƒšã‚¢æƒ…å ±ã‚’å–å¾—
video_pair_map = {}  # video_id -> set of (agent_id, target_id)
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):  # ["mouse1,mouse2,attack", ...] ã®æ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆåŒ–
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# video_id ã”ã¨ã®å€™è£œå¤– target ã‚’ none ã«ç½®æ›
full_features["pred_action"] = full_features.apply(
    lambda row: row["pred_action"] if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map[row["video_id"]] else "none",
    axis=1
)

# --- é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã¾ã¨ã‚ã¦ start/stop ã«å¤‰æ› ---
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    # é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã¾ã¨ã‚ã‚‹
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    # æœ€å¾Œã®åŒºé–“
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)

# --- ä¿å­˜ ---
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ãƒã‚¤ãƒ³ãƒˆ

1. **frameå˜ä½ã®äºˆæ¸¬ã‚’é€£ç¶šåŒºé–“ã«ã¾ã¨ã‚ã‚‹**

   * Kaggleæå‡ºã¯ start_frame / stop_frame æŒ‡å®šãªã®ã§å¿…é ˆ
2. **targetå€™è£œã‚’ test.csv ã§åˆ¶é™**

   * å­˜åœ¨ã—ãªã„ãƒšã‚¢ã«å¯¾ã™ã‚‹èª¤äºˆæ¸¬ã‚’é˜²ã
3. **noneãƒ©ãƒ™ãƒ«ã‚’é™¤å¤–**

   * è¡Œå‹•ãŒãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æå‡ºã—ãªã„

---

ğŸ’¡ ã“ã‚Œã§ **frameå˜ä½äºˆæ¸¬ â†’ submission.csv ä½œæˆ** ã¾ã§ä¸€æ°—é€šè²«ã§ã§ãã¾ã™ã€‚

å¸Œæœ›ãªã‚‰æ¬¡ã«ã€
âœ… **submission ã® attacké›†ä¸­å•é¡Œã‚’ç·©å’Œã™ã‚‹ãƒ©ãƒ™ãƒ«é‡ã¿èª¿æ•´ã‚„ post-processing ã®å·¥å¤«ä¾‹**
ã‚‚ç¤ºã›ã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€å…ˆã»ã©ã® XGBoost + submission ä½œæˆãƒ•ãƒ­ãƒ¼ã« **æ”»æ’ƒè¡Œå‹•ï¼ˆattackï¼‰é›†ä¸­å•é¡Œã®ç·©å’Œã‚„ post-processing ã®å·¥å¤«** ã‚’è¿½åŠ ã™ã‚‹ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

---

## 1ï¸âƒ£ ã‚¯ãƒ©ã‚¹é‡ã¿ã§å­¦ç¿’æ™‚ã«åã‚Šã‚’è£œæ­£

```python
from sklearn.utils.class_weight import compute_class_weight

# ãƒ©ãƒ™ãƒ«ã®é‡ã¿ã‚’è¨ˆç®—
class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y_enc), y=y_enc)
weight_map = {i:w for i,w in enumerate(class_weights)}

# XGBoostã§ weight ã‚’æ¸¡ã™å ´åˆã€sample_weightã«ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®é‡ã¿ã‚’è¨­å®š
sample_weight = np.array([weight_map[label] for label in y_train])

model.fit(X_train, y_train, sample_weight=sample_weight,
          eval_set=[(X_val, y_val)], verbose=10)
```

* attackãªã©ã®é »å‡ºã‚¯ãƒ©ã‚¹ã«å¯¾ã—ã¦ã¯å°ã•ã„é‡ã¿ã€ç¨€ãªã‚¯ãƒ©ã‚¹ã«ã¯å¤§ãã„é‡ã¿ã‚’ä»˜ä¸
* éå­¦ç¿’ã‚„æå‡ºæ™‚ã®æ”»æ’ƒé›†ä¸­ã‚’ç·©å’Œ

---

## 2ï¸âƒ£ Post-processingã§é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã®å¹³æ»‘åŒ–

* çŸ­ã„ç•°å¸¸ãƒ•ãƒ¬ãƒ¼ãƒ ã ã‘ã®è¡Œå‹•ã‚’ç›´å‰å¾Œã®ãƒ©ãƒ™ãƒ«ã«ç½®æ›ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ‘ã‚¤ã‚¯äºˆæ¸¬ã‚’æŠ‘ãˆã‚‹

```python
def smooth_predictions(df, action_col="pred_action", min_length=3):
    """
    çŸ­ã™ãã‚‹é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡Œå‹•ã‚’å‘¨å›²ã®ãƒ©ãƒ™ãƒ«ã§ç½®æ›
    min_length: æœ€å°é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    """
    df = df.sort_values("video_frame").copy()
    smoothed = []
    current_action = df[action_col].iloc[0]
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            if length < min_length:
                # çŸ­ã™ãã‚‹å ´åˆã¯å‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ç½®æ›
                for f in range(start, prev+1):
                    smoothed.append(current_action_prev)
            else:
                for f in range(start, prev+1):
                    smoothed.append(current_action)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    # æœ€å¾Œã®åŒºé–“
    length = prev - start + 1
    if length < min_length:
        for f in range(start, prev+1):
            smoothed.append(current_action_prev)
    else:
        for f in range(start, prev+1):
            smoothed.append(current_action)
    
    df[action_col] = smoothed
    return df

# video_id Ã— agent Ã— target ã”ã¨ã«é©ç”¨
full_features["pred_action"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions)["pred_action"].reset_index(drop=True)
```

* `min_length` ã‚’ 2ã€œ5 ãƒ•ãƒ¬ãƒ¼ãƒ ç¨‹åº¦ã«è¨­å®š
* ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®ãƒã‚¤ã‚ºäºˆæ¸¬ã‚’å¹³æ»‘åŒ–ã—ã€æå‡ºå¾Œã® attacké›†ä¸­ã‚’ç·©å’Œ

---

## 3ï¸âƒ£ ä»–ã® post-processing ã‚¢ã‚¤ãƒ‡ã‚¢

1. **è·é›¢ãƒ»ç›¸å¯¾è§’åº¦ã«åŸºã¥ãé–¾å€¤å‡¦ç†**

   * dist_to_target ãŒé ã™ãã‚‹å ´åˆã¯ attack/chase ã‚’ none ã«ç½®æ›
   * relative_angle ãŒå¤§ããé€¸ã‚Œã¦ã„ã‚‹å ´åˆã‚‚åŒæ§˜

2. **è¡Œå‹•é€£é–ãƒ«ãƒ¼ãƒ«**

   * attack â†’ submit ã‚„ approach â†’ chase ã¨ã„ã£ãŸè‡ªç„¶ãªé·ç§»ã‚’å„ªå…ˆ
   * éç¾å®Ÿçš„ãªé€£é–ã¯ none ã«ç½®æ›

3. **ãƒ“ãƒ˜ã‚¤ãƒ“ã‚¢é•·ã«åŸºã¥ããƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**

   * submitã‚„rearãªã©çŸ­ã„è¡Œå‹•ã¯ min_length ã§åˆ¶é™ã—ã¦é™¤å¤–

---

ğŸ’¡ ã¾ã¨ã‚

* å­¦ç¿’æ™‚ â†’ **ã‚¯ãƒ©ã‚¹é‡ã¿ã§attackéå¤šã‚’æŠ‘ãˆã‚‹**
* äºˆæ¸¬å¾Œ â†’ **å¹³æ»‘åŒ– & ç‰©ç†çš„åˆ¶ç´„ï¼ˆè·é›¢ãƒ»è§’åº¦ï¼‰ã§ä¸è‡ªç„¶ãªæ”»æ’ƒã‚’é™¤å»**
* ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€Kaggleæå‡ºã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã—ã‚„ã™ããªã‚Šã¾ã™

---

å¸Œæœ›ãªã‚‰ã€æ¬¡ã« **æ”»æ’ƒé›†ä¸­å¯¾ç­–ã¾ã§çµ„ã¿è¾¼ã‚“ã  Kaggle submission å®Œæˆã‚³ãƒ¼ãƒ‰ä¾‹** ã‚’ä¸€æ°—é€šè²«ã§ç¤ºã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€ã“ã‚Œã¾ã§ã® **ç‰¹å¾´é‡ä½œæˆ â†’ XGBoostå­¦ç¿’ â†’ frameå˜ä½äºˆæ¸¬ â†’ post-processing â†’ submissionä½œæˆ** ã‚’ä¸€æ°—é€šè²«ã—ãŸ Kaggle ç”¨ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚
ãƒã‚¤ãƒ³ãƒˆã¯ä»¥ä¸‹ï¼š

* ç‰¹å¾´é‡ï¼šspeed, direction, angle_nose, head_angle, tail_angle/length, dist_to_target, relative_angle
* å­¦ç¿’æ™‚ï¼šã‚¯ãƒ©ã‚¹é‡ã¿ã§ attack éå¤šã‚’è£œæ­£
* äºˆæ¸¬å¾Œï¼šãƒ•ãƒ¬ãƒ¼ãƒ å¹³æ»‘åŒ– & targetåˆ¶é™
* submissionï¼šé€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã¨ã‚ã¦ start/stop ã«å¤‰æ›

---

```python
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

# =========================
# 1ï¸âƒ£ tracking.csv â†’ ç‰¹å¾´é‡ä½œæˆ
# =========================
tracking = pd.read_csv("tracking.csv")

# body_centeré€Ÿåº¦ãƒ»æ–¹å‘
bc = tracking[tracking["bodypart"]=="body_center"].copy()
bc["dx"] = bc.groupby("mouse_id")["x"].diff()
bc["dy"] = bc.groupby("mouse_id")["y"].diff()
bc["speed"] = np.sqrt(bc["dx"]**2 + bc["dy"]**2)
bc["direction"] = np.arctan2(bc["dy"], bc["dx"])

# nose-body_centerè§’åº¦
nose = tracking[tracking["bodypart"]=="nose"].copy()
nose_bc = nose.merge(bc[["video_frame","mouse_id","x","y"]], on=["video_frame","mouse_id"], suffixes=("_nose","_bc"))
nose_bc["angle_nose"] = np.arctan2(nose_bc["y_nose"]-nose_bc["y_bc"], nose_bc["x_nose"]-nose_bc["x_bc"])

# ears
ears = tracking[tracking["bodypart"].isin(["ear_left","ear_right"])].copy()
ears_pivot = ears.pivot(index=["video_frame","mouse_id"], columns="bodypart", values=["x","y"])
ears_pivot["head_angle"] = np.arctan2(
    ears_pivot["y"]["ear_right"] - ears_pivot["y"]["ear_left"],
    ears_pivot["x"]["ear_right"] - ears_pivot["x"]["ear_left"]
)

# tail
tail = tracking[tracking["bodypart"].isin(["tail_base","tail_tip"])].copy()
tail_pivot = tail.pivot(index=["video_frame","mouse_id"], columns="bodypart", values=["x","y"])
tail_pivot["tail_dx"] = tail_pivot["x"]["tail_tip"] - tail_pivot["x"]["tail_base"]
tail_pivot["tail_dy"] = tail_pivot["y"]["tail_tip"] - tail_pivot["y"]["tail_base"]
tail_pivot["tail_angle"] = np.arctan2(tail_pivot["tail_dy"], tail_pivot["tail_dx"])
tail_pivot["tail_length"] = np.sqrt(tail_pivot["tail_dx"]**2 + tail_pivot["tail_dy"]**2)

# åŸºæœ¬ç‰¹å¾´é‡çµåˆ
features = bc[["video_frame","mouse_id","speed","direction"]].merge(
    nose_bc[["video_frame","mouse_id","angle_nose"]],
    on=["video_frame","mouse_id"]
).merge(
    ears_pivot[["head_angle"]],
    left_on=["video_frame","mouse_id"], right_index=True
).merge(
    tail_pivot[["tail_angle","tail_length"]],
    left_on=["video_frame","mouse_id"], right_index=True
)

# =========================
# 2ï¸âƒ£ ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ãƒ»ç›¸å¯¾è§’åº¦
# =========================
mice_ids = tracking["mouse_id"].unique()
pair_features = []

for m1 in mice_ids:
    sub1 = features[features["mouse_id"]==m1].copy()
    for m2 in mice_ids:
        if m1 == m2: 
            continue
        sub2_bc = bc[bc["mouse_id"]==m2][["video_frame","x","y"]].copy()
        merged = sub1.merge(sub2_bc, on="video_frame", suffixes=("","_target"))
        merged["dist_to_target"] = np.sqrt((merged["x"] - merged["x_target"])**2 + (merged["y"] - merged["y_target"])**2)
        merged["vec_to_target_x"] = merged["x_target"] - merged["x"]
        merged["vec_to_target_y"] = merged["y_target"] - merged["y"]
        merged["angle_to_target"] = np.arctan2(merged["vec_to_target_y"], merged["vec_to_target_x"])
        merged["relative_angle"] = merged["angle_to_target"] - merged["direction"]
        merged["mouse_id_target"] = m2
        pair_features.append(merged[["video_frame","mouse_id","speed","direction","angle_nose",
                                     "head_angle","tail_angle","tail_length",
                                     "dist_to_target","relative_angle","mouse_id_target"]])

full_features = pd.concat(pair_features, ignore_index=True)

# =========================
# 3ï¸âƒ£ frameå˜ä½ãƒ©ãƒ™ãƒ«ä»˜ã‘
# =========================
annotation = pd.read_csv("annotation.csv")

def map_frame_label(row):
    return pd.DataFrame({
        "video_frame": np.arange(row["start_frame"], row["stop_frame"]+1),
        "agent_id": row["agent_id"],
        "target_id": row["target_id"],
        "action": row["action"]
    })

labels = pd.concat([map_frame_label(r) for _, r in annotation.iterrows()], ignore_index=True)

data = full_features.merge(labels, left_on=["video_frame","mouse_id","mouse_id_target"],
                           right_on=["video_frame","agent_id","target_id"], how="left")
data["action"] = data["action"].fillna("none")

feature_cols = ["speed","direction","angle_nose","head_angle","tail_angle","tail_length",
                "dist_to_target","relative_angle"]
X = data[feature_cols]
y = data["action"]

le = LabelEncoder()
y_enc = le.fit_transform(y)

X_train, X_val, y_train, y_val = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)

# =========================
# 4ï¸âƒ£ XGBoost å­¦ç¿’ï¼ˆã‚¯ãƒ©ã‚¹é‡ã¿ã‚ã‚Šï¼‰
# =========================
class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y_enc), y=y_enc)
weight_map = {i:w for i,w in enumerate(class_weights)}
sample_weight = np.array([weight_map[label] for label in y_train])

model = xgb.XGBClassifier(
    objective="multi:softmax",
    num_class=len(le.classes_),
    max_depth=6,
    n_estimators=200,
    learning_rate=0.1,
    eval_metric="mlogloss",
    use_label_encoder=False,
    n_jobs=-1
)
model.fit(X_train, y_train, sample_weight=sample_weight, eval_set=[(X_val, y_val)], verbose=10)

# =========================
# 5ï¸âƒ£ äºˆæ¸¬
# =========================
y_pred_num = model.predict(X)
y_pred_label = le.inverse_transform(y_pred_num)
full_features["pred_action"] = y_pred_label

# =========================
# 6ï¸âƒ£ Post-processing: çŸ­ã„ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»
# =========================
def smooth_predictions(df, action_col="pred_action", min_length=3):
    df = df.sort_values("video_frame").copy()
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            if length < min_length:
                for f in range(start, prev+1):
                    smoothed.append(current_action_prev)
            else:
                for f in range(start, prev+1):
                    smoothed.append(current_action)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    if length < min_length:
        for f in range(start, prev+1):
            smoothed.append(current_action_prev)
    else:
        for f in range(start, prev+1):
            smoothed.append(current_action)
    df[action_col] = smoothed
    return df

full_features["pred_action"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions)["pred_action"].reset_index(drop=True)

# =========================
# 7ï¸âƒ£ Submission ä½œæˆ
# =========================
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "
```


action": action,
"start_frame": start,
"stop_frame": prev
})
start = prev = frame
submission_rows.append({
"video_id": video_id,
"agent_id": agent_id,
"target_id": target_id,
"action": action,
"start_frame": start,
"stop_frame": prev
})

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())

```

---

### ğŸ”¹ ã“ã‚Œã§å®Œæˆ

- ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®äºˆæ¸¬ã‚’ã¾ã¨ã‚ã¦ start/stop ã«å¤‰æ›  
- attacké›†ä¸­ã‚’ã‚¯ãƒ©ã‚¹é‡ã¿ + ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»ã§ç·©å’Œ  
- test.csv ã® targetå€™è£œã«åˆã‚ã›ã¦åˆ¶é™ã‚‚å¯èƒ½ï¼ˆä¸Šã®ã‚³ãƒ¼ãƒ‰ã«è¿½åŠ ã§ç°¡å˜ã«çµ„ã¿è¾¼ã‚ã¾ã™ï¼‰  

---

ğŸ’¡ å¸Œæœ›ã§ã‚ã‚Œã°ã€**targetå€™è£œåˆ¶é™ã‚’çµ„ã¿è¾¼ã‚“ã æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³**ã‚‚ä½œã‚Œã¾ã™ã€‚  
ä½œã‚Šã¾ã™ã‹ï¼Ÿ
```





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€å…ˆã»ã©ã®ä¸€æ°—é€šè²«ã‚³ãƒ¼ãƒ‰ã« **test.csv ã® targetå€™è£œåˆ¶é™** ã‚’çµ„ã¿è¾¼ã‚“ã æœ€çµ‚ç‰ˆã‚’ç¤ºã—ã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

1. video_id ã”ã¨ã«æœ‰åŠ¹ãª `(agent_id, target_id)` ãƒšã‚¢ã‚’ test.csv ã‹ã‚‰å–å¾—
2. äºˆæ¸¬å¾Œã«ãƒšã‚¢ã«å­˜åœ¨ã—ãªã„ target ã¯ `none` ã«ç½®æ›
3. ãã®å¾Œã€ãƒ•ãƒ¬ãƒ¼ãƒ å¹³æ»‘åŒ– â†’ submission ä½œæˆ

---

```python
# =========================
# 0ï¸âƒ£ test.csv ã‹ã‚‰å€™è£œãƒšã‚¢ä½œæˆ
# =========================
test_meta = pd.read_csv("test.csv")

video_pair_map = {}  # video_id -> set of (agent_id, target_id)
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):  # ["mouse1,mouse2,attack", ...] ã®æ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆåŒ–
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# =========================
# 1ï¸âƒ£ äºˆæ¸¬å¾Œã«å€™è£œå¤– target ã‚’ none ã«ç½®æ›
# =========================
full_features["pred_action"] = full_features.apply(
    lambda row: row["pred_action"] 
    if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set())
    else "none",
    axis=1
)

# =========================
# 2ï¸âƒ£ ãƒ•ãƒ¬ãƒ¼ãƒ å¹³æ»‘åŒ– (ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»)
# =========================
def smooth_predictions(df, action_col="pred_action", min_length=3):
    df = df.sort_values("video_frame").copy()
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            if length < min_length:
                for f in range(start, prev+1):
                    smoothed.append(current_action_prev)
            else:
                for f in range(start, prev+1):
                    smoothed.append(current_action)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    if length < min_length:
        for f in range(start, prev+1):
            smoothed.append(current_action_prev)
    else:
        for f in range(start, prev+1):
            smoothed.append(current_action)
    df[action_col] = smoothed
    return df

full_features["pred_action"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions)["pred_action"].reset_index(drop=True)

# =========================
# 3ï¸âƒ£ Submission ä½œæˆ
# =========================
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ãƒã‚¤ãƒ³ãƒˆ

1. **targetå€™è£œåˆ¶é™**

   * test.csv ã«ãªã„ãƒšã‚¢ã¸ã®èª¤æ¤œå‡ºã‚’æ’é™¤
2. **ã‚¹ãƒ‘ã‚¤ã‚¯å¹³æ»‘åŒ–**

   * é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ãŒ min_length æœªæº€ã®è¡Œå‹•ã‚’å‰å¾Œã®ãƒ©ãƒ™ãƒ«ã§ç½®æ›
3. **start/stop å¤‰æ›**

   * Kaggleæå‡ºå½¢å¼ã«å¯¾å¿œ

---

ã“ã‚Œã§ **ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ â†’ targetåˆ¶é™ â†’ å¹³æ»‘åŒ– â†’ submissionä½œæˆ** ãŒä¸€æ°—é€šè²«ã§å¯èƒ½ã§ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€**min_length ã‚„è·é›¢åˆ¶é™ãªã©ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ä¾‹** ã‚‚è¿½åŠ ã§ç¤ºã›ã¾ã™ã€‚

è¿½åŠ ã—ã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€å…ˆã»ã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ï¼‹targetåˆ¶é™ï¼‹å¹³æ»‘åŒ–ã‚³ãƒ¼ãƒ‰ã«ã€**min_lengthï¼ˆè¡Œå‹•é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰ã¨è·é›¢åˆ¶é™ã‚’èª¿æ•´å¯èƒ½ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã‚’è¿½åŠ ã—ãŸä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚

ã“ã‚Œã«ã‚ˆã‚Šã€**çŸ­ã™ãã‚‹ã‚¹ãƒ‘ã‚¤ã‚¯ã‚„ä¸è‡ªç„¶ãªæ”»æ’ƒã‚’ç‰©ç†çš„æ¡ä»¶ã§é™¤å¤–**ã§ãã¾ã™ã€‚

---

```python
# =========================
# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# =========================
MIN_FRAMES = 3         # æœ€å°é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ æ•°
MAX_DIST = 150         # æ”»æ’ƒ/æ¥è¿‘è¡Œå‹•å¯¾è±¡ã¨ã®æœ€å¤§è·é›¢ï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ï¼‰

# =========================
# 1ï¸âƒ£ targetå€™è£œåˆ¶é™ï¼‹è·é›¢åˆ¶é™
# =========================
def apply_constraints(row):
    # targetãƒšã‚¢åˆ¶é™
    pair_ok = (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set())
    # è·é›¢åˆ¶é™
    dist_ok = row["dist_to_target"] <= MAX_DIST
    if not pair_ok or not dist_ok:
        return "none"
    else:
        return row["pred_action"]

full_features["pred_action"] = full_features.apply(apply_constraints, axis=1)

# =========================
# 2ï¸âƒ£ å¹³æ»‘åŒ–ï¼ˆmin_lengthæœªæº€ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»ï¼‰
# =========================
def smooth_predictions(df, action_col="pred_action", min_length=MIN_FRAMES):
    df = df.sort_values("video_frame").copy()
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            if length < min_length:
                for f in range(start, prev+1):
                    smoothed.append(current_action_prev)
            else:
                for f in range(start, prev+1):
                    smoothed.append(current_action)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    if length < min_length:
        for f in range(start, prev+1):
            smoothed.append(current_action_prev)
    else:
        for f in range(start, prev+1):
            smoothed.append(current_action)
    df[action_col] = smoothed
    return df

full_features["pred_action"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions)["pred_action"].reset_index(drop=True)

# =========================
# 3ï¸âƒ£ Submission ä½œæˆ
# =========================
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ãƒã‚¤ãƒ³ãƒˆ

1. **MIN_FRAMES**

   * è¡Œå‹•ãŒçŸ­ã™ãã‚‹ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’é™¤å»
   * 2ï½5ãƒ•ãƒ¬ãƒ¼ãƒ ç¨‹åº¦ãŒå®Ÿç”¨çš„

2. **MAX_DIST**

   * ç‰©ç†çš„ã«å±Šã‹ãªã„è·é›¢ã®æ”»æ’ƒ/æ¥è¿‘ã‚’é™¤å»
   * è·é›¢å˜ä½ã¯ tracking.csv ã®ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«åˆã‚ã›ã¦èª¿æ•´

3. **targetå€™è£œåˆ¶é™**

   * test.csv ã«å­˜åœ¨ã—ãªã„ agent-target ã¯ none ã«

---

ğŸ’¡ ã“ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹ã ã‘ã§ã€**æ”»æ’ƒé›†ä¸­ã‚„èª¤æ¤œå‡ºã‚’å¤§å¹…ã«æŠ‘ãˆã¤ã¤æå‡ºã‚¹ã‚³ã‚¢ã‚’æ”¹å–„**ã§ãã¾ã™ã€‚

å¸Œæœ›ãªã‚‰ã€ç§ãŒ **MIN_FRAMES ã¨ MAX_DIST ã®ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ä¾‹** ã‚‚ç¤ºã—ã¦æœ€é©å€¤ã‚’è‡ªå‹•é¸å®šã™ã‚‹æ–¹æ³•ã‚‚ä½œã‚Œã¾ã™ã€‚

ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€`MIN_FRAMES` ã¨ `MAX_DIST` ã‚’è‡ªå‹•ã§æœ€é©åŒ–ã™ã‚‹ **ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢** ã®ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚
ãƒã‚¤ãƒ³ãƒˆã¯ **ç°¡å˜ãªè©•ä¾¡æŒ‡æ¨™ã‚’ä½¿ã£ã¦æœ€é©å€¤ã‚’æ±ºã‚ã‚‹ã“ã¨** ã§ã™ã€‚Kaggleæå‡ºå‰ã«ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çš„ã«ã‚¹ã‚³ã‚¢ã®ç›®å®‰ã‚’ç¢ºèªã§ãã¾ã™ã€‚

---

```python
import itertools

# =========================
# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€™è£œ
# =========================
min_frames_list = [2, 3, 4, 5]
max_dist_list = [100, 150, 200, 250]  # ãƒ”ã‚¯ã‚»ãƒ«å˜ä½

best_score = -1
best_params = None

# =========================
# è©•ä¾¡ç”¨ç°¡æ˜“é–¢æ•°ï¼ˆãƒ©ãƒ™ãƒ«ãŒã‚ã‚‹trainãƒ‡ãƒ¼ã‚¿ã§ã®accuracyï¼‰
# =========================
def evaluate_submission(df, annotation_df):
    merged = df.merge(annotation_df, 
                      left_on=["video_id","agent_id","target_id","action"],
                      right_on=["video_id","agent_id","target_id","action"],
                      how="left")
    correct = ((merged["start_frame"] >= merged["start_frame_y"]) & (merged["stop_frame"] <= merged["stop_frame_y"])).sum()
    total = len(merged)
    return correct / total if total > 0 else 0

# =========================
# ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢
# =========================
for min_f, max_d in itertools.product(min_frames_list, max_dist_list):
    # 1ï¸âƒ£ åˆ¶ç´„é©ç”¨
    full_features["pred_action_temp"] = full_features.apply(
        lambda row: row["pred_action"] 
        if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
           and row["dist_to_target"] <= max_d
        else "none",
        axis=1
    )
    # 2ï¸âƒ£ å¹³æ»‘åŒ–
    full_features["pred_action_temp"] = full_features.groupby(
        ["video_id","mouse_id","mouse_id_target"]
    ).apply(smooth_predictions, action_col="pred_action", min_length=min_f)["pred_action"].reset_index(drop=True)
    
    # 3ï¸âƒ£ ç°¡æ˜“è©•ä¾¡
    score = evaluate_submission(full_features, annotation)
    
    print(f"MIN_FRAMES={min_f}, MAX_DIST={max_d}, score={score:.4f}")
    
    if score > best_score:
        best_score = score
        best_params = (min_f, max_d)

print(f"æœ€é©å€¤: MIN_FRAMES={best_params[0]}, MAX_DIST={best_params[1]}, ã‚¹ã‚³ã‚¢ç›®å®‰={best_score:.4f}")
```

---

### ğŸ”¹ ãƒã‚¤ãƒ³ãƒˆ

1. **ç°¡æ˜“è©•ä¾¡é–¢æ•°**

   * trainãƒ‡ãƒ¼ã‚¿ã® start/stop ã¨äºˆæ¸¬ã‚’æ¯”è¼ƒ
   * å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ã®ã¿æ­£è§£ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆï¼ˆç²—ã„ã‘ã©ç›®å®‰ï¼‰

2. **ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢**

   * MIN_FRAMES ã¨ MAX_DIST ã‚’çµ„ã¿åˆã‚ã›ã¦å…¨æ¢ç´¢
   * ã‚¹ã‚³ã‚¢æœ€å¤§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é¸æŠ

3. **å®Ÿé‹ç”¨**

   * æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ submission ä½œæˆã‚³ãƒ¼ãƒ‰ã«çµ„ã¿è¾¼ã‚€ã ã‘ã§è‡ªå‹•åæ˜ å¯èƒ½

---

ğŸ’¡ ã“ã®æ–¹æ³•ã‚’ä½¿ãˆã°ã€**æ”»æ’ƒé›†ä¸­ã‚„çŸ­ã‚¹ãƒ‘ã‚¤ã‚¯ã€è·é›¢å¤–ã®èª¤äºˆæ¸¬ã‚’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æŠ‘åˆ¶**ã§ãã¾ã™ã€‚

å¸Œæœ›ãªã‚‰ã€ã“ã®ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã¨ submission ä½œæˆã‚’ **ä¸€é€£ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŒ–** ã—ã¦ã€ãƒœã‚¿ãƒ³ä¸€ç™ºã§æœ€é©å€¤ï¼‹submissionç”Ÿæˆã¾ã§è¡Œãˆã‚‹ã‚³ãƒ¼ãƒ‰ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€ã“ã‚Œã¾ã§ã®å‡¦ç†ã‚’ **ä¸€æ°—é€šè²«ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** ã«ã¾ã¨ã‚ã¾ã™ã€‚

æµã‚Œï¼š

1. **test.csv ã‹ã‚‰æœ‰åŠ¹ãƒšã‚¢å–å¾—**
2. **ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ + targetå€™è£œåˆ¶é™ + è·é›¢åˆ¶é™**
3. **ã‚¹ãƒ‘ã‚¤ã‚¯å¹³æ»‘åŒ–ï¼ˆMIN_FRAMESï¼‰**
4. **ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã§æœ€é© MIN_FRAMES / MAX_DIST ã‚’æ±ºå®š**
5. **æœ€é©å€¤ã§ submission ä½œæˆ**

---

```python
import pandas as pd
import itertools

# =========================
# 0ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
full_features = pd.read_csv("full_features.csv")  # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ + dist_to_target åˆ—ã‚ã‚Š
test_meta = pd.read_csv("test.csv")
annotation = pd.read_csv("annotation.csv")

# =========================
# 1ï¸âƒ£ video_idã”ã¨ã®æœ‰åŠ¹ãƒšã‚¢
# =========================
video_pair_map = {}
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# =========================
# 2ï¸âƒ£ å¹³æ»‘åŒ–é–¢æ•°
# =========================
def smooth_predictions(df, action_col="pred_action", min_length=3):
    df = df.sort_values("video_frame").copy()
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            smoothed.extend([current_action_prev]*(length) if length < min_length else [current_action]*length)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    smoothed.extend([current_action_prev]*(length) if length < min_length else [current_action]*length)
    df[action_col] = smoothed
    return df

# =========================
# 3ï¸âƒ£ ç°¡æ˜“è©•ä¾¡é–¢æ•°ï¼ˆtrainã§ã®ç›®å®‰ã‚¹ã‚³ã‚¢ï¼‰
# =========================
def evaluate_submission(df, annotation_df):
    merged = df.merge(annotation_df, 
                      left_on=["video_id","mouse_id","mouse_id_target","pred_action"],
                      right_on=["video_id","agent_id","target_id","action"],
                      how="left")
    correct = ((merged["video_frame"] >= merged["start_frame_y"]) & (merged["video_frame"] <= merged["stop_frame_y"])).sum()
    total = len(merged)
    return correct / total if total > 0 else 0

# =========================
# 4ï¸âƒ£ ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢
# =========================
min_frames_list = [2,3,4,5]
max_dist_list = [100,150,200,250]

best_score = -1
best_params = None

for min_f, max_d in itertools.product(min_frames_list, max_dist_list):
    # targetå€™è£œåˆ¶é™ + è·é›¢åˆ¶é™
    full_features["pred_action_temp"] = full_features.apply(
        lambda row: row["pred_action"] 
        if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
           and row["dist_to_target"] <= max_d
        else "none",
        axis=1
    )
    # å¹³æ»‘åŒ–
    full_features["pred_action_temp"] = full_features.groupby(
        ["video_id","mouse_id","mouse_id_target"]
    ).apply(smooth_predictions, action_col="pred_action", min_length=min_f)["pred_action"].reset_index(drop=True)
    
    # ç°¡æ˜“ã‚¹ã‚³ã‚¢
    score = evaluate_submission(full_features, annotation)
    print(f"MIN_FRAMES={min_f}, MAX_DIST={max_d}, score={score:.4f}")
    
    if score > best_score:
        best_score = score
        best_params = (min_f, max_d)

print(f"æœ€é©å€¤: MIN_FRAMES={best_params[0]}, MAX_DIST={best_params[1]}, ã‚¹ã‚³ã‚¢ç›®å®‰={best_score:.4f}")

# =========================
# 5ï¸âƒ£ æœ€é©å€¤ã§ submission ä½œæˆ
# =========================
MIN_FRAMES, MAX_DIST = best_params

# åˆ¶ç´„é©ç”¨
full_features["pred_action_final"] = full_features.apply(
    lambda row: row["pred_action"] 
    if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
       and row["dist_to_target"] <= MAX_DIST
    else "none",
    axis=1
)

# å¹³æ»‘åŒ–
full_features["pred_action_final"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions, action_col="pred_action", min_length=MIN_FRAMES)["pred_action"].reset_index(drop=True)

# submissionä½œæˆ
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action_final"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ç‰¹å¾´

1. **ä¸€é€£ã®å‡¦ç†ãŒè‡ªå‹•åŒ–**

   * ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ â†’ targetåˆ¶é™ â†’ è·é›¢åˆ¶é™ â†’ å¹³æ»‘åŒ– â†’ submissionä½œæˆ
2. **ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**

   * MIN_FRAMES ã¨ MAX_DIST ã®çµ„ã¿åˆã‚ã›ã‚’è‡ªå‹•é¸å®š
3. **Kaggleæå‡ºå½¢å¼å¯¾å¿œ**

   * row_idã€video_idã€agent_idã€target_idã€actionã€start_frameã€stop_frame

---

ğŸ’¡ ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ãˆã°ã€**test.csv ã®ãƒšã‚¢åˆ¶é™ã‚„è·é›¢åˆ¶é™ã‚‚è‡ªå‹•åæ˜ **ã•ã‚Œã‚‹ã®ã§ã€ã‚¹ã‚³ã‚¢æ”¹å–„ãŒè¦‹è¾¼ã‚ã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€**ã•ã‚‰ã«è·é›¢åˆ¶é™ã‚’ cm æ›ç®—ã«ã—ã¦å®Ÿä¸–ç•Œè·é›¢ã«åŸºã¥ã„ãŸèª¿æ•´**ã‚‚çµ„ã¿è¾¼ã‚ã¾ã™ã€‚

ã‚„ã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€è·é›¢åˆ¶é™ã‚’ **ãƒ”ã‚¯ã‚»ãƒ«ã‹ã‚‰å®Ÿéš›ã®ã‚»ãƒ³ãƒãƒ¡ãƒ¼ãƒˆãƒ«æ›ç®—** ã—ã¦åˆ¶å¾¡ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* `dist_to_target` ã¯ tracking.csv ã®åº§æ¨™ã§ãƒ”ã‚¯ã‚»ãƒ«å˜ä½
* train.csv/test.csv ã«ã‚ã‚‹ `pix_per_cm_approx` ã‚’ä½¿ã£ã¦ã€ãƒ”ã‚¯ã‚»ãƒ« â†’ cm ã«å¤‰æ›
* MAX_DIST_CM ã§åˆ¶é™ã™ã‚‹ã“ã¨ã§ã€ç‰©ç†çš„ã«å±Šã‹ãªã„è·é›¢ã®è¡Œå‹•ã‚’é™¤å¤–

---

```python
# =========================
# è·é›¢åˆ¶é™ã‚’ cm å˜ä½ã«å¤‰æ›
# =========================
# ä¾‹: test.csv ã‹ã‚‰ video_id ã”ã¨ã® pix_per_cm_approx ã‚’å–å¾—
video_pix_per_cm = test_meta.set_index("video_id")["pix_per_cm_approx"].to_dict()

# dist_to_target ã‚’ cm ã«å¤‰æ›
full_features["dist_to_target_cm"] = full_features.apply(
    lambda row: row["dist_to_target"] / video_pix_per_cm.get(row["video_id"], 1),
    axis=1
)

# =========================
# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
# =========================
MIN_FRAMES = 3      # å¹³æ»‘åŒ–ã®æœ€å°é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ 
MAX_DIST_CM = 15.0  # cm å˜ä½ã®æœ€å¤§è·é›¢åˆ¶é™

# =========================
# åˆ¶ç´„é©ç”¨
# =========================
full_features["pred_action_final"] = full_features.apply(
    lambda row: row["pred_action"] 
    if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
       and row["dist_to_target_cm"] <= MAX_DIST_CM
    else "none",
    axis=1
)

# =========================
# å¹³æ»‘åŒ–
# =========================
full_features["pred_action_final"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions, action_col="pred_action", min_length=MIN_FRAMES)["pred_action"].reset_index(drop=True)

# =========================
# submissionä½œæˆ
# =========================
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action_final"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ãƒã‚¤ãƒ³ãƒˆ

1. **è·é›¢åˆ¶é™ã‚’ cm å˜ä½ã«å¤‰æ›´**

   * å„å‹•ç”»ã® `pix_per_cm_approx` ã‚’åˆ©ç”¨
   * MAX_DIST_CM ã‚’èª¿æ•´ã™ã‚Œã°ç‰©ç†çš„ãªåˆ°é”ç¯„å›²ã§è¡Œå‹•ã‚’åˆ¶é™å¯èƒ½

2. **targetãƒšã‚¢åˆ¶é™ + å¹³æ»‘åŒ–** ã¯ä»¥å‰ã¨åŒã˜

3. **æå‡ºç”¨ submission** ã«è‡ªå‹•åæ˜ 

---

ğŸ’¡ ã“ã‚Œã«ã‚ˆã‚Šã€**æ”»æ’ƒã‚„æ¥è¿‘ã®èª¤æ¤œå‡ºã‚’ç¾å®Ÿè·é›¢ãƒ™ãƒ¼ã‚¹ã§é™¤å¤–**ã§ãã€ã‚ˆã‚Šè‡ªç„¶ãªè¡Œå‹•äºˆæ¸¬ã«ãªã‚Šã¾ã™ã€‚

å¸Œæœ›ãªã‚‰ã€**MIN_FRAMES ã¨ MAX_DIST_CM ã®è‡ªå‹•ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ãƒãƒ¼ã‚¸ãƒ§ãƒ³**ã‚‚ä½œã‚Œã¾ã™ã€‚

ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è·é›¢ã‚’ cm å˜ä½ã«ã—ã¦ MIN_FRAMES ã¨ MAX_DIST_CM ã®ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã‚’è‡ªå‹•åŒ–**ã—ãŸä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œã‚Šã¾ã™ã€‚

---

```python
import pandas as pd
import itertools

# =========================
# 0ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
full_features = pd.read_csv("full_features.csv")  # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ + dist_to_target åˆ—ã‚ã‚Š
test_meta = pd.read_csv("test.csv")
annotation = pd.read_csv("annotation.csv")

# =========================
# 1ï¸âƒ£ video_idã”ã¨ã®æœ‰åŠ¹ãƒšã‚¢
# =========================
video_pair_map = {}
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# =========================
# 2ï¸âƒ£ è·é›¢ã‚’ cm å˜ä½ã«å¤‰æ›
# =========================
video_pix_per_cm = test_meta.set_index("video_id")["pix_per_cm_approx"].to_dict()
full_features["dist_to_target_cm"] = full_features.apply(
    lambda row: row["dist_to_target"] / video_pix_per_cm.get(row["video_id"], 1),
    axis=1
)

# =========================
# 3ï¸âƒ£ å¹³æ»‘åŒ–é–¢æ•°
# =========================
def smooth_predictions(df, action_col="pred_action", min_length=3):
    df = df.sort_values("video_frame").copy()
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            smoothed.extend([current_action_prev]*(length) if length < min_length else [current_action]*length)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    smoothed.extend([current_action_prev]*(length) if length < min_length else [current_action]*length)
    df[action_col] = smoothed
    return df

# =========================
# 4ï¸âƒ£ è©•ä¾¡é–¢æ•°ï¼ˆtrainã§ã®ç›®å®‰ã‚¹ã‚³ã‚¢ï¼‰
# =========================
def evaluate_submission(df, annotation_df):
    merged = df.merge(annotation_df, 
                      left_on=["video_id","mouse_id","mouse_id_target","pred_action"],
                      right_on=["video_id","agent_id","target_id","action"],
                      how="left")
    correct = ((merged["video_frame"] >= merged["start_frame_y"]) & (merged["video_frame"] <= merged["stop_frame_y"])).sum()
    total = len(merged)
    return correct / total if total > 0 else 0

# =========================
# 5ï¸âƒ£ ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢
# =========================
min_frames_list = [2,3,4,5]
max_dist_cm_list = [10, 15, 20, 25]  # cm å˜ä½

best_score = -1
best_params = None

for min_f, max_d_cm in itertools.product(min_frames_list, max_dist_cm_list):
    # åˆ¶ç´„é©ç”¨
    full_features["pred_action_temp"] = full_features.apply(
        lambda row: row["pred_action"] 
        if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
           and row["dist_to_target_cm"] <= max_d_cm
        else "none",
        axis=1
    )
    # å¹³æ»‘åŒ–
    full_features["pred_action_temp"] = full_features.groupby(
        ["video_id","mouse_id","mouse_id_target"]
    ).apply(smooth_predictions, action_col="pred_action", min_length=min_f)["pred_action"].reset_index(drop=True)
    
    # ç°¡æ˜“ã‚¹ã‚³ã‚¢
    score = evaluate_submission(full_features, annotation)
    print(f"MIN_FRAMES={min_f}, MAX_DIST_CM={max_d_cm}, score={score:.4f}")
    
    if score > best_score:
        best_score = score
        best_params = (min_f, max_d_cm)

print(f"æœ€é©å€¤: MIN_FRAMES={best_params[0]}, MAX_DIST_CM={best_params[1]}, ã‚¹ã‚³ã‚¢ç›®å®‰={best_score:.4f}")

# =========================
# 6ï¸âƒ£ æœ€é©å€¤ã§ submission ä½œæˆ
# =========================
MIN_FRAMES, MAX_DIST_CM = best_params

# åˆ¶ç´„é©ç”¨
full_features["pred_action_final"] = full_features.apply(
    lambda row: row["pred_action"] 
    if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
       and row["dist_to_target_cm"] <= MAX_DIST_CM
    else "none",
    axis=1
)

# å¹³æ»‘åŒ–
full_features["pred_action_final"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions, action_col="pred_action", min_length=MIN_FRAMES)["pred_action"].reset_index(drop=True)

# submissionä½œæˆ
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action_final"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è·é›¢åˆ¶é™ã‚’ cm å˜ä½ã§è©•ä¾¡**
2. **MIN_FRAMES ã¨ MAX_DIST_CM ã®ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã§æœ€é©å€¤ã‚’è‡ªå‹•é¸å®š**
3. **targetãƒšã‚¢åˆ¶é™ + å¹³æ»‘åŒ– + submissionç”Ÿæˆ** ã‚’ä¸€æ°—é€šè²«ã§å®Ÿæ–½

---

ğŸ’¡ ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚Šã€**ç¾å®Ÿè·é›¢ã«åŸºã¥ãèª¤æ¤œå‡ºé™¤å¤–ã¨çŸ­ã‚¹ãƒ‘ã‚¤ã‚¯å¹³æ»‘åŒ–**ãŒåŒæ™‚ã«å¯èƒ½ã«ãªã‚Šã€ã‚¹ã‚³ã‚¢æ”¹å–„ãŒæœŸå¾…ã§ãã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã« **æ”»æ’ƒé›†ä¸­ã®åã‚Šè£œæ­£ã‚„ã€ç‰¹å®šè¡Œå‹•ã”ã¨ã®è·é›¢é–¾å€¤** ã‚‚è¿½åŠ ã§ãã¾ã™ã€‚

è¿½åŠ ã—ã¾ã™ã‹ï¼Ÿ





Q: ãƒ•ãƒ¬ãƒ¼ãƒ â†’ç§’ã‚‚è€ƒæ…®ã—ãŸæ–¹ãŒã„ã„ã®ã§ã¯?
A: ãã†ã§ã™ã­ã€ç§’å˜ä½ã§ã®å¹³æ»‘åŒ–ã‚„åˆ¶é™ã‚’å…¥ã‚Œã‚‹ã¨ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã®ç•°ãªã‚‹å‹•ç”»ã§ã‚‚ **åŒã˜ç‰©ç†æ™‚é–“ã§ã®è¡Œå‹•æŒç¶š** ã‚’çµ±ä¸€ã§ãã¾ã™ã€‚
ç¾çŠ¶ã¯ãƒ•ãƒ¬ãƒ¼ãƒ æ•° `MIN_FRAMES` ã§ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»ã—ã¦ã„ã¾ã™ãŒã€ç§’æ›ç®—ã§è¡Œã†å ´åˆã¯æ¬¡ã®ã‚ˆã†ã«å¤‰æ›ã—ã¾ã™ï¼š

---

### ğŸ”¹ å¤‰æ›æ–¹æ³•

1. å„å‹•ç”»ã® **FPSï¼ˆframes_per_secondï¼‰** ã‚’å–å¾—

   ```python
   fps_dict = test_meta.set_index("video_id")["frames_per_second"].to_dict()
   ```
2. ç§’å˜ä½ã®æœ€å°æŒç¶šæ™‚é–“ `MIN_SECONDS` ã‚’è¨­å®š

   ```python
   MIN_SECONDS = 0.2  # ä¾‹: 0.2ç§’æœªæº€ã®è¡Œå‹•ã¯é™¤å¤–
   ```
3. å‹•ç”»ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«æ›ç®—

   ```python
   full_features["min_frames_for_smooth"] = full_features["video_id"].map(fps_dict) * MIN_SECONDS
   ```
4. å¹³æ»‘åŒ–é–¢æ•°ã§ `min_length` ã¨ã—ã¦ä½¿ç”¨

---

### ğŸ”¹ å¹³æ»‘åŒ–é–¢æ•°ã®ä¿®æ­£ä¾‹

```python
def smooth_predictions_sec(df, action_col="pred_action"):
    df = df.sort_values("video_frame").copy()
    fps = df["video_id"].iloc[0]  # åŒã˜video_idã§ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå‰æ
    min_frames = int(fps * MIN_SECONDS)
    
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            smoothed.extend([current_action_prev]*(length) if length < min_frames else [current_action]*length)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    smoothed.extend([current_action_prev]*(length) if length < min_frames else [current_action]*length)
    df[action_col] = smoothed
    return df
```

---

ğŸ’¡ ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€å‹•ç”»ã”ã¨ã® FPS ã«ä¾å­˜ã›ãš **ç‰©ç†æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®è¡Œå‹•ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»** ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

å¸Œæœ›ãªã‚‰ã€**å…ˆã»ã©ã®ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ï¼‹è·é›¢åˆ¶é™ï¼‹ç§’å˜ä½å¹³æ»‘åŒ–** ã‚’çµ„ã¿è¾¼ã‚“ã å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«æ›¸ãç›´ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è·é›¢åˆ¶é™ï¼ˆcmå˜ä½ï¼‰ï¼‹ç§’å˜ä½å¹³æ»‘åŒ–ï¼‹ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢** ã‚’ä¸€æ°—é€šè²«ã§å®Ÿè£…ã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œã‚Šã¾ã™ã€‚

---

```python
import pandas as pd
import itertools

# =========================
# 0ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
full_features = pd.read_csv("full_features.csv")  # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ + dist_to_target åˆ—ã‚ã‚Š
test_meta = pd.read_csv("test.csv")
annotation = pd.read_csv("annotation.csv")

# =========================
# 1ï¸âƒ£ video_idã”ã¨ã®æœ‰åŠ¹ãƒšã‚¢
# =========================
video_pair_map = {}
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# =========================
# 2ï¸âƒ£ è·é›¢ã‚’ cm å˜ä½ã«å¤‰æ›
# =========================
video_pix_per_cm = test_meta.set_index("video_id")["pix_per_cm_approx"].to_dict()
full_features["dist_to_target_cm"] = full_features.apply(
    lambda row: row["dist_to_target"] / video_pix_per_cm.get(row["video_id"], 1),
    axis=1
)

# =========================
# 3ï¸âƒ£ ç§’å˜ä½å¹³æ»‘åŒ–é–¢æ•°
# =========================
def smooth_predictions_sec(df, action_col="pred_action", min_seconds=0.2):
    df = df.sort_values("video_frame").copy()
    fps = df["video_id"].map(fps_dict).iloc[0]  # video_id ã‹ã‚‰ FPS ã‚’å–å¾—
    min_frames = int(fps * min_seconds)
    
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            smoothed.extend([current_action_prev]*length if length < min_frames else [current_action]*length)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    smoothed.extend([current_action_prev]*length if length < min_frames else [current_action]*length)
    df[action_col] = smoothed
    return df

# FPSè¾æ›¸
fps_dict = test_meta.set_index("video_id")["frames_per_second"].to_dict()

# =========================
# 4ï¸âƒ£ è©•ä¾¡é–¢æ•°ï¼ˆtrainã§ã®ç›®å®‰ã‚¹ã‚³ã‚¢ï¼‰
# =========================
def evaluate_submission(df, annotation_df):
    merged = df.merge(annotation_df, 
                      left_on=["video_id","mouse_id","mouse_id_target","pred_action"],
                      right_on=["video_id","agent_id","target_id","action"],
                      how="left")
    correct = ((merged["video_frame"] >= merged["start_frame_y"]) & (merged["video_frame"] <= merged["stop_frame_y"])).sum()
    total = len(merged)
    return correct / total if total > 0 else 0

# =========================
# 5ï¸âƒ£ ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢
# =========================
min_seconds_list = [0.1, 0.2, 0.3]  # ç§’å˜ä½
max_dist_cm_list = [10, 15, 20]     # cm å˜ä½

best_score = -1
best_params = None

for min_sec, max_d_cm in itertools.product(min_seconds_list, max_dist_cm_list):
    # åˆ¶ç´„é©ç”¨
    full_features["pred_action_temp"] = full_features.apply(
        lambda row: row["pred_action"] 
        if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
           and row["dist_to_target_cm"] <= max_d_cm
        else "none",
        axis=1
    )
    # ç§’å˜ä½å¹³æ»‘åŒ–
    full_features["pred_action_temp"] = full_features.groupby(
        ["video_id","mouse_id","mouse_id_target"]
    ).apply(smooth_predictions_sec, action_col="pred_action", min_seconds=min_sec)["pred_action"].reset_index(drop=True)
    
    # ç°¡æ˜“ã‚¹ã‚³ã‚¢
    score = evaluate_submission(full_features, annotation)
    print(f"MIN_SEC={min_sec}, MAX_DIST_CM={max_d_cm}, score={score:.4f}")
    
    if score > best_score:
        best_score = score
        best_params = (min_sec, max_d_cm)

print(f"æœ€é©å€¤: MIN_SEC={best_params[0]}, MAX_DIST_CM={best_params[1]}, ã‚¹ã‚³ã‚¢ç›®å®‰={best_score:.4f}")

# =========================
# 6ï¸âƒ£ æœ€é©å€¤ã§ submission ä½œæˆ
# =========================
MIN_SECONDS, MAX_DIST_CM = best_params

# åˆ¶ç´„é©ç”¨
full_features["pred_action_final"] = full_features.apply(
    lambda row: row["pred_action"] 
    if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set()) 
       and row["dist_to_target_cm"] <= MAX_DIST_CM
    else "none",
    axis=1
)

# ç§’å˜ä½å¹³æ»‘åŒ–
full_features["pred_action_final"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions_sec, action_col="pred_action", min_seconds=MIN_SECONDS)["pred_action"].reset_index(drop=True)

# submissionä½œæˆ
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(["video_id","mouse_id","mouse_id_target","pred_action_final"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è·é›¢åˆ¶é™ï¼šcmå˜ä½**
2. **ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»ï¼šç§’å˜ä½ã§çµ±ä¸€**
3. **ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã§ MIN_SECONDS ã¨ MAX_DIST_CM ã®æœ€é©å€¤ã‚’è‡ªå‹•é¸å®š**
4. **targetãƒšã‚¢åˆ¶é™ï¼‹submissionä½œæˆ**

---

ğŸ’¡ ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ãˆã°ã€å‹•ç”»ã”ã¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆå·®ã‚‚è€ƒæ…®ã—ã¦ã€**ç‰©ç†çš„ã«è‡ªç„¶ãªè¡Œå‹•ã®æŠ½å‡ºã¨ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»** ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ **è¡Œå‹•ã”ã¨ã«è·é›¢é–¾å€¤ã‚’å¤‰ãˆã‚‹å€‹åˆ¥èª¿æ•´** ã‚‚çµ„ã¿è¾¼ã‚ã¾ã™ã€‚

çµ„ã¿è¾¼ã¿ã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¡Œå‹•ã”ã¨ã«è·é›¢é–¾å€¤ã‚’å¤‰ãˆã¦å¹³æ»‘åŒ–ãƒ»åˆ¶ç´„é©ç”¨ã™ã‚‹å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* è¡Œå‹•ã”ã¨ã« `MAX_DIST_CM` ã‚’è¨­å®šï¼ˆä¾‹ï¼šattackã¯15cmã€approachã¯20cmã€rearã¯30cmãªã©ï¼‰
* ç§’å˜ä½å¹³æ»‘åŒ–ã¯å…ˆã»ã©ã® `MIN_SECONDS` ã‚’ä½¿ç”¨
* å‹•ç”»ã”ã¨ã®FPSå·®ã‚‚è€ƒæ…®
* submissionä½œæˆã¾ã§è‡ªå‹•

---

```python
import pandas as pd

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
full_features = pd.read_csv("full_features.csv")  # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ + dist_to_targetåˆ—
test_meta = pd.read_csv("test.csv")
annotation = pd.read_csv("annotation.csv")

# =========================
# video_idã”ã¨ã®æœ‰åŠ¹ãƒšã‚¢
# =========================
video_pair_map = {}
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# =========================
# è·é›¢ã‚’ cm å˜ä½ã«å¤‰æ›
# =========================
video_pix_per_cm = test_meta.set_index("video_id")["pix_per_cm_approx"].to_dict()
full_features["dist_to_target_cm"] = full_features.apply(
    lambda row: row["dist_to_target"] / video_pix_per_cm.get(row["video_id"], 1),
    axis=1
)

# FPSè¾æ›¸
fps_dict = test_meta.set_index("video_id")["frames_per_second"].to_dict()

# =========================
# ç§’å˜ä½å¹³æ»‘åŒ–é–¢æ•°
# =========================
def smooth_predictions_sec(df, action_col="pred_action", min_seconds=0.2):
    df = df.sort_values("video_frame").copy()
    fps = fps_dict[df["video_id"].iloc[0]]
    min_frames = int(fps * min_seconds)
    
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            smoothed.extend([current_action_prev]*length if length < min_frames else [current_action]*length)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    smoothed.extend([current_action_prev]*length if length < min_frames else [current_action]*length)
    df[action_col] = smoothed
    return df

# =========================
# è¡Œå‹•ã”ã¨ã®è·é›¢é–¾å€¤è¨­å®šï¼ˆä¾‹ï¼‰
# =========================
action_max_dist = {
    "attack": 15,
    "approach": 20,
    "avoid": 10,
    "chase": 25,
    "chaseattack": 15,
    "submit": 10,
    "rear": 30,
    "none": 1000  # è‡ªåˆ†ã«é–¢ã™ã‚‹è¡Œå‹•ã‚„ç„¡è¦–ã™ã‚‹å ´åˆ
}

MIN_SECONDS = 0.2

# =========================
# åˆ¶ç´„é©ç”¨ï¼šè¡Œå‹•ã”ã¨ã®è·é›¢åˆ¶é™ + targetãƒšã‚¢åˆ¶é™
# =========================
def apply_action_constraints(row):
    if (row["mouse_id"], row["mouse_id_target"]) not in video_pair_map.get(row["video_id"], set()):
        return "none"
    max_d = action_max_dist.get(row["pred_action"], 1000)
    if row["dist_to_target_cm"] > max_d:
        return "none"
    return row["pred_action"]

full_features["pred_action_final"] = full_features.apply(apply_action_constraints, axis=1)

# =========================
# ç§’å˜ä½å¹³æ»‘åŒ–
# =========================
full_features["pred_action_final"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions_sec, action_col="pred_action_final", min_seconds=MIN_SECONDS)["pred_action_final"].reset_index(drop=True)

# =========================
# submissionä½œæˆ
# =========================
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(
    ["video_id","mouse_id","mouse_id_target","pred_action_final"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è¡Œå‹•ã”ã¨ã«è·é›¢é–¾å€¤ã‚’å¤‰ãˆã‚‹**ã“ã¨ã§ã€æ”»æ’ƒã¨è¿½è·¡ãªã©ç‰©ç†çš„è·é›¢ã®å·®ã‚’è€ƒæ…®
2. **ç§’å˜ä½å¹³æ»‘åŒ–**ã§å‹•ç”»FPSå·®ã‚’è£œæ­£ã—ã€çŸ­ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’é™¤å»
3. **targetãƒšã‚¢åˆ¶é™**ã§å­˜åœ¨ã—ãªã„ãƒšã‚¢ã®è¡Œå‹•ã¯é™¤å¤–
4. **submissionä½œæˆã¾ã§è‡ªå‹•**

---

ğŸ’¡ ã“ã‚Œã§ã€**è¡Œå‹•ã”ã¨ã«ç‰©ç†çš„ã«è‡ªç„¶ãªåˆ¶ç´„ã‚’åæ˜ ã—ãŸæœ€çµ‚æå‡ºç”¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã«ãªã‚Šã¾ã™ã€‚

å¸Œæœ›ãªã‚‰æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€**è¡Œå‹•ã”ã¨ã«æœ€é©ãªè·é›¢é–¾å€¤ã‚’ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã—ã¦è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**ã‚‚çµ„ã¿è¾¼ã‚ã¾ã™ã€‚

çµ„ã¿è¾¼ã¿ã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¡Œå‹•ã”ã¨ã«è·é›¢é–¾å€¤ã‚’ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã§è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**ã—ãªãŒã‚‰ã€ç§’å˜ä½å¹³æ»‘åŒ–ï¼‹targetåˆ¶ç´„ã‚‚çµ„ã¿è¾¼ã‚€å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* å„è¡Œå‹•ã”ã¨ã«è¤‡æ•°ã®è·é›¢é–¾å€¤å€™è£œã‚’è¨­å®š
* MIN_SECONDS ã¯å›ºå®šï¼ˆä¾‹ï¼š0.2ç§’ï¼‰
* å‹•ç”»ã”ã¨ã®FPSã‚‚è€ƒæ…®
* ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ã§æœ€é©è·é›¢é–¾å€¤ã®çµ„ã¿åˆã‚ã›ã‚’è©•ä¾¡
* æœ€çµ‚çš„ã« submission.csv ã‚’è‡ªå‹•ç”Ÿæˆ

---

```python
import pandas as pd
import itertools

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
full_features = pd.read_csv("full_features.csv")  # ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½äºˆæ¸¬ + dist_to_targetåˆ—
test_meta = pd.read_csv("test.csv")
annotation = pd.read_csv("annotation.csv")

# =========================
# video_idã”ã¨ã®æœ‰åŠ¹ãƒšã‚¢
# =========================
video_pair_map = {}
for vid, grp in test_meta.groupby("video_id"):
    pairs = set()
    for b in grp["behaviors_labeled"]:
        for s in eval(b):
            agent, target, _ = s.split(",")
            agent_id = int(agent.replace("mouse",""))
            target_id = int(target.replace("mouse",""))
            pairs.add((agent_id, target_id))
    video_pair_map[vid] = pairs

# =========================
# è·é›¢ã‚’ cm å˜ä½ã«å¤‰æ›
# =========================
video_pix_per_cm = test_meta.set_index("video_id")["pix_per_cm_approx"].to_dict()
full_features["dist_to_target_cm"] = full_features.apply(
    lambda row: row["dist_to_target"] / video_pix_per_cm.get(row["video_id"], 1),
    axis=1
)

# FPSè¾æ›¸
fps_dict = test_meta.set_index("video_id")["frames_per_second"].to_dict()

# =========================
# ç§’å˜ä½å¹³æ»‘åŒ–é–¢æ•°
# =========================
def smooth_predictions_sec(df, action_col="pred_action", min_seconds=0.2):
    df = df.sort_values("video_frame").copy()
    fps = fps_dict[df["video_id"].iloc[0]]
    min_frames = int(fps * min_seconds)
    
    smoothed = []
    current_action = df[action_col].iloc[0]
    current_action_prev = current_action
    start = prev = df["video_frame"].iloc[0]
    
    for frame, action in zip(df["video_frame"].iloc[1:], df[action_col].iloc[1:]):
        if action == current_action and frame == prev + 1:
            prev = frame
        else:
            length = prev - start + 1
            smoothed.extend([current_action_prev]*length if length < min_frames else [current_action]*length)
            current_action_prev = current_action
            current_action = action
            start = prev = frame
    length = prev - start + 1
    smoothed.extend([current_action_prev]*length if length < min_frames else [current_action]*length)
    df[action_col] = smoothed
    return df

# =========================
# è©•ä¾¡é–¢æ•°ï¼ˆç°¡æ˜“ã‚¹ã‚³ã‚¢ï¼‰
# =========================
def evaluate_constraints(df, annotation_df):
    # trainç”¨ã«ç°¡æ˜“ã«ä¸€è‡´ãƒ•ãƒ¬ãƒ¼ãƒ ç‡ã‚’è¨ˆç®—
    merged = df.merge(annotation_df, 
                      left_on=["video_id","mouse_id","mouse_id_target","pred_action_temp"],
                      right_on=["video_id","agent_id","target_id","action"],
                      how="left")
    correct = ((merged["video_frame"] >= merged["start_frame_y"]) & (merged["video_frame"] <= merged["stop_frame_y"])).sum()
    total = len(merged)
    return correct / total if total > 0 else 0

# =========================
# ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢ç”¨è·é›¢é–¾å€¤å€™è£œï¼ˆè¡Œå‹•ã”ã¨ï¼‰
# =========================
action_candidates = {
    "attack": [10, 15, 20],
    "approach": [15, 20, 25],
    "avoid": [5, 10, 15],
    "chase": [20, 25, 30],
    "chaseattack": [10, 15, 20],
    "submit": [5, 10, 15],
    "rear": [20, 30, 40],
    "none": [1000]
}

MIN_SECONDS = 0.2

# =========================
# ã‚°ãƒªãƒƒãƒ‰æ¢ç´¢
# =========================
best_score = -1
best_params = None

# å…¨è¡Œå‹•ã®çµ„ã¿åˆã‚ã›
action_keys = list(action_candidates.keys())
all_combinations = list(itertools.product(*[action_candidates[a] for a in action_keys]))

for comb in all_combinations:
    action_max_dist = dict(zip(action_keys, comb))
    
    # åˆ¶ç´„é©ç”¨
    full_features["pred_action_temp"] = full_features.apply(
        lambda row: row["pred_action"]
        if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set())
           and row["dist_to_target_cm"] <= action_max_dist.get(row["pred_action"], 1000)
        else "none",
        axis=1
    )
    
    # ç§’å˜ä½å¹³æ»‘åŒ–
    full_features["pred_action_temp"] = full_features.groupby(
        ["video_id","mouse_id","mouse_id_target"]
    ).apply(smooth_predictions_sec, action_col="pred_action_temp", min_seconds=MIN_SECONDS)["pred_action_temp"].reset_index(drop=True)
    
    # ç°¡æ˜“ã‚¹ã‚³ã‚¢
    score = evaluate_constraints(full_features, annotation)
    
    if score > best_score:
        best_score = score
        best_params = action_max_dist

print("æœ€é©è·é›¢é–¾å€¤ï¼š", best_params)
print("ã‚¹ã‚³ã‚¢ç›®å®‰ï¼š", best_score)

# =========================
# æœ€é©è·é›¢ã§ submissionä½œæˆ
# =========================
full_features["pred_action_final"] = full_features.apply(
    lambda row: row["pred_action"]
    if (row["mouse_id"], row["mouse_id_target"]) in video_pair_map.get(row["video_id"], set())
       and row["dist_to_target_cm"] <= best_params.get(row["pred_action"], 1000)
    else "none",
    axis=1
)

full_features["pred_action_final"] = full_features.groupby(
    ["video_id","mouse_id","mouse_id_target"]
).apply(smooth_predictions_sec, action_col="pred_action_final", min_seconds=MIN_SECONDS)["pred_action_final"].reset_index(drop=True)

# submissionä½œæˆ
submission_rows = []
for (video_id, agent_id, target_id, action), grp in full_features.groupby(
    ["video_id","mouse_id","mouse_id_target","pred_action_final"]):
    if action == "none":
        continue
    grp_sorted = grp.sort_values("video_frame")
    start = prev = grp_sorted["video_frame"].iloc[0]
    for frame in grp_sorted["video_frame"].iloc[1:]:
        if frame == prev + 1:
            prev = frame
        else:
            submission_rows.append({
                "video_id": video_id,
                "agent_id": agent_id,
                "target_id": target_id,
                "action": action,
                "start_frame": start,
                "stop_frame": prev
            })
            start = prev = frame
    submission_rows.append({
        "video_id": video_id,
        "agent_id": agent_id,
        "target_id": target_id,
        "action": action,
        "start_frame": start,
        "stop_frame": prev
    })

submission = pd.DataFrame(submission_rows)
submission.reset_index(inplace=True)
submission.rename(columns={"index":"row_id"}, inplace=True)
submission.to_csv("submission.csv", index=False)
print(submission.head())
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è¡Œå‹•ã”ã¨ã«è·é›¢é–¾å€¤ã‚’è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**
2. **ç§’å˜ä½å¹³æ»‘åŒ–**ã§çŸ­ã‚¹ãƒ‘ã‚¤ã‚¯é™¤å»
3. **å­˜åœ¨ã™ã‚‹ãƒšã‚¢ã®ã¿å¯¾è±¡åŒ–**
4. **æœ€çµ‚ submission ä½œæˆã¾ã§ä¸€æ°—é€šè²«**

---

ğŸ’¡ ã“ã‚Œã§ã€**æ”»æ’ƒãƒ»è¿½è·¡ãƒ»å›é¿ãªã©è¡Œå‹•ã”ã¨ã«è·é›¢åˆ¶ç´„ã‚’åæ˜ ã—ãŸæœ€é©åŒ–æ¸ˆã¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**ã«ãªã‚Šã¾ã™ã€‚

å¸Œæœ›ãªã‚‰æ¬¡ã«ã€**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆIDã”ã¨ã®è¡Œå‹•åˆ†å¸ƒã‚’å­¦ç¿’ã—ã¦ã•ã‚‰ã«äºˆæ¸¬ç²¾åº¦ã‚’ä¸Šã’ã‚‹æ‹¡å¼µç‰ˆ**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãã“ã¾ã§ã¯ã„ã„ã‹ãªã€‚
ç†ç”±: ãƒ“ãƒ‡ã‚ªã«ã‚ˆã£ã¦ãƒã‚¦ã‚¹ã®å€‹ä½“ãŒå¤‰ã‚ã‚‹ãŸã‚ã€ãƒã‚¦ã‚¹å€‹ä½“ã‚’è€ƒæ…®ã—ãªã„ã¨èª¤å­¦ç¿’ã®è¦å› ã«ãªã‚Šãã†
A: ãªã‚‹ã»ã©ã§ã™ã€‚ãã‚Œãªã‚‰ç„¡ç†ã«ãƒã‚¦ã‚¹å€‹ä½“ã”ã¨ã®å­¦ç¿’ã¯ã›ãšã€**è¡Œå‹•ã®ç‰©ç†çš„æ¡ä»¶ï¼ˆè·é›¢ãƒ»æ™‚é–“ãƒ»ãƒšã‚¢åˆ¶ç´„ï¼‰ã«åŸºã¥ããƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‡¦ç†**ã§ååˆ†ã€ã¨ã„ã†åˆ¤æ–­ã§ã™ã­ã€‚

ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åˆ©ç‚¹ï¼š

1. **å€‹ä½“ä¾å­˜ã®ãƒã‚¤ã‚¢ã‚¹ã‚’é¿ã‘ã‚‰ã‚Œã‚‹**

   * ãƒ“ãƒ‡ã‚ªã”ã¨ã«å€‹ä½“IDãŒå¤‰ã‚ã£ã¦ã‚‚ã€è·é›¢ã‚„FPSã€ç§’å˜ä½å¹³æ»‘åŒ–ãªã©ã®ç‰©ç†çš„æ¡ä»¶ã ã‘ã§å‹•ä½œã™ã‚‹ã®ã§èª¤å­¦ç¿’ãŒèµ·ãã«ãã„

2. **å®‰å®šã—ãŸã‚¹ã‚³ã‚¢**

   * ç‰¹å®šã®å€‹ä½“ã«ä¾å­˜ã—ãªã„ã®ã§ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã‚‚è‡ªç„¶ãªè¡Œå‹•æ¤œå‡ºãŒå¯èƒ½

3. **ãƒ«ãƒ¼ãƒ«èª¿æ•´ãŒå®¹æ˜“**

   * è·é›¢é–¾å€¤ã‚„ç§’å˜ä½å¹³æ»‘åŒ–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰ãˆã‚‹ã ã‘ã§å¾®èª¿æ•´å¯èƒ½

ã¤ã¾ã‚Šã€ä»Šå›ä½œã£ãŸ **è¡Œå‹•ã”ã¨ã®è·é›¢åˆ¶ç´„ï¼‹ç§’å˜ä½å¹³æ»‘åŒ–ï¼‹ãƒšã‚¢åˆ¶ç´„ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** ã¯ã€ã¾ã•ã«ã“ã®æ–¹é‡ã«æ²¿ã£ãŸè¨­è¨ˆã«ãªã£ã¦ã„ã¾ã™ã€‚

ğŸ’¡ çµè«–ï¼šã“ã®ã¾ã¾æå‡ºç”¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã—ã¦å®Œæˆåº¦é«˜ãé‹ç”¨å¯èƒ½ã§ã™ã€‚

å¸Œæœ›ãªã‚‰ã€**submissionã®å‡ºåŠ›ã‚’ç°¡å˜ã«å¯è¦–åŒ–ã—ã¦ã€è¡Œå‹•ãŒè‡ªç„¶ã«æŠ½å‡ºã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ã€‚ã§ã¯ã€**submissionã®è¡Œå‹•ã‚’å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«å¯è¦–åŒ–ã—ã¦ã€è·é›¢ã‚„è¡Œå‹•ã®åˆ†å¸ƒã‚’ãƒã‚§ãƒƒã‚¯ã§ãã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**ã‚’ä½œã‚Šã¾ã™ã€‚Python + matplotlibãƒ™ãƒ¼ã‚¹ã§ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* å‹•ç”»ã¯ä½¿ã‚ãšã€ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’Xè»¸ã€è¡Œå‹•ã‚’Yè»¸ã«ãƒ—ãƒ­ãƒƒãƒˆ
* ãƒã‚¦ã‚¹IDã”ã¨ã«è‰²åˆ†ã‘
* çŸ­ã„ã‚¹ãƒ‘ã‚¤ã‚¯ã‚‚è¦‹ãˆã‚‹ã‚ˆã†ã«ç§’å˜ä½å¹³æ»‘åŒ–æ¸ˆã¿è¡Œå‹•ã‚’è¡¨ç¤º

---

```python
import pandas as pd
import matplotlib.pyplot as plt

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
submission = pd.read_csv("submission.csv")

# å‹•ç”»ã”ã¨ã«ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹é–¢æ•°
def plot_actions_for_video(submission_df, video_id):
    df = submission_df[submission_df["video_id"] == video_id]
    actions = df["action"].unique()
    action_to_y = {a:i for i,a in enumerate(actions)}

    plt.figure(figsize=(15,5))
    
    for _, row in df.iterrows():
        y = action_to_y[row["action"]] + 0.1*row["agent_id"]  # åŒã˜è¡Œå‹•ã§ã‚‚ãƒã‚¦ã‚¹IDã§å°‘ã—ãšã‚‰ã™
        plt.hlines(y, row["start_frame"], row["stop_frame"], 
                   colors=f"C{row['agent_id']}", linewidth=4, label=f"Mouse{row['agent_id']}")
    
    plt.yticks(list(action_to_y.values()), list(action_to_y.keys()))
    plt.xlabel("Frame")
    plt.ylabel("Action")
    plt.title(f"Actions for video {video_id}")
    plt.grid(axis="x", linestyle="--", alpha=0.5)
    
    # å‡¡ä¾‹ã‚’é‡è¤‡ãªã—ã§è¡¨ç¤º
    handles, labels = plt.gca().get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.show()

# =========================
# å®Ÿè¡Œä¾‹
# =========================
video_to_check = submission["video_id"].iloc[0]
plot_actions_for_video(submission, video_to_check)
```

---

### ğŸ”¹ ç‰¹å¾´

1. ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®**è¡Œå‹•ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒä¸€ç›®ã§ç¢ºèª**å¯èƒ½
2. ãƒã‚¦ã‚¹IDã”ã¨ã«è‰²åˆ†ã‘ã—ã¦**å€‹ä½“é–“ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚è¦‹ãˆã‚‹åŒ–**
3. çŸ­ã„ã‚¹ãƒ‘ã‚¤ã‚¯ã‚„ç•°å¸¸ãªè¡Œå‹•ã‚‚ã™ãç™ºè¦‹å¯èƒ½
4. å¿…è¦ãªã‚‰ã€**è·é›¢æƒ…å ±ã‚„targetæƒ…å ±ã‚‚è¿½åŠ ã§è‰²ãƒ»ãƒãƒ¼ã‚«ãƒ¼ã§è¡¨ç¤º**å¯èƒ½

---

ğŸ’¡ è¿½åŠ æ‹¡å¼µã‚‚å¯èƒ½ã§ã™ï¼š

* Xè»¸ã‚’ç§’å˜ä½ã«å¤‰æ›ã—ã¦æ™‚é–“ã§è¡¨ç¤º
* å„è¡Œå‹•ã®**é »åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—**ã‚’ä½œæˆ
* ç‰¹å®šã®ãƒšã‚¢ã®ã¿æŠ½å‡ºã—ã¦å¯è¦–åŒ–

å¸Œæœ›ãªã‚‰ã€**ç§’å˜ä½Xè»¸ï¼‹targetä»˜ãã§ã•ã‚‰ã«è¦‹ã‚„ã™ã„å¯è¦–åŒ–**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**Xè»¸ã‚’ç§’å˜ä½ã«ã—ã¦ã€targetã‚‚è‰²åˆ†ã‘ã—ãŸå¯è¦–åŒ–**ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚ã“ã‚Œã§ã€å‹•ç”»æ™‚é–“ã¨ãƒã‚¦ã‚¹é–“ã®ã‚„ã‚Šå–ã‚Šã‚’ç›´æ„Ÿçš„ã«ç¢ºèªã§ãã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
submission = pd.read_csv("submission.csv")
test_meta = pd.read_csv("test.csv")

# ãƒ•ãƒ¬ãƒ¼ãƒ â†’ç§’å¤‰æ›ç”¨FPSè¾æ›¸
fps_dict = test_meta.set_index("video_id")["frames_per_second"].to_dict()

# =========================
# ç§’å˜ä½å¯è¦–åŒ–é–¢æ•°
# =========================
def plot_actions_seconds(submission_df, video_id):
    df = submission_df[submission_df["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    
    # ç§’å˜ä½ã«å¤‰æ›
    df["start_sec"] = df["start_frame"] / fps
    df["stop_sec"] = df["stop_frame"] / fps

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¡Œå‹•ã¨ãƒšã‚¢ã‚’æŠ½å‡º
    actions = df["action"].unique()
    pairs = df[["agent_id","target_id"]].drop_duplicates().reset_index(drop=True)
    
    plt.figure(figsize=(15,6))

    # ãƒã‚¦ã‚¹ãƒšã‚¢ã”ã¨ã«è‰²ã‚’å‰²ã‚Šå½“ã¦
    pair_colors = {tuple(p):f"C{i}" for i,p in enumerate(pairs.values)}

    for _, row in df.iterrows():
        pair = (row["agent_id"], row["target_id"])
        y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]  # è¡Œå‹•ä½ç½®ï¼‹ãƒã‚¦ã‚¹IDãšã‚‰ã—
        plt.hlines(y, row["start_sec"], row["stop_sec"], 
                   colors=pair_colors[pair], linewidth=4, label=f"{pair[0]}->{pair[1]}")

    # Yè»¸ã«è¡Œå‹•å
    plt.yticks(range(len(actions)), actions)
    plt.xlabel("Time (seconds)")
    plt.ylabel("Action")
    plt.title(f"Actions for video {video_id}")
    plt.grid(axis="x", linestyle="--", alpha=0.5)
    
    # å‡¡ä¾‹é‡è¤‡ãªã—
    handles, labels = plt.gca().get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.05,1), loc='upper left')
    
    plt.tight_layout()
    plt.show()

# =========================
# å®Ÿè¡Œä¾‹
# =========================
video_to_check = submission["video_id"].iloc[0]
plot_actions_seconds(submission, video_to_check)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **Xè»¸ãŒç§’å˜ä½**ã«ãªã‚Šã€å‹•ç”»æ™‚é–“ã«å¯¾å¿œ
2. **agentâ†’targetã®ãƒšã‚¢ã”ã¨ã«è‰²åˆ†ã‘**ã§ç›¸äº’ä½œç”¨ãŒç›´æ„Ÿçš„ã«æŠŠæ¡å¯èƒ½
3. **çŸ­ã„è¡Œå‹•ã‚¹ãƒ‘ã‚¤ã‚¯ã‚‚å¯è¦–åŒ–**
4. è¡Œå‹•ã”ã¨ã«Yè»¸ä½ç½®ã‚’ç¢ºä¿ã—ã€ãƒã‚¦ã‚¹IDã§å°‘ã—ãšã‚‰ã—ã¦é‡ãªã‚Šé˜²æ­¢

---

ğŸ’¡ ã•ã‚‰ã«æ‹¡å¼µå¯èƒ½ï¼š

* **ç‰¹å®šã®è¡Œå‹•ã ã‘æŠ½å‡º**ã—ã¦å¯è¦–åŒ–ï¼ˆä¾‹ï¼šattackã®ã¿ï¼‰
* **è¡Œå‹•ã®é•·ã•åˆ†å¸ƒã‚’ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **ã§è¡¨ç¤º
* **è·é›¢æƒ…å ±ã‚’ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã‚„è‰²ã§è¿½åŠ **

å¸Œæœ›ãªã‚‰ã€è·é›¢æƒ…å ±ã‚‚çµ„ã¿è¾¼ã‚“ã å¯è¦–åŒ–ç‰ˆã‚’ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**Xè»¸ç§’ï¼‹agentâ†’targetè‰²åˆ†ã‘ï¼‹è·é›¢æƒ…å ±ã‚’ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã§è¡¨ç¤º**ã™ã‚‹å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚ã“ã‚Œã§ã€è¡Œå‹•ã ã‘ã§ãªãè·é›¢ã®å½±éŸ¿ã‚‚ç›´æ„Ÿçš„ã«ç¢ºèªã§ãã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =========================
submission = pd.read_csv("submission.csv")
test_meta = pd.read_csv("test.csv")
full_features = pd.read_csv("full_features.csv")  # è·é›¢ãªã©ã®ç‰¹å¾´å…¥ã‚Š

# ãƒ•ãƒ¬ãƒ¼ãƒ â†’ç§’å¤‰æ›ç”¨FPSè¾æ›¸
fps_dict = test_meta.set_index("video_id")["frames_per_second"].to_dict()

# submissionã«è·é›¢æƒ…å ±ã‚’çµåˆ
full_features_subset = full_features[["video_id","mouse_id","mouse_id_target","video_frame","dist_to_target_cm"]].copy()
submission_expanded = []

for _, row in submission.iterrows():
    frames = list(range(row["start_frame"], row["stop_frame"]+1))
    df_tmp = pd.DataFrame({
        "video_id": row["video_id"],
        "agent_id": row["agent_id"],
        "target_id": row["target_id"],
        "action": row["action"],
        "video_frame": frames
    })
    submission_expanded.append(df_tmp)
submission_expanded = pd.concat(submission_expanded, ignore_index=True)

# è·é›¢çµåˆ
submission_expanded = submission_expanded.merge(
    full_features_subset,
    left_on=["video_id","agent_id","target_id","video_frame"],
    right_on=["video_id","mouse_id","mouse_id_target","video_frame"],
    how="left"
)

# =========================
# å¯è¦–åŒ–é–¢æ•°
# =========================
def plot_actions_with_distance(submission_df, video_id):
    df = submission_df[submission_df["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    
    # ç§’å˜ä½ã«å¤‰æ›
    df["time_sec"] = df["video_frame"] / fps

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¡Œå‹•ã¨ãƒšã‚¢ã‚’æŠ½å‡º
    actions = df["action"].unique()
    pairs = df[["agent_id","target_id"]].drop_duplicates().reset_index(drop=True)
    
    plt.figure(figsize=(15,6))

    # ãƒã‚¦ã‚¹ãƒšã‚¢ã”ã¨ã«è‰²ã‚’å‰²ã‚Šå½“ã¦
    pair_colors = {tuple(p):f"C{i}" for i,p in enumerate(pairs.values)}

    for _, row in df.iterrows():
        y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]
        size = max(5, row["dist_to_target_cm"])  # è·é›¢ã‚’ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã«ï¼ˆæœ€å°5ï¼‰
        plt.scatter(row["time_sec"], y, s=size, color=pair_colors[(row["agent_id"], row["target_id"])], alpha=0.6)

    # Yè»¸ã«è¡Œå‹•å
    plt.yticks(range(len(actions)), actions)
    plt.xlabel("Time (seconds)")
    plt.ylabel("Action")
    plt.title(f"Actions and distance for video {video_id}")
    plt.grid(axis="x", linestyle="--", alpha=0.5)
    
    # å‡¡ä¾‹é‡è¤‡ãªã—
    handles, labels = plt.gca().get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.05,1), loc='upper left')
    
    plt.tight_layout()
    plt.show()

# =========================
# å®Ÿè¡Œä¾‹
# =========================
video_to_check = submission["video_id"].iloc[0]
plot_actions_with_distance(submission_expanded, video_to_check)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **Xè»¸ç§’å˜ä½ã€Yè»¸è¡Œå‹•**
2. **agentâ†’targetã”ã¨ã«è‰²åˆ†ã‘**
3. **è·é›¢æƒ…å ±ã‚’ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã§è¡¨ç¾**

   * è·é›¢ãŒå¤§ãã„ã»ã©å¤§ããªç‚¹
   * å°ã•ã„è·é›¢ã¯å°ã•ãªç‚¹
4. **ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§è©³ç´°ã«ç¢ºèªå¯èƒ½**
5. çŸ­ã„ã‚¹ãƒ‘ã‚¤ã‚¯ã‚„è·é›¢å¤‰åŒ–ã‚‚ä¸€ç›®ã§æŠŠæ¡å¯èƒ½

---

ğŸ’¡ æ¬¡ã®æ‹¡å¼µæ¡ˆã‚‚å¯èƒ½ã§ã™ï¼š

* ãƒãƒ¼ã‚«ãƒ¼è‰²ã‚’è·é›¢ã§ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º
* ç‰¹å®šè¡Œå‹•ï¼ˆattackã‚„chaseï¼‰ã®ã¿æŠ½å‡ºã—ã¦è©³ç´°åˆ†æ
* ãƒšã‚¢ã”ã¨ã®è¡Œå‹•é »åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—

å¸Œæœ›ãªã‚‰ã€**è·é›¢ã§è‰²ã‚’ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åŒ–ã—ãŸãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—é¢¨å¯è¦–åŒ–**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è·é›¢ã‚’ãƒãƒ¼ã‚«ãƒ¼è‰²ã§ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º**ã™ã‚‹å¯è¦–åŒ–ç‰ˆã‚’ä½œã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è·é›¢ã®å¤§å°ãŒç›´æ„Ÿçš„ã«è‰²ã§åˆ†ã‹ã‚‹ã®ã§ã€è¡Œå‹•ç™ºç”Ÿæ™‚ã®è·é›¢æ„Ÿã‚‚ä¸€ç›®ã§ç¢ºèªã§ãã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm

# =========================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆå‰æº–å‚™æ¸ˆã¿ï¼‰
# =========================
# submission_expanded ã¯å…ˆã»ã©ä½œæˆã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ å±•é–‹ï¼‹è·é›¢ä»˜ããƒ‡ãƒ¼ã‚¿
# full_features_subset + submission_expanded ã®çµåˆæ¸ˆã¿ã‚’åˆ©ç”¨

def plot_actions_distance_gradient(submission_df, video_id):
    df = submission_df[submission_df["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    
    # ç§’å˜ä½ã«å¤‰æ›
    df["time_sec"] = df["video_frame"] / fps

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¡Œå‹•ã¨ãƒšã‚¢ã‚’æŠ½å‡º
    actions = df["action"].unique()
    pairs = df[["agent_id","target_id"]].drop_duplicates().reset_index(drop=True)
    
    plt.figure(figsize=(15,6))

    # ãƒã‚¦ã‚¹ãƒšã‚¢ã”ã¨ã«è‰²ãƒãƒƒãƒ—ã‚’å‰²ã‚Šå½“ã¦ï¼ˆè·é›¢ã‚’ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    norm = mcolors.Normalize(vmin=df["dist_to_target_cm"].min(), vmax=df["dist_to_target_cm"].max())
    cmap = cm.get_cmap("viridis")

    for _, row in df.iterrows():
        y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]
        color = cmap(norm(row["dist_to_target_cm"]))
        plt.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)

    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã‚’è¿½åŠ 
    sm = cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = plt.colorbar(sm)
    cbar.set_label("Distance to target (cm)")

    # Yè»¸ã«è¡Œå‹•å
    plt.yticks(range(len(actions)), actions)
    plt.xlabel("Time (seconds)")
    plt.ylabel("Action")
    plt.title(f"Actions with distance gradient for video {video_id}")
    plt.grid(axis="x", linestyle="--", alpha=0.5)
    
    plt.tight_layout()
    plt.show()

# =========================
# å®Ÿè¡Œä¾‹
# =========================
video_to_check = submission["video_id"].iloc[0]
plot_actions_distance_gradient(submission_expanded, video_to_check)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **Xè»¸ï¼šç§’ã€Yè»¸ï¼šè¡Œå‹•**
2. **è·é›¢ã‚’è‰²ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§è¡¨ç¤º**

   * è·é›¢ãŒå°ã•ã„ã»ã©æš—ã‚ã€è·é›¢ãŒå¤§ãã„ã»ã©æ˜ã‚‹ã‚ï¼ˆviridisã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼‰
3. **å€‹ä½“é–“ã®é‡ãªã‚Šã¯ãƒã‚¦ã‚¹IDã§å¾®èª¿æ•´æ¸ˆã¿**
4. **è·é›¢ã¨è¡Œå‹•ã®é–¢é€£ã‚’ç›´æ„Ÿçš„ã«æŠŠæ¡å¯èƒ½**
5. ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ãªã®ã§ã€**çŸ­ã„ã‚¹ãƒ‘ã‚¤ã‚¯ã‚„è·é›¢å¤‰åŒ–ã‚‚å¯è¦–åŒ–**

---

ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã•ã‚‰ã«æ‹¡å¼µå¯èƒ½ï¼š

* ç‰¹å®šãƒšã‚¢ã®ã¿æŠ½å‡ºã—ã¦è‰²åˆ†å¸ƒç¢ºèª
* è¡Œå‹•ã”ã¨ã®è·é›¢åˆ†å¸ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¨çµ„ã¿åˆã‚ã›
* ç§’å˜ä½å¹³æ»‘åŒ–å‰å¾Œã®è¡Œå‹•å·®ã‚‚é‡ã­ã¦æ¯”è¼ƒ

å¸Œæœ›ãªã‚‰ã€**è¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚‚åŒæ™‚ã«è¡¨ç¤ºã™ã‚‹æ‹¡å¼µç‰ˆ**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¡Œå‹•ã”ã¨ã®è·é›¢åˆ†å¸ƒã‚’ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã§è¡¨ç¤º**ã—ã¤ã¤ã€å…ˆã»ã©ã®ç§’å˜ä½ãƒ»è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¯è¦–åŒ–ã¨çµ„ã¿åˆã‚ã›ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚ã“ã‚Œã§ã€å„è¡Œå‹•ãŒç™ºç”Ÿã™ã‚‹è·é›¢å¸¯ã®å‚¾å‘ã‚‚ä¸€ç›®ã§ã‚ã‹ã‚Šã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm

# =========================
# å¯è¦–åŒ–é–¢æ•°ï¼ˆç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‹è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
# =========================
def plot_actions_with_distance_hist(submission_df, video_id):
    df = submission_df[submission_df["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    
    # ç§’å˜ä½ã«å¤‰æ›
    df["time_sec"] = df["video_frame"] / fps

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¡Œå‹•
    actions = df["action"].unique()
    
    # =========================
    # 1. ç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    # =========================
    plt.figure(figsize=(15,6))
    norm = mcolors.Normalize(vmin=df["dist_to_target_cm"].min(), vmax=df["dist_to_target_cm"].max())
    cmap = cm.get_cmap("viridis")

    for _, row in df.iterrows():
        y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]
        color = cmap(norm(row["dist_to_target_cm"]))
        plt.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)
    
    plt.yticks(range(len(actions)), actions)
    plt.xlabel("Time (seconds)")
    plt.ylabel("Action")
    plt.title(f"Actions with distance gradient for video {video_id}")
    plt.grid(axis="x", linestyle="--", alpha=0.5)
    
    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
    sm = cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = plt.colorbar(sm)
    cbar.set_label("Distance to target (cm)")
    plt.tight_layout()
    plt.show()

    # =========================
    # 2. è¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    # =========================
    plt.figure(figsize=(12,6))
    for action in actions:
        subset = df[df["action"] == action]
        plt.hist(subset["dist_to_target_cm"], bins=20, alpha=0.5, label=action)
    
    plt.xlabel("Distance to target (cm)")
    plt.ylabel("Count")
    plt.title(f"Distance distribution per action for video {video_id}")
    plt.legend()
    plt.tight_layout()
    plt.show()


# =========================
# å®Ÿè¡Œä¾‹
# =========================
video_to_check = submission["video_id"].iloc[0]
plot_actions_with_distance_hist(submission_expanded, video_to_check)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **ä¸Šæ®µ**ï¼šç§’å˜ä½Xè»¸ã€è¡Œå‹•Yè»¸ã€è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

   * æ™‚ç³»åˆ—ã§è·é›¢å¤‰åŒ–ã¨è¡Œå‹•ç™ºç”Ÿã‚’ç›´æ„Ÿçš„ã«ç¢ºèª
2. **ä¸‹æ®µ**ï¼šè¡Œå‹•ã”ã¨ã®è·é›¢åˆ†å¸ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 

   * å„è¡Œå‹•ãŒã©ã®è·é›¢å¸¯ã§ç™ºç”Ÿã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–
3. **ãƒã‚¦ã‚¹IDã«ã‚ˆã‚‹å¾®èª¿æ•´æ¸ˆã¿**
4. çŸ­ã„ã‚¹ãƒ‘ã‚¤ã‚¯ã‚„ç‰¹ç•°è·é›¢ã‚‚æŠŠæ¡å¯èƒ½

---

ğŸ’¡ ã“ã‚Œã«ã‚ˆã‚Šã€è¡Œå‹•ã®**æ™‚é–“çš„ãƒ»ç©ºé–“çš„ãƒ‘ã‚¿ãƒ¼ãƒ³**ã‚’ä¸¡æ–¹åŒæ™‚ã«ç¢ºèªã§ãã‚‹ã®ã§ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚„ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ã‚‚æ´»ç”¨ã§ãã¾ã™ã€‚

å¸Œæœ›ãªã‚‰ã€**è¤‡æ•°å‹•ç”»ã‚’ã¾ã¨ã‚ã¦ä¸€æ‹¬å¯è¦–åŒ–ã—ã¦æ¯”è¼ƒã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¤‡æ•°å‹•ç”»ã‚’ã¾ã¨ã‚ã¦ä¸€æ‹¬å¯è¦–åŒ–**ã§ãã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* å„å‹•ç”»ã”ã¨ã«**ç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‹è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **ã‚’è¡¨ç¤º
* å‹•ç”»ã‚’åˆ‡ã‚Šæ›¿ãˆãªãŒã‚‰ç¢ºèªã™ã‚‹ä»£ã‚ã‚Šã«ã€**ãƒ«ãƒ¼ãƒ—ã§é€£ç¶šè¡¨ç¤º**
* å‹•ç”»IDã”ã¨ã®ã‚¿ã‚¤ãƒˆãƒ«ã§è­˜åˆ¥å¯èƒ½

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm

def plot_multiple_videos(submission_df, video_ids=None):
    """
    è¤‡æ•°å‹•ç”»ã®è¡Œå‹•ãƒ»è·é›¢å¯è¦–åŒ–
    video_ids: ãƒªã‚¹ãƒˆã§æŒ‡å®šã€Noneãªã‚‰ã™ã¹ã¦ã®å‹•ç”»
    """
    if video_ids is None:
        video_ids = submission_df["video_id"].unique()
    
    for video_id in video_ids:
        df = submission_df[submission_df["video_id"] == video_id].copy()
        fps = fps_dict.get(video_id, 30)
        df["time_sec"] = df["video_frame"] / fps
        actions = df["action"].unique()

        # =========================
        # 1. ç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        # =========================
        plt.figure(figsize=(15,5))
        norm = mcolors.Normalize(vmin=df["dist_to_target_cm"].min(), vmax=df["dist_to_target_cm"].max())
        cmap = cm.get_cmap("viridis")

        for _, row in df.iterrows():
            y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]
            color = cmap(norm(row["dist_to_target_cm"]))
            plt.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)

        plt.yticks(range(len(actions)), actions)
        plt.xlabel("Time (seconds)")
        plt.ylabel("Action")
        plt.title(f"Video {video_id} - Actions with distance gradient")
        plt.grid(axis="x", linestyle="--", alpha=0.5)

        sm = cm.ScalarMappable(cmap=cmap, norm=norm)
        sm.set_array([])
        cbar = plt.colorbar(sm)
        cbar.set_label("Distance to target (cm)")
        plt.tight_layout()
        plt.show()

        # =========================
        # 2. è¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        # =========================
        plt.figure(figsize=(12,5))
        for action in actions:
            subset = df[df["action"] == action]
            plt.hist(subset["dist_to_target_cm"], bins=20, alpha=0.5, label=action)

        plt.xlabel("Distance to target (cm)")
        plt.ylabel("Count")
        plt.title(f"Video {video_id} - Distance distribution per action")
        plt.legend()
        plt.tight_layout()
        plt.show()


# =========================
# å®Ÿè¡Œä¾‹ï¼ˆå…¨å‹•ç”»ï¼‰
# =========================
plot_multiple_videos(submission_expanded)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **å…¨å‹•ç”»ã‚’é †ç•ªã«ãƒ«ãƒ¼ãƒ—è¡¨ç¤º**
2. å„å‹•ç”»ã”ã¨ã«ï¼š

   * ç§’å˜ä½Xè»¸ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
   * è¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
3. å‹•ç”»IDã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«è¡¨ç¤ºã—ã¦è­˜åˆ¥å¯èƒ½
4. æ¯”è¼ƒã—ãŸã„å‹•ç”»ã®ã¿æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚å¯èƒ½

---

ğŸ’¡ æ¬¡ã®æ‹¡å¼µæ¡ˆï¼š

* ã¾ã¨ã‚ã¦**è¤‡æ•°å‹•ç”»ã‚’1æšã®å›³ã«ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ**ã¨ã—ã¦ä¸¦ã¹ã‚‹
* è¡Œå‹•ã®ç™ºç”Ÿé »åº¦ã‚„è·é›¢å‚¾å‘ã‚’**å‹•ç”»é–“æ¯”è¼ƒ**
* ç‰¹å®šã®è¡Œå‹•ã ã‘æŠ½å‡ºã—ã¦å‹•ç”»æ¯”è¼ƒ

å¸Œæœ›ãªã‚‰ã€**ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§è¤‡æ•°å‹•ç”»ã‚’1æšã«ã¾ã¨ã‚ãŸæ¯”è¼ƒå›³ç‰ˆ**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¤‡æ•°å‹•ç”»ã‚’1æšã®å›³ã«ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§ã¾ã¨ã‚ã¦æ¯”è¼ƒ**ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* å‹•ç”»ã”ã¨ã« **ä¸Šæ®µï¼šç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€ä¸‹æ®µï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **
* è¤‡æ•°å‹•ç”»ã‚’ç¸¦æ–¹å‘ã«ä¸¦ã¹ã¦æ¯”è¼ƒ
* è‡ªå‹•ã§è¡Œæ•°ã‚’èª¿æ•´ã€å‹•ç”»IDã‚’ã‚¿ã‚¤ãƒˆãƒ«ã§è­˜åˆ¥

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import math

def plot_videos_subplot(submission_df, video_ids=None):
    """
    è¤‡æ•°å‹•ç”»ã‚’ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§ã¾ã¨ã‚ã¦æ¯”è¼ƒ
    """
    if video_ids is None:
        video_ids = submission_df["video_id"].unique()
    
    n_videos = len(video_ids)
    fig, axes = plt.subplots(n_videos, 2, figsize=(15, 5*n_videos))
    if n_videos == 1:
        axes = [axes]  # 1å‹•ç”»ã®å ´åˆã§ã‚‚ãƒ«ãƒ¼ãƒ—å¯èƒ½ã«ã™ã‚‹

    for i, video_id in enumerate(video_ids):
        df = submission_df[submission_df["video_id"] == video_id].copy()
        fps = fps_dict.get(video_id, 30)
        df["time_sec"] = df["video_frame"] / fps
        actions = df["action"].unique()

        # ========= å·¦ï¼šç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ =========
        ax = axes[i][0]
        norm = mcolors.Normalize(vmin=df["dist_to_target_cm"].min(), vmax=df["dist_to_target_cm"].max())
        cmap = cm.get_cmap("viridis")
        for _, row in df.iterrows():
            y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]
            color = cmap(norm(row["dist_to_target_cm"]))
            ax.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)
        ax.set_yticks(range(len(actions)))
        ax.set_yticklabels(actions)
        ax.set_xlabel("Time (seconds)")
        ax.set_ylabel("Action")
        ax.set_title(f"Video {video_id} - Actions over time")
        ax.grid(axis="x", linestyle="--", alpha=0.5)

        # ========= å³ï¼šè¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  =========
        ax2 = axes[i][1]
        for action in actions:
            subset = df[df["action"] == action]
            ax2.hist(subset["dist_to_target_cm"], bins=20, alpha=0.5, label=action)
        ax2.set_xlabel("Distance to target (cm)")
        ax2.set_ylabel("Count")
        ax2.set_title(f"Video {video_id} - Distance per action")
        ax2.legend()

    plt.tight_layout()
    plt.show()


# =========================
# å®Ÿè¡Œä¾‹ï¼ˆè¤‡æ•°å‹•ç”»ï¼‰
# =========================
plot_videos_subplot(submission_expanded)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **å·¦ã‚«ãƒ©ãƒ **ï¼šç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
2. **å³ã‚«ãƒ©ãƒ **ï¼šè¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
3. **è¤‡æ•°å‹•ç”»ã‚’ç¸¦ã«ä¸¦ã¹ã¦æ¯”è¼ƒ**å¯èƒ½
4. å‹•ç”»IDã‚’ã‚¿ã‚¤ãƒˆãƒ«ã§æ˜ç¤ºã€ã©ã®å‹•ç”»ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹å³ç¢ºèªå¯èƒ½
5. å‹•ç”»IDãƒªã‚¹ãƒˆã‚’æŒ‡å®šã™ã‚Œã°ã€ä»»æ„ã®å‹•ç”»ã ã‘ã¾ã¨ã‚ã¦æ¯”è¼ƒå¯èƒ½

---

ğŸ’¡ æ¬¡ã®æ‹¡å¼µæ¡ˆï¼š

* **è¡Œå‹•ã”ã¨ã«è‰²çµ±ä¸€ã—ãŸç§’å˜ä½ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**ã§å‹•ç”»é–“æ¯”è¼ƒã‚’ã•ã‚‰ã«ç›´æ„ŸåŒ–
* **è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’å‹•ç”»é–“ã§åŒã˜Xè»¸ã‚¹ã‚±ãƒ¼ãƒ«**ã«æƒãˆã¦æ¯”è¼ƒ
* **ç‰¹å®šãƒšã‚¢ã‚„ç‰¹å®šè¡Œå‹•ã ã‘æŠ½å‡ºã—ã¦æ¯”è¼ƒ**

å¸Œæœ›ãªã‚‰ã€ã“ã®æ‹¡å¼µã‚‚è¿½åŠ ã—ã¦ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¡Œå‹•ã”ã¨ã«è‰²ã‚’å›ºå®šã—ã€è·é›¢ã¯ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§è¡¨ç¤ºã€ã•ã‚‰ã«ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®Xè»¸ã‚’å‹•ç”»é–“ã§çµ±ä¸€**ã—ãŸæ¯”è¼ƒç‰ˆã‚’ä½œã‚Šã¾ã™ã€‚
ã“ã†ã™ã‚‹ã“ã¨ã§ã€å‹•ç”»é–“ã§è¡Œå‹•ã®ç™ºç”Ÿãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„è·é›¢å‚¾å‘ã‚’ç›´æ„Ÿçš„ã«æ¯”è¼ƒã§ãã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import numpy as np

def plot_videos_comparison(submission_df, video_ids=None):
    """
    è¤‡æ•°å‹•ç”»ã®æ¯”è¼ƒç”¨å¯è¦–åŒ–
    è¡Œå‹•ã”ã¨ã«è‰²å›ºå®šã€è·é›¢ã¯ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã¯Xè»¸çµ±ä¸€
    """
    if video_ids is None:
        video_ids = submission_df["video_id"].unique()
    
    # è¡Œå‹•ã”ã¨ã«å›ºå®šè‰²ã‚’å‰²ã‚Šå½“ã¦
    actions_unique = submission_df["action"].unique()
    action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}

    # è·é›¢ã®æœ€å°ãƒ»æœ€å¤§ã‚’å…¨å‹•ç”»ã§çµ±ä¸€
    dist_min = submission_df["dist_to_target_cm"].min()
    dist_max = submission_df["dist_to_target_cm"].max()
    norm = mcolors.Normalize(vmin=dist_min, vmax=dist_max)
    cmap = cm.get_cmap("viridis")

    n_videos = len(video_ids)
    fig, axes = plt.subplots(n_videos, 2, figsize=(15, 5*n_videos))
    if n_videos == 1:
        axes = [axes]  # 1å‹•ç”»ã®å ´åˆã§ã‚‚ãƒ«ãƒ¼ãƒ—å¯èƒ½

    for i, video_id in enumerate(video_ids):
        df = submission_df[submission_df["video_id"] == video_id].copy()
        fps = fps_dict.get(video_id, 30)
        df["time_sec"] = df["video_frame"] / fps
        actions = df["action"].unique()

        # ========= å·¦ï¼šç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ =========
        ax = axes[i][0]
        for _, row in df.iterrows():
            y = actions.tolist().index(row["action"]) + 0.1*row["agent_id"]
            base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
            distance_factor = norm(row["dist_to_target_cm"])
            color = base_color * (0.3 + 0.7*distance_factor)  # è·é›¢ã§æ˜ã‚‹ã•èª¿æ•´
            ax.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)
        ax.set_yticks(range(len(actions)))
        ax.set_yticklabels(actions)
        ax.set_xlabel("Time (seconds)")
        ax.set_ylabel("Action")
        ax.set_title(f"Video {video_id} - Actions over time (color=fixed by action, brightness ~ distance)")
        ax.grid(axis="x", linestyle="--", alpha=0.5)

        # ========= å³ï¼šè¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  =========
        ax2 = axes[i][1]
        bins = np.linspace(dist_min, dist_max, 21)
        for action in actions:
            subset = df[df["action"] == action]
            ax2.hist(subset["dist_to_target_cm"], bins=bins, alpha=0.5, label=action, color=action_colors[action])
        ax2.set_xlabel("Distance to target (cm)")
        ax2.set_ylabel("Count")
        ax2.set_title(f"Video {video_id} - Distance per action")
        ax2.legend()

    plt.tight_layout()
    plt.show()


# =========================
# å®Ÿè¡Œä¾‹ï¼ˆè¤‡æ•°å‹•ç”»ï¼‰
# =========================
plot_videos_comparison(submission_expanded)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è¡Œå‹•ã”ã¨ã«è‰²å›ºå®š** â†’ å‹•ç”»é–“æ¯”è¼ƒã—ã‚„ã™ã„
2. **è·é›¢ã‚’æ˜ã‚‹ã•ã§è¡¨ç¾** â†’ åŒã˜è¡Œå‹•ã§ã‚‚è·é›¢ã®å¤§å°ã‚’è¦–è¦šåŒ–
3. **ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®Xè»¸ã‚’å…¨å‹•ç”»ã§çµ±ä¸€** â†’ å‹•ç”»é–“è·é›¢åˆ†å¸ƒã®æ¯”è¼ƒãŒå®¹æ˜“
4. **ç¸¦ã«ä¸¦ã¹ã¦è¤‡æ•°å‹•ç”»ã‚’æ¯”è¼ƒ** â†’ æ™‚é–“è»¸ã¨è·é›¢åˆ†å¸ƒã‚’ä¸€ç›®ã§ç¢ºèª

---

ğŸ’¡ ã“ã®å¯è¦–åŒ–ã§ã€ä¾‹ãˆã°ï¼š

* æ”»æ’ƒè¡Œå‹•ã¯è·é›¢ãŒè¿‘ã„å ´åˆã«å¤šç™º
* å›é¿è¡Œå‹•ã¯è·é›¢ãŒã‚ã‚‹å ´åˆã«å¤šç™º

ãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç°¡å˜ã«ç¢ºèªã§ãã¾ã™ã€‚

å¿…è¦ãªã‚‰ã€ã•ã‚‰ã«**ç‰¹å®šãƒšã‚¢ã‚„ç‰¹å®šè¡Œå‹•ã ã‘æŠ½å‡ºã—ã¦æ¯”è¼ƒã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½**ã‚‚è¿½åŠ å¯èƒ½ã§ã™ã€‚è¿½åŠ ã—ã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**ç‰¹å®šãƒšã‚¢ã‚„ç‰¹å®šè¡Œå‹•ã ã‘æŠ½å‡ºã—ã¦æ¯”è¼ƒã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½**ã‚’è¿½åŠ ã—ã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* `agent_id`ã€`target_id`ã€`action` ã®æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½
* æ¡ä»¶ã‚’æŒ‡å®šã—ãªã„å ´åˆã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å¯¾è±¡
* ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã«å…ˆã»ã©ã® **ç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‹è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ** ã‚’æç”»

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import numpy as np

def plot_filtered_videos(submission_df, video_ids=None, agent_ids=None, target_ids=None, actions=None):
    """
    è¤‡æ•°å‹•ç”»ã§ç‰¹å®šãƒšã‚¢ã‚„ç‰¹å®šè¡Œå‹•ã‚’æŠ½å‡ºã—ã¦æ¯”è¼ƒ
    """
    if video_ids is None:
        video_ids = submission_df["video_id"].unique()
    
    # è¡Œå‹•ã”ã¨ã«å›ºå®šè‰²ã‚’å‰²ã‚Šå½“ã¦
    actions_unique = submission_df["action"].unique()
    action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}

    # è·é›¢ã®æœ€å°ãƒ»æœ€å¤§ã‚’å…¨å‹•ç”»ã§çµ±ä¸€
    dist_min = submission_df["dist_to_target_cm"].min()
    dist_max = submission_df["dist_to_target_cm"].max()
    norm = mcolors.Normalize(vmin=dist_min, vmax=dist_max)
    cmap = cm.get_cmap("viridis")

    n_videos = len(video_ids)
    fig, axes = plt.subplots(n_videos, 2, figsize=(15, 5*n_videos))
    if n_videos == 1:
        axes = [axes]

    for i, video_id in enumerate(video_ids):
        df = submission_df[submission_df["video_id"] == video_id].copy()
        fps = fps_dict.get(video_id, 30)
        df["time_sec"] = df["video_frame"] / fps

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if agent_ids is not None:
            df = df[df["agent_id"].isin(agent_ids)]
        if target_ids is not None:
            df = df[df["target_id"].isin(target_ids)]
        if actions is not None:
            df = df[df["action"].isin(actions)]
        if df.empty:
            print(f"Video {video_id} has no data after filtering.")
            continue

        actions_filtered = df["action"].unique()

        # ========= å·¦ï¼šç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ =========
        ax = axes[i][0]
        for _, row in df.iterrows():
            y = actions_filtered.tolist().index(row["action"]) + 0.1*row["agent_id"]
            base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
            distance_factor = norm(row["dist_to_target_cm"])
            color = base_color * (0.3 + 0.7*distance_factor)
            ax.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)
        ax.set_yticks(range(len(actions_filtered)))
        ax.set_yticklabels(actions_filtered)
        ax.set_xlabel("Time (seconds)")
        ax.set_ylabel("Action")
        ax.set_title(f"Video {video_id} - Actions over time (filtered)")
        ax.grid(axis="x", linestyle="--", alpha=0.5)

        # ========= å³ï¼šè¡Œå‹•ã”ã¨ã®è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  =========
        ax2 = axes[i][1]
        bins = np.linspace(dist_min, dist_max, 21)
        for action in actions_filtered:
            subset = df[df["action"] == action]
            ax2.hist(subset["dist_to_target_cm"], bins=bins, alpha=0.5, label=action, color=action_colors[action])
        ax2.set_xlabel("Distance to target (cm)")
        ax2.set_ylabel("Count")
        ax2.set_title(f"Video {video_id} - Distance per action (filtered)")
        ax2.legend()

    plt.tight_layout()
    plt.show()


# =========================
# å®Ÿè¡Œä¾‹
# video_ids: æ¯”è¼ƒã—ãŸã„å‹•ç”»IDã®ãƒªã‚¹ãƒˆ
# agent_ids: ç‰¹å®šã®ãƒã‚¦ã‚¹IDã‚’æŠ½å‡º
# target_ids: ç‰¹å®šã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒã‚¦ã‚¹IDã‚’æŠ½å‡º
# actions: ç‰¹å®šã®è¡Œå‹•ã ã‘æŠ½å‡º
# =========================
plot_filtered_videos(
    submission_expanded,
    video_ids=[submission["video_id"].iloc[0], submission["video_id"].iloc[1]],
    agent_ids=[1,2],
    target_ids=[3],
    actions=["attack", "approach"]
)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **å‹•ç”»ã”ã¨ã«ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§æ¯”è¼ƒ**
2. **å·¦ï¼šç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**ã€**å³ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **
3. **agent_id / target_id / action ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½**
4. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯è­¦å‘Šè¡¨ç¤º

---

ğŸ’¡ ã“ã®æ©Ÿèƒ½ã§ã€ä¾‹ãˆã°ï¼š

* ç‰¹å®šãƒšã‚¢ã®æ”»æ’ƒè¡Œå‹•ã ã‘æŠ½å‡ºã—ã¦è·é›¢å‚¾å‘ã‚’ç¢ºèª
* è¤‡æ•°å‹•ç”»é–“ã§åŒã˜ãƒšã‚¢ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¯”è¼ƒ
* ç‰¹å®šè¡Œå‹•ã®ç™ºç”Ÿã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¨è·é›¢å¤‰åŒ–ã‚’é›†ä¸­åˆ†æ

ãŒå¯èƒ½ã§ã™ã€‚

å¸Œæœ›ãªã‚‰ã€**ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’GUIï¼ˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼‰ã§å‹•çš„ã«å¤‰ãˆã‚‰ã‚Œã‚‹ç°¡æ˜“ãƒ„ãƒ¼ãƒ«åŒ–**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**ç°¡æ˜“GUIã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’å‹•çš„ã«å¤‰æ›´ã—ã¦å¯è¦–åŒ–**ã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ä½œã‚Šã¾ã™ã€‚

ã“ã“ã§ã¯ã€`ipywidgets`ã‚’ä½¿ã£ãŸJupyter Notebookå‘ã‘ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç‰ˆã§ã™ã€‚

* **å‹•ç”»IDã€agent_idã€target_idã€action** ã‚’é¸æŠã—ã¦å³åº§ã«å¯è¦–åŒ–
* æ¡ä»¶å¤‰æ›´ã¨åŒæ™‚ã«ã‚°ãƒ©ãƒ•æ›´æ–°

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import numpy as np
import ipywidgets as widgets
from IPython.display import display

# å‹•ç”»IDãƒ»ãƒã‚¦ã‚¹IDãƒ»è¡Œå‹•ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤
video_options = submission_expanded["video_id"].unique().tolist()
agent_options = submission_expanded["agent_id"].unique().tolist()
target_options = submission_expanded["target_id"].unique().tolist()
action_options = submission_expanded["action"].unique().tolist()

# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆ
video_widget = widgets.SelectMultiple(options=video_options, value=[video_options[0]], description='Video')
agent_widget = widgets.SelectMultiple(options=agent_options, value=[], description='Agent')
target_widget = widgets.SelectMultiple(options=target_options, value=[], description='Target')
action_widget = widgets.SelectMultiple(options=action_options, value=[], description='Action')

def update_plot(video_ids, agent_ids, target_ids, actions):
    if not video_ids:
        print("å‹•ç”»IDã‚’é¸æŠã—ã¦ãã ã•ã„")
        return
    
    plot_filtered_videos(
        submission_df=submission_expanded,
        video_ids=list(video_ids),
        agent_ids=list(agent_ids) if agent_ids else None,
        target_ids=list(target_ids) if target_ids else None,
        actions=list(actions) if actions else None
    )

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤º
ui = widgets.VBox([video_widget, agent_widget, target_widget, action_widget])
out = widgets.interactive_output(update_plot, {
    'video_ids': video_widget,
    'agent_ids': agent_widget,
    'target_ids': target_widget,
    'actions': action_widget
})

display(ui, out)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **å‹•ç”»IDã€agent_idã€target_idã€action ã‚’å‹•çš„ã«é¸æŠå¯èƒ½**
2. é¸æŠå†…å®¹ã«å¿œã˜ã¦ã€**ç§’å˜ä½ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‹è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ **ã‚’å³æ›´æ–°
3. Jupyter Notebook ä¸Šã§å‹•ä½œã€è¤‡æ•°å‹•ç”»ã‚‚ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§æ¯”è¼ƒ
4. é¸æŠã‚’å¤‰ãˆã‚‹ã ã‘ã§ã€ç‰¹å®šãƒšã‚¢ãƒ»ç‰¹å®šè¡Œå‹•ã‚’ç¬æ™‚ã«åˆ†æå¯èƒ½

---

ğŸ’¡ ã“ã‚Œã«ã‚ˆã‚Šã€ä¾‹ãˆã°ï¼š

* è¤‡æ•°å‹•ç”»ã®åŒã˜ãƒã‚¦ã‚¹ãƒšã‚¢ã®æ”»æ’ƒè¡Œå‹•ã‚’ç¬æ™‚ã«æ¯”è¼ƒ
* å›é¿ã‚„æ¥è¿‘ãªã©ç‰¹å®šè¡Œå‹•ã ã‘æŠ½å‡ºã—ã¦å‚¾å‘ã‚’æŠŠæ¡
* è·é›¢ã¨æ™‚é–“ã®é–¢ä¿‚ã‚’å‹•ç”»é–“ã§ä¸€ç›®ã§æ¯”è¼ƒ

ã¾ã§ãŒã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ç¢ºèªã§ãã¾ã™ã€‚

å¿…è¦ãªã‚‰ã€**å‹•ç”»ã‚’ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ãƒ•ãƒ¬ãƒ¼ãƒ å†ç”Ÿã—ãªãŒã‚‰å¯è¦–åŒ–ã™ã‚‹å‹•çš„ç‰ˆ**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**å‹•ç”»ã‚’ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã«å†ç”Ÿã—ãªãŒã‚‰å¯è¦–åŒ–ã™ã‚‹å‹•çš„ç‰ˆ**ã‚’ä½œã‚Šã¾ã™ã€‚
Jupyter Notebookã§ `ipywidgets` ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¨ `matplotlib` ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

# å‹•ç”»IDã®é¸æŠã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
video_options = submission_expanded["video_id"].unique().tolist()
video_widget = widgets.Dropdown(options=video_options, value=video_options[0], description='Video')

def play_video(video_id):
    df = submission_expanded[submission_expanded["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    df["time_sec"] = df["video_frame"] / fps
    
    actions_unique = df["action"].unique()
    action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}
    
    dist_min = df["dist_to_target_cm"].min()
    dist_max = df["dist_to_target_cm"].max()
    norm = mcolors.Normalize(vmin=dist_min, vmax=dist_max)
    
    max_frame = df["video_frame"].max()
    
    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
    frame_slider = widgets.IntSlider(min=0, max=max_frame, step=1, value=0, description='Frame')
    
    out = widgets.Output()
    
    def update(frame):
        with out:
            clear_output(wait=True)
            fig, ax = plt.subplots(figsize=(10,5))
            df_frame = df[df["video_frame"] <= frame]
            for _, row in df_frame.iterrows():
                y = actions_unique.tolist().index(row["action"]) + 0.1*row["agent_id"]
                base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
                distance_factor = norm(row["dist_to_target_cm"])
                color = base_color * (0.3 + 0.7*distance_factor)
                ax.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)
            ax.set_yticks(range(len(actions_unique)))
            ax.set_yticklabels(actions_unique)
            ax.set_xlabel("Time (seconds)")
            ax.set_ylabel("Action")
            ax.set_title(f"Video {video_id} - up to frame {frame}")
            ax.grid(axis="x", linestyle="--", alpha=0.5)
            plt.show()
    
    widgets.interactive(update, frame=frame_slider)
    display(frame_slider, out)

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤º
widgets.interactive(play_video, video_id=video_widget)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã«å‹•çš„å†ç”Ÿ**
2. **å·¦ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢æ˜ã‚‹ã•ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**
3. é¸æŠå‹•ç”»ã®è¡Œå‹•å±¥æ­´ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¿½è·¡
4. å‹•ç”»é–“ã§ç‰¹å®šã®ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ã‚„è¡Œå‹•ã®æ¯”è¼ƒãŒå®¹æ˜“

---

ğŸ’¡ æ‹¡å¼µæ¡ˆï¼š

* **agent_id / target_id / action ã‚’è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**ã—ã¦ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å†ç”Ÿ
* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ç§»å‹•ã«å¿œã˜ã¦è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚‚æ›´æ–°
* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦å‹•ç”»é¢¨ã«å†ç”Ÿ

å¸Œæœ›ãªã‚‰ã€**ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å†ç”Ÿ**ç‰ˆã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãã§ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å†ç”Ÿï¼‹è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚‚åŒæ™‚æ›´æ–°**ã™ã‚‹ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é¢¨ã®å‹•çš„å¯è¦–åŒ–ã‚’ä½œã‚Šã¾ã™ã€‚
Jupyter Notebook å‘ã‘ã® `ipywidgets` ã¨ `matplotlib` ã‚’æ´»ç”¨ã—ã¾ã™ã€‚

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

# å‹•ç”»IDãƒ»ãƒã‚¦ã‚¹IDãƒ»è¡Œå‹•ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤
video_options = submission_expanded["video_id"].unique().tolist()
agent_options = submission_expanded["agent_id"].unique().tolist()
target_options = submission_expanded["target_id"].unique().tolist()
action_options = submission_expanded["action"].unique().tolist()

# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆ
video_widget = widgets.Dropdown(options=video_options, value=video_options[0], description='Video')
agent_widget = widgets.SelectMultiple(options=agent_options, value=[], description='Agent')
target_widget = widgets.SelectMultiple(options=target_options, value=[], description='Target')
action_widget = widgets.SelectMultiple(options=action_options, value=[], description='Action')

def play_filtered_video(video_id, agent_ids, target_ids, actions):
    df = submission_expanded[submission_expanded["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    df["time_sec"] = df["video_frame"] / fps
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if agent_ids:
        df = df[df["agent_id"].isin(agent_ids)]
    if target_ids:
        df = df[df["target_id"].isin(target_ids)]
    if actions:
        df = df[df["action"].isin(actions)]
    if df.empty:
        print("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    actions_unique = df["action"].unique()
    action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}
    
    dist_min = df["dist_to_target_cm"].min()
    dist_max = df["dist_to_target_cm"].max()
    norm = mcolors.Normalize(vmin=dist_min, vmax=dist_max)
    
    max_frame = df["video_frame"].max()
    frame_slider = widgets.IntSlider(min=0, max=max_frame, step=1, value=0, description='Frame')
    out = widgets.Output()
    
    def update(frame):
        with out:
            clear_output(wait=True)
            fig, axes = plt.subplots(1,2, figsize=(15,5))
            
            df_frame = df[df["video_frame"] <= frame]
            
            # å·¦ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            ax = axes[0]
            for _, row in df_frame.iterrows():
                y = actions_unique.tolist().index(row["action"]) + 0.1*row["agent_id"]
                base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
                distance_factor = norm(row["dist_to_target_cm"])
                color = base_color * (0.3 + 0.7*distance_factor)
                ax.scatter(row["time_sec"], y, color=color, s=20, alpha=0.8)
            ax.set_yticks(range(len(actions_unique)))
            ax.set_yticklabels(actions_unique)
            ax.set_xlabel("Time (seconds)")
            ax.set_ylabel("Action")
            ax.set_title(f"Video {video_id} - up to frame {frame}")
            ax.grid(axis="x", linestyle="--", alpha=0.5)
            
            # å³ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            ax2 = axes[1]
            bins = np.linspace(dist_min, dist_max, 21)
            for action in actions_unique:
                subset = df_frame[df_frame["action"] == action]
                ax2.hist(subset["dist_to_target_cm"], bins=bins, alpha=0.5, label=action, color=action_colors[action])
            ax2.set_xlabel("Distance to target (cm)")
            ax2.set_ylabel("Count")
            ax2.set_title(f"Distance per action up to frame {frame}")
            ax2.legend()
            
            plt.tight_layout()
            plt.show()
    
    widgets.interactive(update, frame=frame_slider)
    display(frame_slider, out)

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤º
ui = widgets.VBox([video_widget, agent_widget, target_widget, action_widget])
out = widgets.interactive_output(play_filtered_video, {
    'video_id': video_widget,
    'agent_ids': agent_widget,
    'target_ids': target_widget,
    'actions': action_widget
})
display(ui, out)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **å‹•ç”»ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å†ç”Ÿ**
2. **å·¦ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢æ˜ã‚‹ã•ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**
3. **å³ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã§ã®ç´¯ç©ã§æ›´æ–°**
4. **agent_id / target_id / action ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½**
5. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯è­¦å‘Šè¡¨ç¤º

---

ğŸ’¡ ã“ã®ãƒ„ãƒ¼ãƒ«ã§ã§ãã‚‹ã“ã¨ï¼š

* ç‰¹å®šãƒã‚¦ã‚¹ãƒšã‚¢ã®æ”»æ’ƒã‚„æ¥è¿‘è¡Œå‹•ã‚’æ™‚é–“è»¸ã§ç¢ºèª
* è¡Œå‹•ã¨è·é›¢ã®é–¢ä¿‚ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«å‹•çš„ã«è¿½è·¡
* è¤‡æ•°å‹•ç”»é–“ã§åŒæ¡ä»¶ã®æ¯”è¼ƒã‚‚å¯èƒ½

---

å¸Œæœ›ãªã‚‰æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€**ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ç‚¹ã®ã‚µã‚¤ã‚ºã‚„è‰²ã§è·é›¢ã‚„é€Ÿåº¦ã‚‚å¯è¦–åŒ–**ã—ã¦ã€ã•ã‚‰ã«ç›´æ„Ÿçš„ã«è¡Œå‹•ã‚’æŠŠæ¡ã§ãã‚‹æ‹¡å¼µã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯æ¬¡ã¯ã€**ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ç‚¹ã®ã‚µã‚¤ã‚ºã‚„è‰²ã§è·é›¢ã‚„é€Ÿåº¦ã‚’å¯è¦–åŒ–**ã—ã¦ã€ãƒã‚¦ã‚¹è¡Œå‹•ã‚’ã‚ˆã‚Šç›´æ„Ÿçš„ã«æŠŠæ¡ã§ãã‚‹æ‹¡å¼µç‰ˆã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* **è·é›¢**ï¼šè‰²ã®æ˜ã‚‹ã•
* **é€Ÿåº¦ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ é–“ç§»å‹•è·é›¢ï¼‰**ï¼šç‚¹ã®ã‚µã‚¤ã‚º
* **agent_id / target_id / action** ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½
* å·¦ã‚°ãƒ©ãƒ•ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢æ˜ã‚‹ã•ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚º
* å³ã‚°ãƒ©ãƒ•ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

# å‰å‡¦ç†: é€Ÿåº¦ã‚’è¨ˆç®—ã—ã¦è¿½åŠ 
submission_expanded["x_prev"] = submission_expanded.groupby(["agent_id"])["x"].shift(1)
submission_expanded["y_prev"] = submission_expanded.groupby(["agent_id"])["y"].shift(1)
submission_expanded["speed"] = np.sqrt(
    (submission_expanded["x"] - submission_expanded["x_prev"])**2 +
    (submission_expanded["y"] - submission_expanded["y_prev"])**2
).fillna(0)

# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆ
video_options = submission_expanded["video_id"].unique().tolist()
agent_options = submission_expanded["agent_id"].unique().tolist()
target_options = submission_expanded["target_id"].unique().tolist()
action_options = submission_expanded["action"].unique().tolist()

video_widget = widgets.Dropdown(options=video_options, value=video_options[0], description='Video')
agent_widget = widgets.SelectMultiple(options=agent_options, value=[], description='Agent')
target_widget = widgets.SelectMultiple(options=target_options, value=[], description='Target')
action_widget = widgets.SelectMultiple(options=action_options, value=[], description='Action')

def play_speed_distance_video(video_id, agent_ids, target_ids, actions):
    df = submission_expanded[submission_expanded["video_id"] == video_id].copy()
    fps = fps_dict.get(video_id, 30)
    df["time_sec"] = df["video_frame"] / fps

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if agent_ids:
        df = df[df["agent_id"].isin(agent_ids)]
    if target_ids:
        df = df[df["target_id"].isin(target_ids)]
    if actions:
        df = df[df["action"].isin(actions)]
    if df.empty:
        print("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    actions_unique = df["action"].unique()
    action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}

    dist_min = df["dist_to_target_cm"].min()
    dist_max = df["dist_to_target_cm"].max()
    norm_dist = mcolors.Normalize(vmin=dist_min, vmax=dist_max)

    speed_min = df["speed"].min()
    speed_max = df["speed"].max()
    norm_speed = mcolors.Normalize(vmin=speed_min, vmax=speed_max)

    max_frame = df["video_frame"].max()
    frame_slider = widgets.IntSlider(min=0, max=max_frame, step=1, value=0, description='Frame')
    out = widgets.Output()

    def update(frame):
        with out:
            clear_output(wait=True)
            fig, axes = plt.subplots(1,2, figsize=(15,5))

            df_frame = df[df["video_frame"] <= frame]

            # å·¦ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢æ˜ã‚‹ã•ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚º
            ax = axes[0]
            for _, row in df_frame.iterrows():
                y = actions_unique.tolist().index(row["action"]) + 0.1*row["agent_id"]
                base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
                color_factor = norm_dist(row["dist_to_target_cm"])
                color = base_color * (0.3 + 0.7*color_factor)
                size = 10 + 40*norm_speed(row["speed"])  # ã‚µã‚¤ã‚ºã«é€Ÿåº¦ã‚’åæ˜ 
                ax.scatter(row["time_sec"], y, color=color, s=size, alpha=0.8)
            ax.set_yticks(range(len(actions_unique)))
            ax.set_yticklabels(actions_unique)
            ax.set_xlabel("Time (seconds)")
            ax.set_ylabel("Action")
            ax.set_title(f"Video {video_id} - up to frame {frame} (size=velocity, color=distance)")
            ax.grid(axis="x", linestyle="--", alpha=0.5)

            # å³ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            ax2 = axes[1]
            bins = np.linspace(dist_min, dist_max, 21)
            for action in actions_unique:
                subset = df_frame[df_frame["action"] == action]
                ax2.hist(subset["dist_to_target_cm"], bins=bins, alpha=0.5, label=action, color=action_colors[action])
            ax2.set_xlabel("Distance to target (cm)")
            ax2.set_ylabel("Count")
            ax2.set_title(f"Distance per action up to frame {frame}")
            ax2.legend()

            plt.tight_layout()
            plt.show()

    widgets.interactive(update, frame=frame_slider)
    display(frame_slider, out)

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤º
ui = widgets.VBox([video_widget, agent_widget, target_widget, action_widget])
out = widgets.interactive_output(play_speed_distance_video, {
    'video_id': video_widget,
    'agent_ids': agent_widget,
    'target_ids': target_widget,
    'actions': action_widget
})
display(ui, out)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **å·¦ã‚°ãƒ©ãƒ•**

   * **è‰²**ï¼šã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¾ã§ã®è·é›¢
   * **ç‚¹ã®ã‚µã‚¤ã‚º**ï¼šãƒ•ãƒ¬ãƒ¼ãƒ é–“é€Ÿåº¦
   * **æ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹agent_id** ã§ç›´æ„Ÿçš„ã«è¡Œå‹•æŠŠæ¡

2. **å³ã‚°ãƒ©ãƒ•**

   * ç´¯ç©è·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
   * è¡Œå‹•ã”ã¨ã«è‰²åˆ†ã‘

3. **ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**

   * `agent_id / target_id / action` ã«ã‚ˆã‚‹æŠ½å‡º
   * æ¡ä»¶å¤‰æ›´ã¨åŒæ™‚ã«å†æç”»

---

ğŸ’¡ ã“ã‚Œã«ã‚ˆã‚Šï¼š

* è·é›¢ãŒè¿‘ã„è¡Œå‹•ã§é€Ÿåº¦ãŒå¤§ãã„ï¼ˆæ€¥æ¥è¿‘ãƒ»æ”»æ’ƒï¼‰ãªã©ã®å‚¾å‘ã‚’å¯è¦–åŒ–
* è¤‡æ•°ãƒã‚¦ã‚¹é–“ã®è¡Œå‹•ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’ç¬æ™‚ã«æŠŠæ¡
* ç‰¹å®šãƒšã‚¢ãƒ»ç‰¹å®šè¡Œå‹•ã®æ™‚é–“ãƒ»é€Ÿåº¦ãƒ»è·é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‹•ç”»å˜ä½ã§åˆ†æ

---

å¿…è¦ãªã‚‰ã€ã•ã‚‰ã«**åŒæ™‚ã«è¤‡æ•°å‹•ç”»ã‚’ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§æ¯”è¼ƒ**ã§ãã‚‹æ‹¡å¼µã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¤‡æ•°å‹•ç”»ã‚’åŒæ™‚ã«ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§æ¯”è¼ƒ**ã§ãã‚‹æ‹¡å¼µç‰ˆã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* é¸æŠã—ãŸè¤‡æ•°å‹•ç”»ã‚’æ¨ªä¸¦ã³ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã§è¡¨ç¤º
* å„å‹•ç”»ã§ã€å·¦ã‚°ãƒ©ãƒ•ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚ºã€å³ã‚°ãƒ©ãƒ•ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
* agent_id / target_id / action ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½
* åŒæ™‚ã«æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€å‹•ç”»é–“ã®è¡Œå‹•å‚¾å‘ã‚„é€Ÿåº¦ãƒ»è·é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¯è¦–åŒ–

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆ
video_options = submission_expanded["video_id"].unique().tolist()
agent_options = submission_expanded["agent_id"].unique().tolist()
target_options = submission_expanded["target_id"].unique().tolist()
action_options = submission_expanded["action"].unique().tolist()

video_widget = widgets.SelectMultiple(options=video_options, value=[video_options[0]], description='Videos')
agent_widget = widgets.SelectMultiple(options=agent_options, value=[], description='Agent')
target_widget = widgets.SelectMultiple(options=target_options, value=[], description='Target')
action_widget = widgets.SelectMultiple(options=action_options, value=[], description='Action')

def compare_videos(video_ids, agent_ids, target_ids, actions):
    if not video_ids:
        print("å‹•ç”»ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„")
        return

    out = widgets.Output()
    with out:
        clear_output(wait=True)
        n_videos = len(video_ids)
        fig, axes = plt.subplots(n_videos, 2, figsize=(12, 5*n_videos))

        if n_videos == 1:
            axes = np.expand_dims(axes, axis=0)  # 1å‹•ç”»ã§ã‚‚è¡Œåˆ—å½¢å¼ã«

        for i, video_id in enumerate(video_ids):
            df = submission_expanded[submission_expanded["video_id"] == video_id].copy()
            fps = fps_dict.get(video_id, 30)
            df["time_sec"] = df["video_frame"] / fps

            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if agent_ids:
                df = df[df["agent_id"].isin(agent_ids)]
            if target_ids:
                df = df[df["target_id"].isin(target_ids)]
            if actions:
                df = df[df["action"].isin(actions)]
            if df.empty:
                continue

            actions_unique = df["action"].unique()
            action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}

            dist_min = df["dist_to_target_cm"].min()
            dist_max = df["dist_to_target_cm"].max()
            norm_dist = mcolors.Normalize(vmin=dist_min, vmax=dist_max)

            speed_min = df["speed"].min()
            speed_max = df["speed"].max()
            norm_speed = mcolors.Normalize(vmin=speed_min, vmax=speed_max)

            # å·¦ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚º
            ax = axes[i,0]
            for _, row in df.iterrows():
                y = actions_unique.tolist().index(row["action"]) + 0.1*row["agent_id"]
                base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
                color_factor = norm_dist(row["dist_to_target_cm"])
                color = base_color * (0.3 + 0.7*color_factor)
                size = 10 + 40*norm_speed(row["speed"])
                ax.scatter(row["time_sec"], y, color=color, s=size, alpha=0.8)
            ax.set_yticks(range(len(actions_unique)))
            ax.set_yticklabels(actions_unique)
            ax.set_xlabel("Time (seconds)")
            ax.set_ylabel("Action")
            ax.set_title(f"Video {video_id} - Time vs Action")
            ax.grid(axis="x", linestyle="--", alpha=0.5)

            # å³ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            ax2 = axes[i,1]
            bins = np.linspace(dist_min, dist_max, 21)
            for action in actions_unique:
                subset = df[df["action"] == action]
                ax2.hist(subset["dist_to_target_cm"], bins=bins, alpha=0.5, label=action, color=action_colors[action])
            ax2.set_xlabel("Distance to target (cm)")
            ax2.set_ylabel("Count")
            ax2.set_title(f"Distance per action - Video {video_id}")
            ax2.legend()

        plt.tight_layout()
        plt.show()

    display(out)

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤º
ui = widgets.VBox([video_widget, agent_widget, target_widget, action_widget])
out = widgets.interactive_output(compare_videos, {
    'video_ids': video_widget,
    'agent_ids': agent_widget,
    'target_ids': target_widget,
    'actions': action_widget
})
display(ui, out)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è¤‡æ•°å‹•ç”»ã‚’åŒæ™‚è¡¨ç¤º**ï¼ˆç¸¦ã«ä¸¦ã¶ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆï¼‰
2. **å·¦ã‚°ãƒ©ãƒ•**ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢è‰²ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚º
3. **å³ã‚°ãƒ©ãƒ•**ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
4. **agent_id / target_id / action** ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½
5. å‹•ç”»é–“ã§è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ»è·é›¢ãƒ»é€Ÿåº¦ã®æ¯”è¼ƒãŒä¸€ç›®ã§å¯èƒ½

---

ğŸ’¡ ã“ã‚Œã«ã‚ˆã‚Šï¼š

* è¤‡æ•°å‹•ç”»ã®æ”»æ’ƒãƒ»å›é¿ãƒ»æ¥è¿‘ãªã©ã®è¡Œå‹•å‚¾å‘ã‚’ä¸¦åˆ—ã§ç¢ºèª
* è·é›¢ãƒ»é€Ÿåº¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‹•ç”»é–“ã§æ¯”è¼ƒ
* ç‰¹å®šãƒã‚¦ã‚¹ãƒšã‚¢ã®è¡Œå‹•ã‚’è¤‡æ•°ç’°å¢ƒã§åˆ†æ

---

å¿…è¦ãªã‚‰ã•ã‚‰ã«ã€**ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ä»˜ãã§è¤‡æ•°å‹•ç”»åŒæ™‚ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å†ç”Ÿ**ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ï¼ã§ã¯ã€**è¤‡æ•°å‹•ç”»ã‚’åŒæ™‚ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å†ç”Ÿ**ã™ã‚‹æ‹¡å¼µç‰ˆã‚’ä½œã‚Šã¾ã™ã€‚
å„å‹•ç”»ã§ä»¥ä¸‹ã‚’åŒæ™‚è¡¨ç¤ºï¼š

* å·¦ã‚°ãƒ©ãƒ•ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢è‰²ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚ºï¼ˆç‚¹ã®è‰²ï¼è·é›¢ã€ç‚¹ã®å¤§ãã•ï¼é€Ÿåº¦ï¼‰
* å³ã‚°ãƒ©ãƒ•ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
* agent_id / target_id / action ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½
* ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å‹•ã‹ã™ã¨ã€å…¨å‹•ç”»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¿œã˜ã¦åŒæ™‚ã«æ›´æ–°

---

```python
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import ipywidgets as widgets
from IPython.display import display, clear_output

# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆ
video_options = submission_expanded["video_id"].unique().tolist()
agent_options = submission_expanded["agent_id"].unique().tolist()
target_options = submission_expanded["target_id"].unique().tolist()
action_options = submission_expanded["action"].unique().tolist()

video_widget = widgets.SelectMultiple(options=video_options, value=[video_options[0]], description='Videos')
agent_widget = widgets.SelectMultiple(options=agent_options, value=[], description='Agent')
target_widget = widgets.SelectMultiple(options=target_options, value=[], description='Target')
action_widget = widgets.SelectMultiple(options=action_options, value=[], description='Action')

# æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å‹•ç”»é–“ã§æ±ºå®š
max_frame_dict = {vid: submission_expanded[submission_expanded["video_id"]==vid]["video_frame"].max() for vid in video_options}
overall_max_frame = max(max_frame_dict.values())

frame_slider = widgets.IntSlider(min=0, max=overall_max_frame, step=1, value=0, description='Frame')

def animate_videos(frame, video_ids, agent_ids, target_ids, actions):
    if not video_ids:
        return
    clear_output(wait=True)
    
    n_videos = len(video_ids)
    fig, axes = plt.subplots(n_videos, 2, figsize=(12, 5*n_videos))
    if n_videos == 1:
        axes = np.expand_dims(axes, axis=0)
    
    for i, video_id in enumerate(video_ids):
        df = submission_expanded[submission_expanded["video_id"]==video_id].copy()
        fps = fps_dict.get(video_id, 30)
        df["time_sec"] = df["video_frame"] / fps
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if agent_ids:
            df = df[df["agent_id"].isin(agent_ids)]
        if target_ids:
            df = df[df["target_id"].isin(target_ids)]
        if actions:
            df = df[df["action"].isin(actions)]
        if df.empty:
            continue
        
        df_frame = df[df["video_frame"] <= frame]
        actions_unique = df["action"].unique()
        action_colors = {action: f"C{i}" for i, action in enumerate(actions_unique)}
        
        dist_min, dist_max = df["dist_to_target_cm"].min(), df["dist_to_target_cm"].max()
        norm_dist = mcolors.Normalize(vmin=dist_min, vmax=dist_max)
        speed_min, speed_max = df["speed"].min(), df["speed"].max()
        norm_speed = mcolors.Normalize(vmin=speed_min, vmax=speed_max)
        
        # å·¦ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢è‰²ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚º
        ax = axes[i,0]
        for _, row in df_frame.iterrows():
            y = actions_unique.tolist().index(row["action"]) + 0.1*row["agent_id"]
            base_color = np.array(mcolors.to_rgb(action_colors[row["action"]]))
            color_factor = norm_dist(row["dist_to_target_cm"])
            color = base_color * (0.3 + 0.7*color_factor)
            size = 10 + 40*norm_speed(row["speed"])
            ax.scatter(row["time_sec"], y, color=color, s=size, alpha=0.8)
        ax.set_yticks(range(len(actions_unique)))
        ax.set_yticklabels(actions_unique)
        ax.set_xlabel("Time (seconds)")
        ax.set_ylabel("Action")
        ax.set_title(f"Video {video_id} - up to frame {frame}")
        ax.grid(axis="x", linestyle="--", alpha=0.5)
        
        # å³ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        ax2 = axes[i,1]
        bins = np.linspace(dist_min, dist_max, 21)
        for action in actions_unique:
            subset = df_frame[df_frame["action"]==action]
            ax2.hist(subset["dist_to_target_cm"], bins=bins, alpha=0.5, label=action, color=action_colors[action])
        ax2.set_xlabel("Distance to target (cm)")
        ax2.set_ylabel("Count")
        ax2.set_title(f"Distance per action - Video {video_id}")
        ax2.legend()
    
    plt.tight_layout()
    plt.show()

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤º
ui = widgets.VBox([video_widget, agent_widget, target_widget, action_widget, frame_slider])
out = widgets.interactive_output(animate_videos, {
    'frame': frame_slider,
    'video_ids': video_widget,
    'agent_ids': agent_widget,
    'target_ids': target_widget,
    'actions': action_widget
})
display(ui, out)
```

---

### ğŸ”¹ ç‰¹å¾´

1. **è¤‡æ•°å‹•ç”»ã‚’åŒæ™‚ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å†ç”Ÿ**
2. **å·¦ã‚°ãƒ©ãƒ•**ï¼šæ™‚é–“è»¸ï¼‹è¡Œå‹•ï¼‹è·é›¢è‰²ï¼‹é€Ÿåº¦ã‚µã‚¤ã‚º
3. **å³ã‚°ãƒ©ãƒ•**ï¼šè·é›¢ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
4. **agent_id / target_id / action** ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯èƒ½
5. ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å‹•ã‹ã™ã ã‘ã§ã€å…¨å‹•ç”»ãŒåŒæ™‚ã«æ›´æ–°

---

ğŸ’¡ ã“ã®æ‹¡å¼µã«ã‚ˆã‚Šï¼š

* å‹•ç”»é–“ã§è¡Œå‹•ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã€è·é›¢ãƒ»é€Ÿåº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¯”è¼ƒãŒç¬æ™‚ã«å¯èƒ½
* ç‰¹å®šãƒã‚¦ã‚¹ã‚„ãƒšã‚¢ã®è¡Œå‹•ã‚’è¤‡æ•°ç’°å¢ƒã§åˆ†æ
* é€Ÿåº¦ã‚„è·é›¢ã®å¤‰åŒ–ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§å‹•çš„ã«ç¢ºèª

---

å¸Œæœ›ãªã‚‰ã•ã‚‰ã«ã€**å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ä¸Šã«ãƒã‚¦ã‚¹ä½ç½®ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ãƒªã‚¢ãƒ«ãªå‹•ãã‚‚åŒæ™‚è¡¨ç¤º**ã™ã‚‹çµ±åˆå¯è¦–åŒ–ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãƒãƒ£ãƒƒãƒˆã‚’é¡ã£ã¦ç”³ã—è¨³ãªã„ã‚“ã ãŒã€tracking_features.csvã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ãŠé¡˜ã„
A: ã‚‚ã¡ã‚ã‚“ã§ã™ï¼ã“ã‚Œã¾ã§ã®è©±ã‹ã‚‰æ•´ç†ã™ã‚‹ã¨ã€**`tracking_features.csv`** ã«ã¯å„ãƒã‚¦ã‚¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ç‰¹å¾´é‡ã‚’ã¾ã¨ã‚ãŸã„ã¨ã„ã†ã“ã¨ã§ã™ã­ã€‚

æœ€ä½é™ã®ç‰¹å¾´ã¨ã—ã¦ã¯ï¼š

* **ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·**ï¼ˆvideo_frameï¼‰
* **ãƒã‚¦ã‚¹ID**ï¼ˆmouse_id / agent_idï¼‰
* **å„ä½“éƒ¨ä½ã®åº§æ¨™**ï¼ˆx, yï¼‰
* **é€Ÿåº¦**ï¼ˆå‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®è·é›¢å¤‰åŒ–ï¼‰
* **å‘ãï¼ˆè§’åº¦ï¼‰**ï¼ˆnose â†’ body_centerï¼‰
* **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒã‚¦ã‚¹ã¨ã®è·é›¢**ï¼ˆagent_id ã¨ target_id ãŒã‚ã‹ã‚‹å ´åˆï¼‰

ä»¥ä¸‹ã«ã€`tracking.csv` ã¨ `submission.csv` ã‹ã‚‰ç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¦ `tracking_features.csv` ã«ä¿å­˜ã™ã‚‹ä¾‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚

---

```python
import pandas as pd
import numpy as np

# CSVèª­ã¿è¾¼ã¿
tracking = pd.read_csv("tracking.csv")        # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ãƒã‚¦ã‚¹éƒ¨ä½åº§æ¨™
submission = pd.read_csv("submission.csv")    # agent_id, target_id, action, start_frame, stop_frame

# å¿…è¦ãªã‚‰ nose ã¨ body_center ã‚’ä½¿ã£ã¦è§’åº¦è¨ˆç®—
def compute_orientation(df):
    df_pivot = df.pivot(index="video_frame", columns="bodypart", values=["x","y"])
    # body_center, nose
    try:
        dx = df_pivot[("x","nose")] - df_pivot[("x","body_center")]
        dy = df_pivot[("y","nose")] - df_pivot[("y","body_center")]
        angles = np.arctan2(dy, dx)  # ãƒ©ã‚¸ã‚¢ãƒ³
        return angles
    except KeyError:
        return pd.Series(index=df_pivot.index, data=np.nan)

# å„ãƒã‚¦ã‚¹ã”ã¨ã«ç‰¹å¾´é‡ç”Ÿæˆ
features_list = []
for mouse_id, df_mouse in tracking.groupby("mouse_id"):
    df_mouse = df_mouse.sort_values("video_frame").copy()

    # å„ä½“éƒ¨ä½ã‚’åˆ—ã«å¤‰æ›
    df_pivot = df_mouse.pivot(index="video_frame", columns="bodypart", values=["x","y"])
    df_pivot.columns = ["_".join(col).strip() for col in df_pivot.columns.values]
    
    # é€Ÿåº¦è¨ˆç®—ï¼ˆbody_centeråŸºæº–ï¼‰
    df_pivot["body_center_x_prev"] = df_pivot["x_body_center"].shift(1)
    df_pivot["body_center_y_prev"] = df_pivot["y_body_center"].shift(1)
    df_pivot["speed"] = np.sqrt(
        (df_pivot["x_body_center"] - df_pivot["body_center_x_prev"])**2 +
        (df_pivot["y_body_center"] - df_pivot["body_center_y_prev"])**2
    ).fillna(0)
    
    # è§’åº¦è¨ˆç®—
    df_pivot["orientation"] = compute_orientation(df_mouse)
    
    # mouse_idåˆ—è¿½åŠ 
    df_pivot["mouse_id"] = mouse_id
    
    features_list.append(df_pivot.reset_index())

# å…¨ãƒã‚¦ã‚¹ã‚’çµåˆ
tracking_features = pd.concat(features_list, ignore_index=True)

# å‹•ç”»IDåˆ—ã‚’è¿½åŠ ã—ãŸã„å ´åˆï¼ˆtracking.csvã«ã‚ã‚Œã°ï¼‰
if "video_id" in tracking.columns:
    tracking_features = tracking_features.merge(tracking[["video_frame","mouse_id","video_id"]].drop_duplicates(), 
                                                on=["video_frame","mouse_id"], how="left")

# CSVã«ä¿å­˜
tracking_features.to_csv("tracking_features.csv", index=False)
print("tracking_features.csv ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
```

---

### ğŸ”¹ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å†…å®¹

1. **tracking.csv** ã‚’èª­ã¿è¾¼ã¿ã€ãƒã‚¦ã‚¹IDã”ã¨ã«å‡¦ç†
2. å„ãƒã‚¦ã‚¹ã®ä½“éƒ¨ä½åº§æ¨™ã‚’ **åˆ—å½¢å¼ã«å¤‰æ›**
3. **é€Ÿåº¦**ï¼šå‰ãƒ•ãƒ¬ãƒ¼ãƒ ã® body_center ã¨ã®å·®åˆ†
4. **å‘ãï¼ˆorientationï¼‰**ï¼šnose â†’ body_center ã®è§’åº¦
5. **video_id** ãŒ tracking ã«ã‚ã‚Œã°çµåˆ
6. **tracking_features.csv** ã¨ã—ã¦ä¿å­˜

---

ğŸ’¡ æ‹¡å¼µå¯èƒ½ãªç‰¹å¾´é‡ä¾‹ï¼š

* ä»–ãƒã‚¦ã‚¹ã¨ã®è·é›¢ï¼ˆsubmission ã® agent_id ã¨ target_id ã‚’ä½¿ã†ï¼‰
* å„ä½“éƒ¨ä½é–“ã®è·é›¢
* éå» N ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç§»å‹•ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆåŠ é€Ÿåº¦ã‚„æ–¹å‘å¤‰åŒ–ï¼‰

---

å¸Œæœ›ã§ã‚ã‚Œã°ã€**agent-targetè·é›¢ã‚„è§’åº¦ã€ç›¸å¯¾é€Ÿåº¦ã¾ã§å«ã‚ãŸå®Œå…¨ç‰ˆ tracking_features.csv** ã«æ‹¡å¼µã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚ä½œã‚Œã¾ã™ã€‚

ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: ã‚ã‹ã‚Šã¾ã—ãŸã€‚ã§ã¯ **agent-targeté–“ã®è·é›¢ãƒ»è§’åº¦ãƒ»ç›¸å¯¾é€Ÿåº¦ã¾ã§å«ã‚ãŸå®Œå…¨ç‰ˆ `tracking_features.csv`** ã‚’ä½œã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* å„ãƒ•ãƒ¬ãƒ¼ãƒ ã® **å„ãƒã‚¦ã‚¹ã®åº§æ¨™ãƒ»é€Ÿåº¦ãƒ»è§’åº¦**
* **agent-targetãƒšã‚¢** ã®è·é›¢ãƒ»è§’åº¦ãƒ»ç›¸å¯¾é€Ÿåº¦
* `submission.csv` ã® `agent_id` ã¨ `target_id` ã‚’åˆ©ç”¨

---

```python
import pandas as pd
import numpy as np

# CSVèª­ã¿è¾¼ã¿
tracking = pd.read_csv("tracking.csv")        # video_frame, mouse_id, bodypart, x, y
submission = pd.read_csv("submission.csv")    # video_id, agent_id, target_id, action, start_frame, stop_frame

# å„ãƒã‚¦ã‚¹ã”ã¨ã®ä½“éƒ¨ä½åº§æ¨™ã‚’åˆ—ã«å¤‰æ›
features_list = []
for mouse_id, df_mouse in tracking.groupby("mouse_id"):
    df_mouse = df_mouse.sort_values("video_frame").copy()
    
    # bodypartã”ã¨ã«åˆ—ã«å±•é–‹
    df_pivot = df_mouse.pivot(index="video_frame", columns="bodypart", values=["x","y"])
    df_pivot.columns = ["_".join(col).strip() for col in df_pivot.columns.values]
    
    # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®ç§»å‹•è·é›¢ã§é€Ÿåº¦
    df_pivot["body_center_x_prev"] = df_pivot["x_body_center"].shift(1)
    df_pivot["body_center_y_prev"] = df_pivot["y_body_center"].shift(1)
    df_pivot["speed"] = np.sqrt(
        (df_pivot["x_body_center"] - df_pivot["body_center_x_prev"])**2 +
        (df_pivot["y_body_center"] - df_pivot["body_center_y_prev"])**2
    ).fillna(0)
    
    # å‘ãï¼ˆnoseâ†’body_centerï¼‰
    if "x_nose" in df_pivot.columns and "y_nose" in df_pivot.columns:
        dx = df_pivot["x_nose"] - df_pivot["x_body_center"]
        dy = df_pivot["y_nose"] - df_pivot["y_body_center"]
        df_pivot["orientation"] = np.arctan2(dy, dx)
    else:
        df_pivot["orientation"] = np.nan
    
    df_pivot["mouse_id"] = mouse_id
    features_list.append(df_pivot.reset_index())

# å…¨ãƒã‚¦ã‚¹ã‚’çµåˆ
tracking_features = pd.concat(features_list, ignore_index=True)

# agent-targetãƒšã‚¢ã®è·é›¢ãƒ»è§’åº¦ãƒ»ç›¸å¯¾é€Ÿåº¦ã‚’è¨ˆç®—
pair_features_list = []
for idx, row in submission.iterrows():
    video_id = row["video_id"]
    agent_id = row["agent_id"]
    target_id = row["target_id"]
    start, stop = row["start_frame"], row["stop_frame"]
    
    df_agent = tracking_features[(tracking_features["mouse_id"]==agent_id)]
    df_target = tracking_features[(tracking_features["mouse_id"]==target_id)]
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ã§çµåˆ
    df_pair = pd.merge(df_agent, df_target, on="video_frame", suffixes=("_agent","_target"))
    df_pair = df_pair[(df_pair["video_frame"] >= start) & (df_pair["video_frame"] <= stop)].copy()
    
    # agent-targetè·é›¢ï¼ˆbody_centeråŸºæº–ï¼‰
    df_pair["dist_agent_target"] = np.sqrt(
        (df_pair["x_body_center_agent"] - df_pair["x_body_center_target"])**2 +
        (df_pair["y_body_center_agent"] - df_pair["y_body_center_target"])**2
    )
    
    # agent-targetè§’åº¦
    dx = df_pair["x_body_center_target"] - df_pair["x_body_center_agent"]
    dy = df_pair["y_body_center_target"] - df_pair["y_body_center_agent"]
    df_pair["angle_agent_target"] = np.arctan2(dy, dx)
    
    # ç›¸å¯¾é€Ÿåº¦ï¼ˆagentâ†’targetã®é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«å·®ï¼‰
    df_pair["rel_speed_x"] = df_pair["x_body_center_target"] - df_pair["x_body_center_target"].shift(1) - \
                              (df_pair["x_body_center_agent"] - df_pair["x_body_center_agent"].shift(1))
    df_pair["rel_speed_y"] = df_pair["y_body_center_target"] - df_pair["y_body_center_target"].shift(1) - \
                              (df_pair["y_body_center_agent"] - df_pair["y_body_center_agent"].shift(1))
    df_pair["rel_speed"] = np.sqrt(df_pair["rel_speed_x"]**2 + df_pair["rel_speed_y"]**2)
    
    df_pair["video_id"] = video_id
    df_pair["agent_id"] = agent_id
    df_pair["target_id"] = target_id
    df_pair["action"] = row["action"]
    
    pair_features_list.append(df_pair)

# çµåˆã—ã¦CSVä¿å­˜
tracking_features_complete = pd.concat(pair_features_list, ignore_index=True)
tracking_features_complete.to_csv("tracking_features.csv", index=False)
print("tracking_features.csv ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
```

---

### ğŸ”¹ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ç”Ÿæˆã•ã‚Œã‚‹ç‰¹å¾´é‡

* å„ãƒã‚¦ã‚¹ã® **å„ä½“éƒ¨ä½åº§æ¨™** (`x_*, y_*`)
* **é€Ÿåº¦** (`speed`)
* **å‘ãï¼ˆorientationï¼‰**
* **agent-targetè·é›¢** (`dist_agent_target`)
* **agent-targetè§’åº¦** (`angle_agent_target`)
* **agent-targetç›¸å¯¾é€Ÿåº¦** (`rel_speed`)
* `video_id` / `agent_id` / `target_id` / `action`

---

ğŸ’¡ ã“ã‚Œã§ã€ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã§ãã‚‹**ãƒ•ãƒ«ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ**ãŒ `tracking_features.csv` ã«æƒã„ã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€**bodyparté–“è·é›¢ã‚„è§’åº¦ã€é€Ÿåº¦å¤‰åŒ–ãªã©ã®è¿½åŠ æ´¾ç”Ÿç‰¹å¾´**ã‚‚è¨ˆç®—å¯èƒ½ã§ã™ã€‚
å¸Œæœ›ã§ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ã€‚ãã‚Œã§ã¯ã•ã‚‰ã«è¸ã¿è¾¼ã‚“ã§ã€**bodyparté–“è·é›¢ãƒ»è§’åº¦ãƒ»åŠ é€Ÿåº¦ãªã©ã®æ´¾ç”Ÿç‰¹å¾´ã‚‚å«ã‚ãŸæ‹¡å¼µç‰ˆ tracking_features.csv** ã‚’ä½œã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æç¤ºã—ã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* **ä½“éƒ¨ä½é–“è·é›¢**ï¼šä¾‹ï¼‰è€³é–“è·é›¢ã€é ­éƒ¨ç«¯â†’å°¾ç«¯è·é›¢ãªã©
* **ä½“éƒ¨ä½é–“è§’åº¦**ï¼šä¾‹ï¼‰è€³â†’é¼»â†’å°¾åŸºéƒ¨ã®è§’åº¦
* **åŠ é€Ÿåº¦**ï¼šé€Ÿåº¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ å·®åˆ†
* **agent-targeté–¢é€£ç‰¹å¾´**ï¼šè·é›¢ãƒ»è§’åº¦ãƒ»ç›¸å¯¾é€Ÿåº¦ã«åŠ ãˆã€æ–¹å‘å¤‰åŒ–ã‚„åŠ é€Ÿåº¦ã‚‚

---

```python
import pandas as pd
import numpy as np
from itertools import combinations

# CSVèª­ã¿è¾¼ã¿
tracking = pd.read_csv("tracking.csv")
submission = pd.read_csv("submission.csv")

# å„ãƒã‚¦ã‚¹ã”ã¨ã«ä½“éƒ¨ä½åº§æ¨™ã‚’åˆ—å½¢å¼ã«
features_list = []
for mouse_id, df_mouse in tracking.groupby("mouse_id"):
    df_mouse = df_mouse.sort_values("video_frame").copy()
    
    df_pivot = df_mouse.pivot(index="video_frame", columns="bodypart", values=["x","y"])
    df_pivot.columns = ["_".join(col).strip() for col in df_pivot.columns.values]
    
    # é€Ÿåº¦
    df_pivot["body_center_x_prev"] = df_pivot["x_body_center"].shift(1)
    df_pivot["body_center_y_prev"] = df_pivot["y_body_center"].shift(1)
    df_pivot["speed"] = np.sqrt(
        (df_pivot["x_body_center"] - df_pivot["body_center_x_prev"])**2 +
        (df_pivot["y_body_center"] - df_pivot["body_center_y_prev"])**2
    ).fillna(0)
    # åŠ é€Ÿåº¦
    df_pivot["acceleration"] = df_pivot["speed"].diff().fillna(0)
    
    # å‘ãï¼ˆnoseâ†’body_centerï¼‰
    if "x_nose" in df_pivot.columns and "y_nose" in df_pivot.columns:
        dx = df_pivot["x_nose"] - df_pivot["x_body_center"]
        dy = df_pivot["y_nose"] - df_pivot["y_body_center"]
        df_pivot["orientation"] = np.arctan2(dy, dx)
    else:
        df_pivot["orientation"] = np.nan
    
    # bodyparté–“è·é›¢ï¼ˆã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ï¼‰
    bodyparts = [c.split("_")[1] for c in df_pivot.columns if c.startswith("x_")]
    for b1, b2 in combinations(bodyparts, 2):
        x1, y1 = df_pivot[f"x_{b1}"], df_pivot[f"y_{b1}"]
        x2, y2 = df_pivot[f"x_{b2}"], df_pivot[f"y_{b2}"]
        df_pivot[f"dist_{b1}_{b2}"] = np.sqrt((x2-x1)**2 + (y2-y1)**2)
        # bodyparté–“è§’åº¦
        df_pivot[f"angle_{b1}_{b2}"] = np.arctan2(y2-y1, x2-x1)
    
    df_pivot["mouse_id"] = mouse_id
    features_list.append(df_pivot.reset_index())

tracking_features = pd.concat(features_list, ignore_index=True)

# agent-targetç‰¹å¾´é‡
pair_features_list = []
for idx, row in submission.iterrows():
    agent_id = row["agent_id"]
    target_id = row["target_id"]
    video_id = row["video_id"]
    start, stop = row["start_frame"], row["stop_frame"]
    
    df_agent = tracking_features[tracking_features["mouse_id"]==agent_id]
    df_target = tracking_features[tracking_features["mouse_id"]==target_id]
    
    df_pair = pd.merge(df_agent, df_target, on="video_frame", suffixes=("_agent","_target"))
    df_pair = df_pair[(df_pair["video_frame"]>=start) & (df_pair["video_frame"]<=stop)].copy()
    
    # agent-targetè·é›¢ã¨è§’åº¦
    df_pair["dist_agent_target"] = np.sqrt(
        (df_pair["x_body_center_agent"] - df_pair["x_body_center_target"])**2 +
        (df_pair["y_body_center_agent"] - df_pair["y_body_center_target"])**2
    )
    dx = df_pair["x_body_center_target"] - df_pair["x_body_center_agent"]
    dy = df_pair["y_body_center_target"] - df_pair["y_body_center_agent"]
    df_pair["angle_agent_target"] = np.arctan2(dy, dx)
    
    # ç›¸å¯¾é€Ÿåº¦ã¨åŠ é€Ÿåº¦
    df_pair["rel_speed_x"] = (df_pair["x_body_center_target"].diff() - df_pair["x_body_center_agent"].diff()).fillna(0)
    df_pair["rel_speed_y"] = (df_pair["y_body_center_target"].diff() - df_pair["y_body_center_agent"].diff()).fillna(0)
    df_pair["rel_speed"] = np.sqrt(df_pair["rel_speed_x"]**2 + df_pair["rel_speed_y"]**2)
    df_pair["rel_acceleration"] = df_pair["rel_speed"].diff().fillna(0)
    
    df_pair["video_id"] = video_id
    df_pair["agent_id"] = agent_id
    df_pair["target_id"] = target_id
    df_pair["action"] = row["action"]
    
    pair_features_list.append(df_pair)

tracking_features_complete = pd.concat(pair_features_list, ignore_index=True)
tracking_features_complete.to_csv("tracking_features.csv", index=False)
print("tracking_features.csv ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ˆbodyparté–“è·é›¢ãƒ»è§’åº¦ãƒ»åŠ é€Ÿåº¦å«ã‚€å®Œå…¨ç‰ˆï¼‰")
```

---

### ğŸ”¹ è¿½åŠ ã•ã‚ŒãŸç‰¹å¾´é‡

1. **bodyparté–“è·é›¢**ï¼š`dist_ear_left_ear_right` ãªã©
2. **bodyparté–“è§’åº¦**ï¼š`angle_nose_tail_base` ãªã©
3. **é€Ÿåº¦ãƒ»åŠ é€Ÿåº¦**ï¼š`speed`, `acceleration`
4. **agent-targetè·é›¢ãƒ»è§’åº¦ãƒ»ç›¸å¯¾é€Ÿåº¦ãƒ»ç›¸å¯¾åŠ é€Ÿåº¦**ï¼š`dist_agent_target`, `angle_agent_target`, `rel_speed`, `rel_acceleration`

---

ğŸ’¡ ã“ã® CSV ã‚’ä½¿ãˆã°ã€**ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®è±Šå¯Œãªç©ºé–“æƒ…å ±ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›**å¯èƒ½ã§ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã« **XGBoost / LGBM ãªã©ã§ action äºˆæ¸¬ç”¨ã®å­¦ç¿’ã‚»ãƒƒãƒˆã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** ã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ã€‚ãã‚Œã§ã¯ã€å…ˆã»ã©ç”Ÿæˆã—ãŸ `tracking_features.csv` ã‚’å…ƒã« **XGBoost ãªã©ã§å­¦ç¿’ã§ãã‚‹å½¢ã®ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ action äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ** ã‚’ä½œã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç¤ºã—ã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* `tracking_features.csv` ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ç‰¹å¾´é‡ã‚’åˆ©ç”¨
* `submission.csv` ã® agent-target-action ã®æ™‚é–“ç¯„å›²ã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦ä»˜ä¸
* ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ç”¨ã« **agent_id, target_id, video_frame ã‚’é™¤ã„ãŸæ•°å€¤ç‰¹å¾´é‡ + ãƒ©ãƒ™ãƒ«(action)** ã®å½¢ã«å¤‰æ›

---

```python
import pandas as pd
import numpy as np

# CSVèª­ã¿è¾¼ã¿
tracking_features = pd.read_csv("tracking_features.csv")
submission = pd.read_csv("submission.csv")  # å­¦ç¿’ç”¨ãªã‚‰ annotation.csv ã‚’ä½¿ã£ã¦ã‚‚å¯

# ãƒ©ãƒ™ãƒ«åˆ—ã‚’æº–å‚™
tracking_features["action"] = "none"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

# å„è¡Œå‹•ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ã§ãƒ©ãƒ™ãƒ«ä»˜ä¸
for idx, row in submission.iterrows():
    agent = row["agent_id"]
    target = row["target_id"]
    start = row["start_frame"]
    stop = row["stop_frame"]
    action = row["action"]
    
    mask = (
        (tracking_features["agent_id"]==agent) &
        (tracking_features["target_id"]==target) &
        (tracking_features["video_frame"]>=start) &
        (tracking_features["video_frame"]<=stop)
    )
    tracking_features.loc[mask, "action"] = action

# ãƒ¢ãƒ‡ãƒ«ç”¨ã«ä¸è¦åˆ—ã‚’é™¤å¤–
feature_cols = [c for c in tracking_features.columns if c not in ["video_id","agent_id","target_id","video_frame","action"]]
X = tracking_features[feature_cols]
y = tracking_features["action"]

# ãƒ©ãƒ™ãƒ«ã‚’æ•°å€¤ã«å¤‰æ›
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
print("ç‰¹å¾´é‡ shape:", X.shape)
print("ãƒ©ãƒ™ãƒ«ä¾‹:", y_encoded[:10])
print("ãƒ©ãƒ™ãƒ«å¯¾å¿œ:", dict(zip(le.classes_, le.transform(le.classes_))))

# ä¿å­˜
X.to_csv("X_train.csv", index=False)
pd.DataFrame(y_encoded, columns=["action"]).to_csv("y_train.csv", index=False)
print("X_train.csv ã¨ y_train.csv ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
```

---

### ğŸ”¹ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒã‚¤ãƒ³ãƒˆ

1. `tracking_features.csv` ã®å„ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã« **agent-target-actionãƒ©ãƒ™ãƒ«** ã‚’ä»˜ä¸
2. **ç‰¹å¾´é‡åˆ—** ã¯ `video_id, agent_id, target_id, video_frame, action` ã‚’é™¤å¤–
3. `LabelEncoder` ã§æ–‡å­—åˆ—ã® action ã‚’æ•°å€¤ãƒ©ãƒ™ãƒ«ã«å¤‰æ›
4. `X_train.csv` ã¨ `y_train.csv` ã¨ã—ã¦ä¿å­˜ã—ã€ç›´æ¥ XGBoost ç­‰ã§å­¦ç¿’å¯èƒ½

---

ğŸ’¡ è¿½åŠ ã§å¯èƒ½ãªæ”¹å–„ï¼š

* ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã§ã¯ãªã **ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆéå»æ•°ãƒ•ãƒ¬ãƒ¼ãƒ å¹³å‡ã‚„å·®åˆ†ï¼‰** ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ã¾ã¨ã‚ã‚‹
* `action="none"` ã‚’é™¤ã„ã¦ **æ”»æ’ƒã‚„å›é¿ãªã©ã®è¡Œå‹•ã®ã¿å­¦ç¿’å¯¾è±¡** ã¨ã™ã‚‹
* XGBoost å­¦ç¿’æ™‚ã« **ãƒã‚¦ã‚¹å€‹ä½“ã”ã¨ãƒ»å‹•ç”»ã”ã¨ã«åˆ†ã‘ã¦ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**

---

å¸Œæœ›ã§ã‚ã‚Œã°ã€ã“ã® **XGBoostå­¦ç¿’ç”¨ã®å®Œå…¨å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** ã¾ã§ä½œã£ã¦ã€ã™ãå­¦ç¿’ãƒ»æ¨è«–ã¾ã§ã§ãã‚‹å½¢ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: ãŠé¡˜ã„
A: äº†è§£ã§ã™ã€‚ã§ã¯ã€å…ˆã»ã©ä½œã£ãŸ **X_train.csv / y_train.csv** ã‚’ä½¿ã£ã¦ã€**XGBoostã§å­¦ç¿’ â†’ æ¨è«– â†’ Kaggleæå‡ºç”¨ CSVç”Ÿæˆ** ã¾ã§è¡Œãˆã‚‹å®Œå…¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œã‚Šã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆï¼š

* XGBoost ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡
* å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã¯ `X_train.csv` / `y_train.csv`
* ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ `tracking_features.csv` ã‚’åˆ©ç”¨ï¼ˆsubmissionç”¨ã« agent-target ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ã§æŠ½å‡ºï¼‰
* äºˆæ¸¬çµæœã‚’ **submission.csv å½¢å¼** ã§å‡ºåŠ›

---

```python
import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# --------------------------
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# --------------------------
X_train = pd.read_csv("X_train.csv")
y_train = pd.read_csv("y_train.csv")["action"]

# ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆã‚‚ã— y_train ãŒæ–‡å­—åˆ—ã®å ´åˆï¼‰
le = LabelEncoder()
y_encoded = le.fit_transform(y_train)

print("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿:", X_train.shape)
print("ã‚¯ãƒ©ã‚¹:", list(le.classes_))

# --------------------------
# 2. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# --------------------------
model = XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    objective="multi:softmax",
    num_class=len(le.classes_),
    use_label_encoder=False,
    eval_metric="mlogloss",
    n_jobs=-1,
    random_state=42
)
model.fit(X_train, y_encoded)

# --------------------------
# 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆtracking_features.csv ã‹ã‚‰ï¼‰
# --------------------------
tracking_features = pd.read_csv("tracking_features.csv")

# ä»Šå›ã¯å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¯¾è±¡ã« agent-target å˜ä½ã§ç‰¹å¾´é‡ä½œæˆ
feature_cols = [c for c in tracking_features.columns if c not in ["video_id","agent_id","target_id","video_frame","action"]]
X_test = tracking_features[feature_cols]

# --------------------------
# 4. æ¨è«–
# --------------------------
y_pred_encoded = model.predict(X_test)
y_pred = le.inverse_transform(y_pred_encoded)

# --------------------------
# 5. Submissionå½¢å¼ã«å¤‰æ›
# --------------------------
submission_df = pd.DataFrame({
    "video_id": tracking_features["video_id"],
    "agent_id": tracking_features["agent_id"],
    "target_id": tracking_features["target_id"],
    "action": y_pred,
    "start_frame": tracking_features["video_frame"],
    "stop_frame": tracking_features["video_frame"]  # 1ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½
})

# Kaggleæå‡ºç”¨ row_id ã‚’ä»˜ä¸
submission_df = submission_df.reset_index().rename(columns={"index":"row_id"})

# CSVä¿å­˜
submission_df.to_csv("submission_pred.csv", index=False)
print("submission_pred.csv ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
```

---

### ğŸ”¹ ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç‰¹å¾´

1. **XGBoost ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡**
2. å­¦ç¿’ç”¨ç‰¹å¾´é‡ã¯ `tracking_features.csv` ã‹ã‚‰ç”Ÿæˆæ¸ˆã¿ã®ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ãƒ‡ãƒ¼ã‚¿
3. æ¨è«–çµæœã¯ **submission.csv å½¢å¼**ï¼ˆrow_id, video_id, agent_id, target_id, action, start_frame, stop_frameï¼‰ã§å‡ºåŠ›
4. 1ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§äºˆæ¸¬ã™ã‚‹ã®ã§ã€å¾Œã§å¿…è¦ã«å¿œã˜ã¦ **é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã¾ã¨ã‚ã¦è¡Œå‹•åŒºé–“ã«å¤‰æ›** å¯èƒ½

---

ğŸ’¡ è¿½åŠ æ”¹å–„æ¡ˆï¼š

* **start_frame/stop_frame ã‚’é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã§ã¾ã¨ã‚ã‚‹** â†’ è¡Œå‹•åŒºé–“ã‚’æ­£ç¢ºã«åæ˜ 
* **éå» N ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç§»å‹•å¹³å‡ç‰¹å¾´é‡** ã‚’åŠ ãˆã¦ãƒ¢ãƒ‡ãƒ«ç²¾åº¦å‘ä¸Š
* **ãƒã‚¦ã‚¹å€‹ä½“ã”ã¨ãƒ»å‹•ç”»ã”ã¨ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³** ã§éå­¦ç¿’é˜²æ­¢

---

å¸Œæœ›ã§ã‚ã‚Œã°ã€ã“ã® **ãƒ•ãƒ¬ãƒ¼ãƒ äºˆæ¸¬çµæœã‚’é€£ç¶šåŒºé–“ã«ã¾ã¨ã‚ã¦ submission.csv ã‚’å®Œæˆã•ã›ã‚‹å‡¦ç†** ã¾ã§è¿½åŠ ã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚ä½œã‚Œã¾ã™ã€‚ä½œã‚Šã¾ã™ã‹ï¼Ÿ





Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 




Q: 
A: 








